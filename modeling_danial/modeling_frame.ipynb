{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data :  (647054, 7)\n",
      "Test  data :  (653646, 6)\n",
      "submission  data :  (95674, 39)\n"
     ]
    }
   ],
   "source": [
    "# Import the functions used in this project\n",
    "import awesome_functions as af\n",
    "import decode_utils as du\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "# Pretty display for notebooks\n",
    "%matplotlib inline\n",
    "\n",
    "# Ignore the warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load the dataset\n",
    "train = pd.read_csv(\"../asset/train.csv\")\n",
    "test = pd.read_csv(\"../asset/test.csv\")\n",
    "submission = pd.read_csv(\"../asset/sample_submission.csv\")\n",
    "\n",
    "# Success - Display the first record\n",
    "print(\"Train data : \", train.shape)\n",
    "print(\"Test  data : \", test.shape)\n",
    "print(\"submission  data : \", submission.shape)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import pickle as pkl\n",
    "slack_url = pkl.load(open(\"Slack_url/send_url.pickle\", \"rb\"))\n",
    "\n",
    "import xgboost\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from scipy.sparse import csr_matrix\n",
    "def fitNaiveBayesModel(X, y):\n",
    "    return MultinomialNB(alpha=0.0).fit(X, y)\n",
    "\n",
    "# 원본을 유지하기 위해서 카피\n",
    "df_train = train.copy()\n",
    "df_test = test.copy()\n",
    "df_submission = submission.copy()\n",
    "\n",
    "df_train_dd = pd.read_csv(\"Feature_matrix/df_train_dd_201807291831.csv\")\n",
    "# df_test_dd = pd.read_csv(\"Feature_matrix/df_test_dd_201807291855.csv\")\n",
    "df_train_fl = pd.read_csv(\"Feature_matrix/df_train_fl_201807291845.csv\")\n",
    "# df_test_fl = pd.read_csv(\"Feature_matrix/df_test_fl_201807291908.csv\")\n",
    "df_train_cp = pd.read_csv(\"Feature_matrix/df_train_cp_201808062200.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pivor_df(df, col):\n",
    "    return pd.pivot_table(data= df, index=\"VisitNumber\", fill_value=0,\\\n",
    "                          values=\"ScanCount\", columns=col, aggfunc=np.sum)\n",
    "\n",
    "def get_rid_of_zero_units(df):\n",
    "    return np.where(df < 0, 0, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_flat_type_user(df_, col = \"DepartmentDescription\", is_to_get_total = False):\n",
    "    \"\"\"\n",
    "        예:) vn_dd_more_than_one, vn_dd_one = get_flat_type_user(df_decoded) 반드시 df는 decoding 함수로 decoded된 것을 넣을 것.\n",
    "    \"\"\"\n",
    "    df = df_.copy()\n",
    "    df_count = df.groupby([\"VisitNumber\", col]).sum()[\"ScanCount\"].reset_index(name=\"Sc_sum\")\n",
    "    df_count[\"Sc_sum\"] = np.where(df_count[\"Sc_sum\"] < 0, 0, df_count[\"Sc_sum\"])\n",
    "    df_count = df_count.dropna()\n",
    "    df_count_total = df_count.groupby(\"VisitNumber\").sum()[\"Sc_sum\"].reset_index(name=\"Total\")\n",
    "    if is_to_get_total:\n",
    "        return df_count_total\n",
    "\n",
    "    df_merged = pd.merge(df_count, df_count_total, on=\"VisitNumber\")\n",
    "    df_merged[\"P\"] = df_merged[\"Sc_sum\"].div(df_merged[\"Total\"])\n",
    "    \n",
    "    num_category_li = []\n",
    "    for i, vn in enumerate(df_merged.VisitNumber.unique()):\n",
    "        tmp_df = df_merged[df_merged[\"VisitNumber\"] == vn]\n",
    "        if tmp_df.Total.values[0] == 0:\n",
    "            num_category_li.append(0)\n",
    "        else:\n",
    "            num_of_category = len(tmp_df[col].unique())\n",
    "            num_category_li.append(num_of_category)\n",
    "        if i % 5000 == 0:\n",
    "            print(str(i) + \"까지 진행됨.\")\n",
    "    \n",
    "    return num_category_li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_decoded = du.decodeStuffNeedsToBeDecoded(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10007"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_decoded.Item_nbr.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_item = get_pivor_df(df_decoded, \"Item_nbr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_train_item = df_train_item.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_do_not_need = ['VisitNumber', 'Return', 'TripType', 'Monday', 'Tuesday', 'Wednesday', 'Thursday',\n",
    "       'Friday', 'Saturday', 'Sunday']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tmp = df_decoded.groupby([\"VisitNumber\", \"DepartmentDescription\"]).agg({\"ScanCount\" : np.sum}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VisitNumber</th>\n",
       "      <th>DepartmentDescription</th>\n",
       "      <th>ScanCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>FINANCIAL SERVICES</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>PERSONAL CARE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>SHOES</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>DAIRY</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>DSD GROCERY</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8</td>\n",
       "      <td>HOUSEHOLD CHEMICALS/SUPP</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>MEAT - FRESH &amp; FROZEN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>NULL</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>PAINT AND ACCESSORIES</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>PETS AND SUPPLIES</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>9</td>\n",
       "      <td>IMPULSE MERCHANDISE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>9</td>\n",
       "      <td>PRODUCE</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10</td>\n",
       "      <td>CANDY, TOBACCO, COOKIES</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>10</td>\n",
       "      <td>DSD GROCERY</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>11</td>\n",
       "      <td>DSD GROCERY</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>11</td>\n",
       "      <td>GROCERY DRY GOODS</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>11</td>\n",
       "      <td>IMPULSE MERCHANDISE</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>12</td>\n",
       "      <td>BOYS WEAR</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>12</td>\n",
       "      <td>HOUSEHOLD CHEMICALS/SUPP</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>12</td>\n",
       "      <td>PERSONAL CARE</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>12</td>\n",
       "      <td>SHOES</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>15</td>\n",
       "      <td>FABRICS AND CRAFTS</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>17</td>\n",
       "      <td>CANDY, TOBACCO, COOKIES</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>17</td>\n",
       "      <td>DSD GROCERY</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>19</td>\n",
       "      <td>ACCESSORIES</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>19</td>\n",
       "      <td>FABRICS AND CRAFTS</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>19</td>\n",
       "      <td>HOME MANAGEMENT</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>19</td>\n",
       "      <td>IMPULSE MERCHANDISE</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>19</td>\n",
       "      <td>JEWELRY AND SUNGLASSES</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>19</td>\n",
       "      <td>MENS WEAR</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322099</th>\n",
       "      <td>191337</td>\n",
       "      <td>DSD GROCERY</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322100</th>\n",
       "      <td>191337</td>\n",
       "      <td>FROZEN FOODS</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322101</th>\n",
       "      <td>191337</td>\n",
       "      <td>GROCERY DRY GOODS</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322102</th>\n",
       "      <td>191337</td>\n",
       "      <td>IMPULSE MERCHANDISE</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322103</th>\n",
       "      <td>191337</td>\n",
       "      <td>MEAT - FRESH &amp; FROZEN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322104</th>\n",
       "      <td>191337</td>\n",
       "      <td>PRE PACKED DELI</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322105</th>\n",
       "      <td>191342</td>\n",
       "      <td>IMPULSE MERCHANDISE</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322106</th>\n",
       "      <td>191343</td>\n",
       "      <td>DSD GROCERY</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322107</th>\n",
       "      <td>191343</td>\n",
       "      <td>IMPULSE MERCHANDISE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322108</th>\n",
       "      <td>191343</td>\n",
       "      <td>MENS WEAR</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322109</th>\n",
       "      <td>191344</td>\n",
       "      <td>BEAUTY</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322110</th>\n",
       "      <td>191344</td>\n",
       "      <td>WIRELESS</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322111</th>\n",
       "      <td>191345</td>\n",
       "      <td>BEAUTY</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322112</th>\n",
       "      <td>191345</td>\n",
       "      <td>COMM BREAD</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322113</th>\n",
       "      <td>191345</td>\n",
       "      <td>DSD GROCERY</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322114</th>\n",
       "      <td>191345</td>\n",
       "      <td>ELECTRONICS</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322115</th>\n",
       "      <td>191345</td>\n",
       "      <td>GROCERY DRY GOODS</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322116</th>\n",
       "      <td>191345</td>\n",
       "      <td>HOUSEHOLD CHEMICALS/SUPP</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322117</th>\n",
       "      <td>191345</td>\n",
       "      <td>HOUSEHOLD PAPER GOODS</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322118</th>\n",
       "      <td>191345</td>\n",
       "      <td>PHARMACY OTC</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322119</th>\n",
       "      <td>191346</td>\n",
       "      <td>DAIRY</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322120</th>\n",
       "      <td>191346</td>\n",
       "      <td>DSD GROCERY</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322121</th>\n",
       "      <td>191346</td>\n",
       "      <td>FROZEN FOODS</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322122</th>\n",
       "      <td>191346</td>\n",
       "      <td>GROCERY DRY GOODS</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322123</th>\n",
       "      <td>191346</td>\n",
       "      <td>HOUSEHOLD CHEMICALS/SUPP</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322124</th>\n",
       "      <td>191346</td>\n",
       "      <td>MEAT - FRESH &amp; FROZEN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322125</th>\n",
       "      <td>191346</td>\n",
       "      <td>PHARMACY OTC</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322126</th>\n",
       "      <td>191346</td>\n",
       "      <td>PRODUCE</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322127</th>\n",
       "      <td>191347</td>\n",
       "      <td>DAIRY</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322128</th>\n",
       "      <td>191347</td>\n",
       "      <td>GROCERY DRY GOODS</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>322129 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        VisitNumber     DepartmentDescription  ScanCount\n",
       "0                 5        FINANCIAL SERVICES         -1\n",
       "1                 7             PERSONAL CARE          1\n",
       "2                 7                     SHOES          1\n",
       "3                 8                     DAIRY          2\n",
       "4                 8               DSD GROCERY          1\n",
       "5                 8  HOUSEHOLD CHEMICALS/SUPP          1\n",
       "6                 8     MEAT - FRESH & FROZEN          1\n",
       "7                 8                      NULL          1\n",
       "8                 8     PAINT AND ACCESSORIES         18\n",
       "9                 8         PETS AND SUPPLIES          4\n",
       "10                9       IMPULSE MERCHANDISE          1\n",
       "11                9                   PRODUCE          2\n",
       "12               10   CANDY, TOBACCO, COOKIES          1\n",
       "13               10               DSD GROCERY          2\n",
       "14               11               DSD GROCERY          1\n",
       "15               11         GROCERY DRY GOODS          1\n",
       "16               11       IMPULSE MERCHANDISE          2\n",
       "17               12                 BOYS WEAR          2\n",
       "18               12  HOUSEHOLD CHEMICALS/SUPP          2\n",
       "19               12             PERSONAL CARE          2\n",
       "20               12                     SHOES          1\n",
       "21               15        FABRICS AND CRAFTS          9\n",
       "22               17   CANDY, TOBACCO, COOKIES          2\n",
       "23               17               DSD GROCERY          2\n",
       "24               19               ACCESSORIES          1\n",
       "25               19        FABRICS AND CRAFTS          1\n",
       "26               19           HOME MANAGEMENT          1\n",
       "27               19       IMPULSE MERCHANDISE          2\n",
       "28               19    JEWELRY AND SUNGLASSES          1\n",
       "29               19                 MENS WEAR          3\n",
       "...             ...                       ...        ...\n",
       "322099       191337               DSD GROCERY          4\n",
       "322100       191337              FROZEN FOODS          3\n",
       "322101       191337         GROCERY DRY GOODS         11\n",
       "322102       191337       IMPULSE MERCHANDISE          2\n",
       "322103       191337     MEAT - FRESH & FROZEN          0\n",
       "322104       191337           PRE PACKED DELI          1\n",
       "322105       191342       IMPULSE MERCHANDISE          2\n",
       "322106       191343               DSD GROCERY          2\n",
       "322107       191343       IMPULSE MERCHANDISE          1\n",
       "322108       191343                 MENS WEAR          6\n",
       "322109       191344                    BEAUTY          4\n",
       "322110       191344                  WIRELESS          1\n",
       "322111       191345                    BEAUTY          1\n",
       "322112       191345                COMM BREAD          3\n",
       "322113       191345               DSD GROCERY          5\n",
       "322114       191345               ELECTRONICS          1\n",
       "322115       191345         GROCERY DRY GOODS          2\n",
       "322116       191345  HOUSEHOLD CHEMICALS/SUPP          1\n",
       "322117       191345     HOUSEHOLD PAPER GOODS          2\n",
       "322118       191345              PHARMACY OTC          2\n",
       "322119       191346                     DAIRY          1\n",
       "322120       191346               DSD GROCERY          3\n",
       "322121       191346              FROZEN FOODS          1\n",
       "322122       191346         GROCERY DRY GOODS          5\n",
       "322123       191346  HOUSEHOLD CHEMICALS/SUPP          2\n",
       "322124       191346     MEAT - FRESH & FROZEN          1\n",
       "322125       191346              PHARMACY OTC          2\n",
       "322126       191346                   PRODUCE          2\n",
       "322127       191347                     DAIRY          1\n",
       "322128       191347         GROCERY DRY GOODS          1\n",
       "\n",
       "[322129 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp.groupby([\"VisitNumber\", \"DepartmentDescription\"]).sum()[\"ScanCount\"].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "scan_total = tmp.groupby(\"VisitNumber\").sum()[\"ScanCount\"].reset_index(name='ScanCount')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_li = scan_total.ScanCount.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "try_new_stuff = df_decoded.groupby([\"Company\", \"DepartmentDescription\"]).sum()[\"ScanCount\"].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "try_new_stuff_1 = try_new_stuff.groupby(\"Company\").size().reset_index(name=\"Count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cp_li = try_new_stuff_1[try_new_stuff_1.Count == 1].Company.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4806"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cp_li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "try_new_stuff = df_decoded.groupby([\"FinelineNumber\", \"DepartmentDescription\"]).sum()[\"ScanCount\"].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "try_new_stuff_1 = try_new_stuff.groupby(\"FinelineNumber\").size().reset_index(name=\"Count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "fl_li = try_new_stuff_1[try_new_stuff_1.Count == 1].FinelineNumber.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2695"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fl_li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "af.sendSlackDm(slack_url, \"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "fl_li = fl_li.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "fl_li = fl_li.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0까지 진행됨.\n",
      "5000까지 진행됨.\n",
      "10000까지 진행됨.\n",
      "15000까지 진행됨.\n",
      "20000까지 진행됨.\n",
      "25000까지 진행됨.\n",
      "30000까지 진행됨.\n",
      "35000까지 진행됨.\n",
      "40000까지 진행됨.\n",
      "45000까지 진행됨.\n",
      "50000까지 진행됨.\n",
      "55000까지 진행됨.\n",
      "60000까지 진행됨.\n",
      "65000까지 진행됨.\n",
      "70000까지 진행됨.\n",
      "75000까지 진행됨.\n",
      "80000까지 진행됨.\n",
      "85000까지 진행됨.\n",
      "90000까지 진행됨.\n",
      "95000까지 진행됨.\n"
     ]
    }
   ],
   "source": [
    "num_fl = get_flat_type_user(df_decoded, \"FinelineNumber\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0까지 진행됨.\n",
      "5000까지 진행됨.\n",
      "10000까지 진행됨.\n",
      "15000까지 진행됨.\n",
      "20000까지 진행됨.\n",
      "25000까지 진행됨.\n",
      "30000까지 진행됨.\n",
      "35000까지 진행됨.\n",
      "40000까지 진행됨.\n",
      "45000까지 진행됨.\n",
      "50000까지 진행됨.\n",
      "55000까지 진행됨.\n",
      "60000까지 진행됨.\n",
      "65000까지 진행됨.\n",
      "70000까지 진행됨.\n",
      "75000까지 진행됨.\n",
      "80000까지 진행됨.\n",
      "85000까지 진행됨.\n",
      "90000까지 진행됨.\n",
      "95000까지 진행됨.\n"
     ]
    }
   ],
   "source": [
    "num_dd = get_flat_type_user(df_decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0까지 진행됨.\n",
      "5000까지 진행됨.\n",
      "10000까지 진행됨.\n",
      "15000까지 진행됨.\n",
      "20000까지 진행됨.\n",
      "25000까지 진행됨.\n",
      "30000까지 진행됨.\n",
      "35000까지 진행됨.\n",
      "40000까지 진행됨.\n",
      "45000까지 진행됨.\n",
      "50000까지 진행됨.\n",
      "55000까지 진행됨.\n",
      "60000까지 진행됨.\n",
      "65000까지 진행됨.\n",
      "70000까지 진행됨.\n",
      "75000까지 진행됨.\n",
      "80000까지 진행됨.\n",
      "85000까지 진행됨.\n",
      "90000까지 진행됨.\n",
      "95000까지 진행됨.\n"
     ]
    }
   ],
   "source": [
    "num_company = get_flat_type_user(df_decoded, \"Company\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0까지 진행됨.\n",
      "5000까지 진행됨.\n",
      "10000까지 진행됨.\n",
      "15000까지 진행됨.\n",
      "20000까지 진행됨.\n",
      "25000까지 진행됨.\n",
      "30000까지 진행됨.\n",
      "35000까지 진행됨.\n",
      "40000까지 진행됨.\n",
      "45000까지 진행됨.\n",
      "50000까지 진행됨.\n",
      "55000까지 진행됨.\n",
      "60000까지 진행됨.\n",
      "65000까지 진행됨.\n",
      "70000까지 진행됨.\n",
      "75000까지 진행됨.\n",
      "80000까지 진행됨.\n",
      "85000까지 진행됨.\n",
      "90000까지 진행됨.\n",
      "95000까지 진행됨.\n"
     ]
    }
   ],
   "source": [
    "num_upc = get_flat_type_user(df_decoded, \"Upc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0까지 진행됨.\n",
      "5000까지 진행됨.\n",
      "10000까지 진행됨.\n",
      "15000까지 진행됨.\n",
      "20000까지 진행됨.\n",
      "25000까지 진행됨.\n",
      "30000까지 진행됨.\n",
      "35000까지 진행됨.\n",
      "40000까지 진행됨.\n",
      "45000까지 진행됨.\n",
      "50000까지 진행됨.\n",
      "55000까지 진행됨.\n",
      "60000까지 진행됨.\n",
      "65000까지 진행됨.\n",
      "70000까지 진행됨.\n",
      "75000까지 진행됨.\n",
      "80000까지 진행됨.\n",
      "85000까지 진행됨.\n",
      "90000까지 진행됨.\n",
      "95000까지 진행됨.\n"
     ]
    }
   ],
   "source": [
    "num_item = get_flat_type_user(df_decoded, \"Item_nbr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_dd = [col for col in df_train_dd.columns if col not in cols_do_not_need]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_dd[col_dd] = df_train_dd[col_dd].div(pd.DataFrame(sc_li, columns=[\"sc\"])[\"sc\"], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1359, 2678, 2870)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(col_fl_filttered_li), len(col_item_filttered_li), len(col_cp_filttered_li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6907"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(col_fl_filttered_li) + len(col_item_filttered_li) + len(col_cp_filttered_li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp_fl = pd.concat([df_train_dd, df_train_fl[fl_li], df_train_item[col_item_filttered_li], df_train_cp[cp_li]], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95674"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cp_fl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp_fl[\"N_DD\"] = num_dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp_fl[\"N_FL\"] = num_fl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp_fl[\"N_COMPANY\"] = num_company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp_fl[\"N_ITEM\"] = num_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp_fl[\"N_UPC\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_dd = [col for col in col_dd if col != \"MENS WEAR\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_count = df_decoded.groupby(\"VisitNumber\").count()[\"TripType\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp_fl[\"ROW_CNT\"] = row_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp_fl.set_index(\"VisitNumber\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_upc = df_decoded.groupby([\"VisitNumber\", \"Upc\"]).sum()[\"ScanCount\"].reset_index(name=\"Sc_sum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "upc_vn_li = df_upc.groupby(\"VisitNumber\").sum()[\"Sc_sum\"].index.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Buffer has wrong number of dimensions (expected 1, got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_set_value\u001b[0;34m(self, index, col, value, takeable)\u001b[0m\n\u001b[1;32m   2029\u001b[0m             \u001b[0mengine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2030\u001b[0;31m             \u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2031\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.set_value\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.set_value\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'Int64Index([     5,      7,      8,      9,     10,     11,     12,     15,\n                17,     19,\n            ...\n            191329, 191331, 191335, 191337, 191342, 191343, 191344, 191345,\n            191346, 191347],\n           dtype='int64', name='VisitNumber', length=95301)' is an invalid key",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-f41c9b2a6dfa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcp_fl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mupc_vn_li\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"N_UPC\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_upc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   1884\u001b[0m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_setter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1885\u001b[0m         \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1886\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtakeable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_takeable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1888\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_set_value\u001b[0;34m(self, index, col, value, takeable)\u001b[0m\n\u001b[1;32m   2033\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2034\u001b[0m             \u001b[0;31m# set using a non-recursive method & reset the cache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2035\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2036\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_item_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2037\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_setitem_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_with_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_setitem_indexer\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_setter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mIndexingError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_convert_tuple\u001b[0;34m(self, key, is_setter)\u001b[0m\n\u001b[1;32m    240\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mIndexingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Too many indexers'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m                 \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_setter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_setter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m                 \u001b[0mkeyidx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyidx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[0;34m(self, obj, axis, is_setter)\u001b[0m\n\u001b[1;32m   1253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1254\u001b[0m                 \u001b[0;31m# unique index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1255\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1256\u001b[0m                     \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/properties.pyx\u001b[0m in \u001b[0;36mpandas._libs.properties.cache_readonly.__get__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mis_unique\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1316\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mis_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1317\u001b[0m         \u001b[0;34m\"\"\" return if the index has unique values \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1318\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.is_unique.__get__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine._do_unique_check\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine._ensure_mapping_populated\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.map_locations\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Buffer has wrong number of dimensions (expected 1, got 2)"
     ]
    }
   ],
   "source": [
    "cp_fl.at[upc_vn_li, \"N_UPC\"] = num_upc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cp_fl = cp_fl.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp_fl[\"Scancount_total\"] = sc_li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp_fl[\"FL_DIV_DD\"] = cp_fl[\"N_FL\"].div(cp_fl[\"N_DD\"], axis = 0)\n",
    "cp_fl[\"UPC_DIV_DD\"] = cp_fl[\"N_UPC\"].div(cp_fl[\"N_DD\"], axis = 0)\n",
    "cp_fl[\"COMPANY_DIV_DD\"] = cp_fl[\"N_COMPANY\"].div(cp_fl[\"N_DD\"], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cp_fl = cp_fl.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp_fl[\"MENSWEAR\"] = cp_fl[\"MENS WEAR\"] + cp_fl[\"MENSWEAR\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp_fl.drop(\"MENS WEAR\", axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fl_remained_li = [col for col in fl_li if col not in zero_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum_li = []\n",
    "# tmp_df = cp_fl[fl_remained_li]\n",
    "col_item_filttered_li = []\n",
    "for idx, col in enumerate(df_train_item.columns):\n",
    "    sum_of_col = df_train_item[col].sum()\n",
    "#     sum_li.append(sum_of_col)\n",
    "    if sum_of_col > 71:\n",
    "        col_item_filttered_li.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>N_DD</th>\n",
       "      <th>N_UPC</th>\n",
       "      <th>N_FL</th>\n",
       "      <th>N_ITEM</th>\n",
       "      <th>ROW_CNT</th>\n",
       "      <th>Scancount_total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>95674.000000</td>\n",
       "      <td>95674.000000</td>\n",
       "      <td>95674.000000</td>\n",
       "      <td>95674.000000</td>\n",
       "      <td>95674.000000</td>\n",
       "      <td>95674.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.298043</td>\n",
       "      <td>6.434360</td>\n",
       "      <td>5.833351</td>\n",
       "      <td>6.404509</td>\n",
       "      <td>6.763112</td>\n",
       "      <td>7.499467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.932498</td>\n",
       "      <td>8.375563</td>\n",
       "      <td>7.356918</td>\n",
       "      <td>8.217316</td>\n",
       "      <td>8.531894</td>\n",
       "      <td>10.261119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-52.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>26.000000</td>\n",
       "      <td>189.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>186.000000</td>\n",
       "      <td>209.000000</td>\n",
       "      <td>311.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               N_DD         N_UPC          N_FL        N_ITEM       ROW_CNT  \\\n",
       "count  95674.000000  95674.000000  95674.000000  95674.000000  95674.000000   \n",
       "mean       3.298043      6.434360      5.833351      6.404509      6.763112   \n",
       "std        2.932498      8.375563      7.356918      8.217316      8.531894   \n",
       "min        0.000000      0.000000      0.000000      0.000000      1.000000   \n",
       "25%        1.000000      2.000000      1.000000      2.000000      2.000000   \n",
       "50%        2.000000      3.000000      3.000000      3.000000      4.000000   \n",
       "75%        5.000000      8.000000      7.000000      8.000000      8.000000   \n",
       "max       26.000000    189.000000    112.000000    186.000000    209.000000   \n",
       "\n",
       "       Scancount_total  \n",
       "count     95674.000000  \n",
       "mean          7.499467  \n",
       "std          10.261119  \n",
       "min         -52.000000  \n",
       "25%           2.000000  \n",
       "50%           4.000000  \n",
       "75%           9.000000  \n",
       "max         311.000000  "
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cp_fl[[\"N_DD\", \"N_UPC\", \"N_FL\", \"N_ITEM\", \"ROW_CNT\", \"Scancount_total\"]].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sum_li = []\n",
    "col_cp_filttered_li = []\n",
    "for idx, col in enumerate(df_train_cp.columns):\n",
    "    sum_of_col = df_train_cp[col].sum()\n",
    "    sum_li.append(sum_of_col)\n",
    "    if sum_of_col >= 15.0:\n",
    "        col_cp_filttered_li.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2870"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(col_cp_filttered_li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_sum_li = np.array(sum_li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.0"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(np_sum_li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "812"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(col_cp_filttered_li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VisitNumber</th>\n",
       "      <th>TripType</th>\n",
       "      <th>Return</th>\n",
       "      <th>1-HR PHOTO</th>\n",
       "      <th>ACCESSORIES</th>\n",
       "      <th>AUTOMOTIVE</th>\n",
       "      <th>BAKERY</th>\n",
       "      <th>BATH AND SHOWER</th>\n",
       "      <th>BEAUTY</th>\n",
       "      <th>BEDDING</th>\n",
       "      <th>...</th>\n",
       "      <th>95</th>\n",
       "      <th>98</th>\n",
       "      <th>N_DD</th>\n",
       "      <th>N_FL</th>\n",
       "      <th>N_COMPANY</th>\n",
       "      <th>N_UPC</th>\n",
       "      <th>Scancount_total</th>\n",
       "      <th>FL_DIV_DD</th>\n",
       "      <th>UPC_DIV_DD</th>\n",
       "      <th>COMPANY_DIV_DD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>999</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>17</td>\n",
       "      <td>15</td>\n",
       "      <td>21</td>\n",
       "      <td>28</td>\n",
       "      <td>2.428571</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>12</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>1.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>15</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>17</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>19</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>23</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>25</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>26</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>1.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>28</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>1.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>29</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>30</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>31</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>33</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>40</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>41</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>43</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>45</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>47</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>49</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>50</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>51</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>53</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95644</th>\n",
       "      <td>191276</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95645</th>\n",
       "      <td>191277</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>21</td>\n",
       "      <td>1.875000</td>\n",
       "      <td>1.875000</td>\n",
       "      <td>1.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95646</th>\n",
       "      <td>191280</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95647</th>\n",
       "      <td>191283</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>1.285714</td>\n",
       "      <td>1.285714</td>\n",
       "      <td>1.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95648</th>\n",
       "      <td>191286</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>24</td>\n",
       "      <td>21</td>\n",
       "      <td>24</td>\n",
       "      <td>27</td>\n",
       "      <td>3.428571</td>\n",
       "      <td>3.428571</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95649</th>\n",
       "      <td>191287</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95650</th>\n",
       "      <td>191289</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95651</th>\n",
       "      <td>191291</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95652</th>\n",
       "      <td>191293</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "      <td>15</td>\n",
       "      <td>22</td>\n",
       "      <td>24</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95653</th>\n",
       "      <td>191298</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>14</td>\n",
       "      <td>20</td>\n",
       "      <td>22</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>1.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95654</th>\n",
       "      <td>191301</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>1.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95655</th>\n",
       "      <td>191304</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>1.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95656</th>\n",
       "      <td>191305</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95657</th>\n",
       "      <td>191311</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95658</th>\n",
       "      <td>191312</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "      <td>22</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>1.875000</td>\n",
       "      <td>1.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95659</th>\n",
       "      <td>191313</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95660</th>\n",
       "      <td>191318</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95661</th>\n",
       "      <td>191322</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95662</th>\n",
       "      <td>191324</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>22</td>\n",
       "      <td>1.636364</td>\n",
       "      <td>1.727273</td>\n",
       "      <td>1.727273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95663</th>\n",
       "      <td>191326</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>1.428571</td>\n",
       "      <td>1.571429</td>\n",
       "      <td>1.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95664</th>\n",
       "      <td>191329</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>20</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>2.222222</td>\n",
       "      <td>2.222222</td>\n",
       "      <td>2.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95665</th>\n",
       "      <td>191331</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95666</th>\n",
       "      <td>191335</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95667</th>\n",
       "      <td>191337</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>24</td>\n",
       "      <td>19</td>\n",
       "      <td>26</td>\n",
       "      <td>27</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.250000</td>\n",
       "      <td>2.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95668</th>\n",
       "      <td>191342</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95669</th>\n",
       "      <td>191343</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95670</th>\n",
       "      <td>191344</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95671</th>\n",
       "      <td>191345</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>17</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.625000</td>\n",
       "      <td>1.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95672</th>\n",
       "      <td>191346</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>13</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.125000</td>\n",
       "      <td>1.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95673</th>\n",
       "      <td>191347</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>95674 rows × 1377 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       VisitNumber  TripType  Return  1-HR PHOTO  ACCESSORIES  AUTOMOTIVE  \\\n",
       "0                5       999       1        -0.0    -0.000000   -0.000000   \n",
       "1                7        30       0         0.0     0.000000    0.000000   \n",
       "2                8        26       1         0.0     0.000000    0.000000   \n",
       "3                9         8       0         0.0     0.000000    0.000000   \n",
       "4               10         8       0         0.0     0.000000    0.000000   \n",
       "5               11        35       0         0.0     0.000000    0.000000   \n",
       "6               12        41       0         0.0     0.000000    0.000000   \n",
       "7               15        21       0         0.0     0.000000    0.000000   \n",
       "8               17         6       0         0.0     0.000000    0.000000   \n",
       "9               19        42       0         0.0     0.111111    0.000000   \n",
       "10              20         7       0         0.0     0.000000    0.000000   \n",
       "11              23         9       0         0.0     0.000000    0.000000   \n",
       "12              25         8       0         0.0     0.000000    0.000000   \n",
       "13              26        39       0         0.0     0.000000    0.000000   \n",
       "14              28        25       0         0.0     0.000000    0.000000   \n",
       "15              29         8       0         0.0     0.000000    0.000000   \n",
       "16              30         9       0         0.0     0.000000    0.000000   \n",
       "17              31         8       0         0.0     0.000000    0.000000   \n",
       "18              32         8       0         0.0     0.000000    0.000000   \n",
       "19              33         8       0         0.0     0.000000    0.000000   \n",
       "20              40         8       0         0.0     0.000000    0.000000   \n",
       "21              41         8       0         0.0     0.000000    0.000000   \n",
       "22              42         8       0         0.0     0.000000    0.000000   \n",
       "23              43        38       0         0.0     0.000000    0.000000   \n",
       "24              45         8       0         0.0     0.000000    0.000000   \n",
       "25              47        35       0         0.0     0.000000    0.000000   \n",
       "26              49        15       0         0.0     0.000000    0.000000   \n",
       "27              50         9       0         0.0     0.000000    0.000000   \n",
       "28              51         8       0         0.0     0.000000    0.000000   \n",
       "29              53         8       0         0.0     0.000000    0.000000   \n",
       "...            ...       ...     ...         ...          ...         ...   \n",
       "95644       191276        21       0         0.0     0.000000    0.000000   \n",
       "95645       191277        44       0         0.0     0.000000    0.000000   \n",
       "95646       191280         8       0         0.0     0.000000    0.000000   \n",
       "95647       191283        44       0         0.0     0.000000    0.000000   \n",
       "95648       191286        40       0         0.0     0.000000    0.000000   \n",
       "95649       191287        26       0         0.0     0.000000    0.000000   \n",
       "95650       191289         8       0         0.0     0.000000    0.000000   \n",
       "95651       191291         8       0         0.0     0.000000    0.000000   \n",
       "95652       191293        36       0         0.0     0.000000    0.000000   \n",
       "95653       191298        40       1         0.0     0.000000    0.045455   \n",
       "95654       191301        42       0         0.0     0.000000    0.000000   \n",
       "95655       191304        36       0         0.0     0.000000    0.000000   \n",
       "95656       191305        31       0         0.0     0.000000    0.000000   \n",
       "95657       191311         9       0         0.0     0.000000    0.000000   \n",
       "95658       191312        42       0         0.0     0.000000    0.000000   \n",
       "95659       191313        30       0         0.0     0.000000    0.000000   \n",
       "95660       191318         7       0         0.0     0.000000    0.000000   \n",
       "95661       191322        38       0         0.0     0.000000    0.000000   \n",
       "95662       191324        40       0         0.0     0.000000    0.136364   \n",
       "95663       191326        38       0         0.0     0.000000    0.000000   \n",
       "95664       191329        24       0         0.0     0.000000    0.000000   \n",
       "95665       191331         9       0         0.0     0.000000    0.000000   \n",
       "95666       191335        32       0         0.0     0.000000    0.000000   \n",
       "95667       191337        38       1         0.0     0.000000    0.000000   \n",
       "95668       191342         8       0         0.0     0.000000    0.000000   \n",
       "95669       191343        25       0         0.0     0.000000    0.000000   \n",
       "95670       191344        22       0         0.0     0.000000    0.000000   \n",
       "95671       191345        39       0         0.0     0.000000    0.000000   \n",
       "95672       191346        39       0         0.0     0.000000    0.000000   \n",
       "95673       191347         8       0         0.0     0.000000    0.000000   \n",
       "\n",
       "         BAKERY  BATH AND SHOWER    BEAUTY  BEDDING       ...        95  98  \\\n",
       "0     -0.000000        -0.000000 -0.000000     -0.0       ...         0   0   \n",
       "1      0.000000         0.000000  0.000000      0.0       ...         0   0   \n",
       "2      0.000000         0.000000  0.000000      0.0       ...         0   0   \n",
       "3      0.000000         0.000000  0.000000      0.0       ...         0   0   \n",
       "4      0.000000         0.000000  0.000000      0.0       ...         0   0   \n",
       "5      0.000000         0.000000  0.000000      0.0       ...         0   0   \n",
       "6      0.000000         0.000000  0.000000      0.0       ...         0   0   \n",
       "7      0.000000         0.000000  0.000000      0.0       ...         0   0   \n",
       "8      0.000000         0.000000  0.000000      0.0       ...         0   0   \n",
       "9      0.000000         0.000000  0.000000      0.0       ...         0   0   \n",
       "10     0.000000         0.000000  0.000000      0.0       ...         0   0   \n",
       "11     0.000000         0.000000  0.000000      0.0       ...         0   0   \n",
       "12     0.000000         0.000000  0.000000      0.0       ...         0   0   \n",
       "13     0.000000         0.000000  0.000000      0.0       ...         0   0   \n",
       "14     0.250000         0.000000  0.000000      0.0       ...         0   0   \n",
       "15     0.000000         0.000000  0.000000      0.0       ...         0   0   \n",
       "16     0.000000         0.000000  0.000000      0.0       ...         0   0   \n",
       "17     0.500000         0.000000  0.000000      0.0       ...         0   0   \n",
       "18     0.000000         0.000000  0.000000      0.0       ...         0   0   \n",
       "19     0.000000         0.000000  0.000000      0.0       ...         0   0   \n",
       "20     0.000000         0.000000  0.000000      0.0       ...         0   0   \n",
       "21     0.000000         0.000000  0.000000      0.0       ...         0   0   \n",
       "22     0.000000         0.000000  0.000000      0.0       ...         0   0   \n",
       "23     0.000000         0.000000  0.000000      0.0       ...         0   0   \n",
       "24     0.000000         0.000000  0.000000      0.0       ...         0   0   \n",
       "25     0.000000         0.000000  0.000000      0.0       ...         0   0   \n",
       "26     0.000000         0.000000  0.000000      0.0       ...         0   0   \n",
       "27     0.000000         0.000000  0.000000      0.0       ...         0   0   \n",
       "28     0.000000         0.000000  0.000000      0.0       ...         0   0   \n",
       "29     0.000000         0.000000  0.000000      0.0       ...         0   0   \n",
       "...         ...              ...       ...      ...       ...        ..  ..   \n",
       "95644  0.000000         0.000000  0.000000      0.0       ...         0   0   \n",
       "95645  0.000000         0.000000  0.047619      0.0       ...         0   0   \n",
       "95646  0.000000         0.000000  0.000000      0.0       ...         0   0   \n",
       "95647  0.000000         0.000000  0.100000      0.0       ...         0   0   \n",
       "95648  0.000000         0.000000  0.000000      0.0       ...         0   0   \n",
       "95649  0.000000         0.000000  0.000000      0.0       ...         0   0   \n",
       "95650  0.000000         0.000000  0.000000      0.0       ...         0   0   \n",
       "95651  0.000000         0.000000  0.000000      0.0       ...         0   0   \n",
       "95652  0.000000         0.125000  0.083333      0.0       ...         0   0   \n",
       "95653  0.045455         0.000000  0.000000      0.0       ...         0   0   \n",
       "95654  0.000000         0.222222  0.000000      0.0       ...         0   0   \n",
       "95655  0.000000         0.000000  0.000000      0.0       ...         0   0   \n",
       "95656  0.000000         0.000000  0.000000      0.0       ...         0   0   \n",
       "95657  0.000000         0.000000  0.000000      0.0       ...         0   0   \n",
       "95658  0.000000         0.000000  0.000000      0.0       ...         0   0   \n",
       "95659  0.000000         0.000000  0.000000      0.0       ...         0   0   \n",
       "95660  0.000000         0.000000  0.000000      0.0       ...         0   0   \n",
       "95661  0.000000         0.000000  0.000000      0.0       ...         0   0   \n",
       "95662  0.045455         0.000000  0.045455      0.0       ...         0   0   \n",
       "95663  0.000000         0.000000  0.000000      0.0       ...         0   0   \n",
       "95664  0.000000         0.100000  0.000000      0.0       ...         0   0   \n",
       "95665  0.000000         0.000000  0.000000      0.0       ...         0   0   \n",
       "95666  0.000000         0.000000  0.000000      0.0       ...         0   0   \n",
       "95667  0.037037         0.000000  0.000000      0.0       ...         0   0   \n",
       "95668  0.000000         0.000000  0.000000      0.0       ...         0   0   \n",
       "95669  0.000000         0.000000  0.000000      0.0       ...         0   0   \n",
       "95670  0.000000         0.000000  0.800000      0.0       ...         0   0   \n",
       "95671  0.000000         0.000000  0.058824      0.0       ...         0   0   \n",
       "95672  0.000000         0.000000  0.000000      0.0       ...         0   0   \n",
       "95673  0.000000         0.000000  0.000000      0.0       ...         0   0   \n",
       "\n",
       "       N_DD  N_FL  N_COMPANY  N_UPC  Scancount_total  FL_DIV_DD  UPC_DIV_DD  \\\n",
       "0         0     0          0      0               -1   0.000000    0.000000   \n",
       "1         2     2          2      2                2   1.000000    1.000000   \n",
       "2         7    17         15     21               28   2.428571    3.000000   \n",
       "3         2     3          3      3                3   1.500000    1.500000   \n",
       "4         2     3          3      3                3   1.500000    1.500000   \n",
       "5         3     4          4      4                4   1.333333    1.333333   \n",
       "6         4     7          7      7                7   1.750000    1.750000   \n",
       "7         1     6          3      6                9   6.000000    6.000000   \n",
       "8         2     4          4      4                4   2.000000    2.000000   \n",
       "9         6     8          7      6                9   1.333333    1.000000   \n",
       "10        2     2          2      2                3   1.000000    1.000000   \n",
       "11        2     2          2      1                2   1.000000    0.500000   \n",
       "12        2     3          2      3                3   1.500000    1.500000   \n",
       "13        5     7          8      9               12   1.400000    1.800000   \n",
       "14        4     6          6      7                8   1.500000    1.750000   \n",
       "15        1     1          1      1                1   1.000000    1.000000   \n",
       "16        1     1          1      1                1   1.000000    1.000000   \n",
       "17        2     2          2      2                2   1.000000    1.000000   \n",
       "18        1     1          1      1                1   1.000000    1.000000   \n",
       "19        2     2          2      2                3   1.000000    1.000000   \n",
       "20        2     2          2      2                3   1.000000    1.000000   \n",
       "21        2     2          2      2                3   1.000000    1.000000   \n",
       "22        1     1          1      1                1   1.000000    1.000000   \n",
       "23        4     4          4      4                4   1.000000    1.000000   \n",
       "24        4     4          4      4                4   1.000000    1.000000   \n",
       "25        3     3          3      3                5   1.000000    1.000000   \n",
       "26        3     5          4      5                5   1.666667    1.666667   \n",
       "27        1     1          1      1                1   1.000000    1.000000   \n",
       "28        1     2          2      2                2   2.000000    2.000000   \n",
       "29        1     1          1      1                1   1.000000    1.000000   \n",
       "...     ...   ...        ...    ...              ...        ...         ...   \n",
       "95644     2     3          3      3                4   1.500000    1.500000   \n",
       "95645     8    15         14     15               21   1.875000    1.875000   \n",
       "95646     3     3          3      3                3   1.000000    1.000000   \n",
       "95647     7     9          8      9               10   1.285714    1.285714   \n",
       "95648     7    24         21     24               27   3.428571    3.428571   \n",
       "95649     1     2          2      2                4   2.000000    2.000000   \n",
       "95650     1     1          1      1                1   1.000000    1.000000   \n",
       "95651     2     2          2      2                2   1.000000    1.000000   \n",
       "95652     5    19         15     22               24   3.800000    4.400000   \n",
       "95653     8    18         14     20               22   2.250000    2.500000   \n",
       "95654     6     7          7      7                9   1.166667    1.166667   \n",
       "95655     5     6          6      6                6   1.200000    1.200000   \n",
       "95656     1     1          1      1                1   1.000000    1.000000   \n",
       "95657     1     2          2      2                2   2.000000    2.000000   \n",
       "95658     8    14         13     15               22   1.750000    1.875000   \n",
       "95659     2     4          4      4                4   2.000000    2.000000   \n",
       "95660     6     6          6      7                7   1.000000    1.166667   \n",
       "95661     7    14         13     14               15   2.000000    2.000000   \n",
       "95662    11    18         19     19               22   1.636364    1.727273   \n",
       "95663     7    10         11     11               11   1.428571    1.571429   \n",
       "95664     9    20         19     20               20   2.222222    2.222222   \n",
       "95665     1     1          1      1                1   1.000000    1.000000   \n",
       "95666     3     9          9      9                9   3.000000    3.000000   \n",
       "95667     8    24         19     26               27   3.000000    3.250000   \n",
       "95668     1     2          2      2                2   2.000000    2.000000   \n",
       "95669     3     5          6      7                9   1.666667    2.333333   \n",
       "95670     2     3          4      5                5   1.500000    2.500000   \n",
       "95671     8    12         11     13               17   1.500000    1.625000   \n",
       "95672     8    16         13     17               17   2.000000    2.125000   \n",
       "95673     2     2          2      2                2   1.000000    1.000000   \n",
       "\n",
       "       COMPANY_DIV_DD  \n",
       "0            0.000000  \n",
       "1            1.000000  \n",
       "2            2.142857  \n",
       "3            1.500000  \n",
       "4            1.500000  \n",
       "5            1.333333  \n",
       "6            1.750000  \n",
       "7            3.000000  \n",
       "8            2.000000  \n",
       "9            1.166667  \n",
       "10           1.000000  \n",
       "11           1.000000  \n",
       "12           1.000000  \n",
       "13           1.600000  \n",
       "14           1.500000  \n",
       "15           1.000000  \n",
       "16           1.000000  \n",
       "17           1.000000  \n",
       "18           1.000000  \n",
       "19           1.000000  \n",
       "20           1.000000  \n",
       "21           1.000000  \n",
       "22           1.000000  \n",
       "23           1.000000  \n",
       "24           1.000000  \n",
       "25           1.000000  \n",
       "26           1.333333  \n",
       "27           1.000000  \n",
       "28           2.000000  \n",
       "29           1.000000  \n",
       "...               ...  \n",
       "95644        1.500000  \n",
       "95645        1.750000  \n",
       "95646        1.000000  \n",
       "95647        1.142857  \n",
       "95648        3.000000  \n",
       "95649        2.000000  \n",
       "95650        1.000000  \n",
       "95651        1.000000  \n",
       "95652        3.000000  \n",
       "95653        1.750000  \n",
       "95654        1.166667  \n",
       "95655        1.200000  \n",
       "95656        1.000000  \n",
       "95657        2.000000  \n",
       "95658        1.625000  \n",
       "95659        2.000000  \n",
       "95660        1.000000  \n",
       "95661        1.857143  \n",
       "95662        1.727273  \n",
       "95663        1.571429  \n",
       "95664        2.111111  \n",
       "95665        1.000000  \n",
       "95666        3.000000  \n",
       "95667        2.375000  \n",
       "95668        2.000000  \n",
       "95669        2.000000  \n",
       "95670        2.000000  \n",
       "95671        1.375000  \n",
       "95672        1.625000  \n",
       "95673        1.000000  \n",
       "\n",
       "[95674 rows x 1377 columns]"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cp_fl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp_fl.drop(\"Return\", axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4806"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sum_li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62.96213066999584"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(sum_li).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df = cp_fl[fl_li]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_li = []\n",
    "col_fl_filttered_li = []\n",
    "for idx, col in enumerate(tmp_df.columns):\n",
    "    sum_of_col = tmp_df[col].sum()\n",
    "    sum_li.append(sum_of_col)\n",
    "    if sum_of_col >= 14:\n",
    "        col_fl_filttered_li.append(col)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np_sum_li = np.array(sorted(sum_li, reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.0"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(np_sum_li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1359"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(col_fl_filttered_li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1303"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(col_fl_filttered_li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VisitNumber</th>\n",
       "      <th>TripType</th>\n",
       "      <th>1-HR PHOTO</th>\n",
       "      <th>ACCESSORIES</th>\n",
       "      <th>AUTOMOTIVE</th>\n",
       "      <th>BAKERY</th>\n",
       "      <th>BATH AND SHOWER</th>\n",
       "      <th>BEAUTY</th>\n",
       "      <th>BEDDING</th>\n",
       "      <th>BOOKS AND MAGAZINES</th>\n",
       "      <th>...</th>\n",
       "      <th>95</th>\n",
       "      <th>98</th>\n",
       "      <th>N_DD</th>\n",
       "      <th>N_FL</th>\n",
       "      <th>N_COMPANY</th>\n",
       "      <th>N_UPC</th>\n",
       "      <th>Scancount_total</th>\n",
       "      <th>FL_DIV_DD</th>\n",
       "      <th>UPC_DIV_DD</th>\n",
       "      <th>COMPANY_DIV_DD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>999</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>17</td>\n",
       "      <td>15</td>\n",
       "      <td>21</td>\n",
       "      <td>28</td>\n",
       "      <td>2.428571</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 6425 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   VisitNumber  TripType  1-HR PHOTO  ACCESSORIES  AUTOMOTIVE  BAKERY  \\\n",
       "0            5       999        -0.0         -0.0        -0.0    -0.0   \n",
       "1            7        30         0.0          0.0         0.0     0.0   \n",
       "2            8        26         0.0          0.0         0.0     0.0   \n",
       "3            9         8         0.0          0.0         0.0     0.0   \n",
       "4           10         8         0.0          0.0         0.0     0.0   \n",
       "\n",
       "   BATH AND SHOWER  BEAUTY  BEDDING  BOOKS AND MAGAZINES       ...        95  \\\n",
       "0             -0.0    -0.0     -0.0                 -0.0       ...         0   \n",
       "1              0.0     0.0      0.0                  0.0       ...         0   \n",
       "2              0.0     0.0      0.0                  0.0       ...         0   \n",
       "3              0.0     0.0      0.0                  0.0       ...         0   \n",
       "4              0.0     0.0      0.0                  0.0       ...         0   \n",
       "\n",
       "   98  N_DD  N_FL  N_COMPANY  N_UPC  Scancount_total  FL_DIV_DD  UPC_DIV_DD  \\\n",
       "0   0     0     0          0      0               -1   0.000000         0.0   \n",
       "1   0     2     2          2      2                2   1.000000         1.0   \n",
       "2   0     7    17         15     21               28   2.428571         3.0   \n",
       "3   0     2     3          3      3                3   1.500000         1.5   \n",
       "4   0     2     3          3      3                3   1.500000         1.5   \n",
       "\n",
       "   COMPANY_DIV_DD  \n",
       "0        0.000000  \n",
       "1        1.000000  \n",
       "2        2.142857  \n",
       "3        1.500000  \n",
       "4        1.500000  \n",
       "\n",
       "[5 rows x 6425 columns]"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cp_fl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "import lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X , train_y = af.get_df_to_fit(cp_fl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_enc = LabelEncoder().fit(train_y)\n",
    "y_labeled = label_enc.transform(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X, train_y, test_y = train_test_split(train_X, y_labeled, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train_X.astype(float)\n",
    "test_X = test_X.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = csr_matrix(train_X.values)\n",
    "X_test = csr_matrix(test_X.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = lightgbm.Dataset(X_train, label=train_y)\n",
    "dtest = lightgbm.Dataset(X_test, label=test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's multi_logloss: 3.42366\tvalid_1's multi_logloss: 3.43017\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[2]\ttraining's multi_logloss: 3.26244\tvalid_1's multi_logloss: 3.27351\n",
      "[3]\ttraining's multi_logloss: 3.12985\tvalid_1's multi_logloss: 3.14469\n",
      "[4]\ttraining's multi_logloss: 3.01658\tvalid_1's multi_logloss: 3.03488\n",
      "[5]\ttraining's multi_logloss: 2.91769\tvalid_1's multi_logloss: 2.93909\n",
      "[6]\ttraining's multi_logloss: 2.8297\tvalid_1's multi_logloss: 2.85389\n",
      "[7]\ttraining's multi_logloss: 2.74994\tvalid_1's multi_logloss: 2.77678\n",
      "[8]\ttraining's multi_logloss: 2.67727\tvalid_1's multi_logloss: 2.70647\n",
      "[9]\ttraining's multi_logloss: 2.6105\tvalid_1's multi_logloss: 2.64189\n",
      "[10]\ttraining's multi_logloss: 2.54875\tvalid_1's multi_logloss: 2.58226\n",
      "[11]\ttraining's multi_logloss: 2.49113\tvalid_1's multi_logloss: 2.52655\n",
      "[12]\ttraining's multi_logloss: 2.43714\tvalid_1's multi_logloss: 2.47455\n",
      "[13]\ttraining's multi_logloss: 2.3865\tvalid_1's multi_logloss: 2.42576\n",
      "[14]\ttraining's multi_logloss: 2.33884\tvalid_1's multi_logloss: 2.37977\n",
      "[15]\ttraining's multi_logloss: 2.29383\tvalid_1's multi_logloss: 2.33648\n",
      "[16]\ttraining's multi_logloss: 2.2512\tvalid_1's multi_logloss: 2.29533\n",
      "[17]\ttraining's multi_logloss: 2.21062\tvalid_1's multi_logloss: 2.25627\n",
      "[18]\ttraining's multi_logloss: 2.17194\tvalid_1's multi_logloss: 2.21893\n",
      "[19]\ttraining's multi_logloss: 2.13492\tvalid_1's multi_logloss: 2.18307\n",
      "[20]\ttraining's multi_logloss: 2.09955\tvalid_1's multi_logloss: 2.14902\n",
      "[21]\ttraining's multi_logloss: 2.06575\tvalid_1's multi_logloss: 2.11649\n",
      "[22]\ttraining's multi_logloss: 2.03313\tvalid_1's multi_logloss: 2.08507\n",
      "[23]\ttraining's multi_logloss: 2.00185\tvalid_1's multi_logloss: 2.05497\n",
      "[24]\ttraining's multi_logloss: 1.97172\tvalid_1's multi_logloss: 2.02607\n",
      "[25]\ttraining's multi_logloss: 1.94271\tvalid_1's multi_logloss: 1.99822\n",
      "[26]\ttraining's multi_logloss: 1.91468\tvalid_1's multi_logloss: 1.97129\n",
      "[27]\ttraining's multi_logloss: 1.88763\tvalid_1's multi_logloss: 1.94536\n",
      "[28]\ttraining's multi_logloss: 1.86158\tvalid_1's multi_logloss: 1.92038\n",
      "[29]\ttraining's multi_logloss: 1.83639\tvalid_1's multi_logloss: 1.8962\n",
      "[30]\ttraining's multi_logloss: 1.812\tvalid_1's multi_logloss: 1.8729\n",
      "[31]\ttraining's multi_logloss: 1.78836\tvalid_1's multi_logloss: 1.85027\n",
      "[32]\ttraining's multi_logloss: 1.76539\tvalid_1's multi_logloss: 1.82834\n",
      "[33]\ttraining's multi_logloss: 1.74325\tvalid_1's multi_logloss: 1.80721\n",
      "[34]\ttraining's multi_logloss: 1.72177\tvalid_1's multi_logloss: 1.78666\n",
      "[35]\ttraining's multi_logloss: 1.7009\tvalid_1's multi_logloss: 1.76674\n",
      "[36]\ttraining's multi_logloss: 1.68057\tvalid_1's multi_logloss: 1.7474\n",
      "[37]\ttraining's multi_logloss: 1.66089\tvalid_1's multi_logloss: 1.72862\n",
      "[38]\ttraining's multi_logloss: 1.64166\tvalid_1's multi_logloss: 1.71036\n",
      "[39]\ttraining's multi_logloss: 1.62299\tvalid_1's multi_logloss: 1.69262\n",
      "[40]\ttraining's multi_logloss: 1.60489\tvalid_1's multi_logloss: 1.67536\n",
      "[41]\ttraining's multi_logloss: 1.58723\tvalid_1's multi_logloss: 1.65855\n",
      "[42]\ttraining's multi_logloss: 1.57004\tvalid_1's multi_logloss: 1.64223\n",
      "[43]\ttraining's multi_logloss: 1.55321\tvalid_1's multi_logloss: 1.62624\n",
      "[44]\ttraining's multi_logloss: 1.53678\tvalid_1's multi_logloss: 1.61069\n",
      "[45]\ttraining's multi_logloss: 1.52087\tvalid_1's multi_logloss: 1.59559\n",
      "[46]\ttraining's multi_logloss: 1.50525\tvalid_1's multi_logloss: 1.58075\n",
      "[47]\ttraining's multi_logloss: 1.49006\tvalid_1's multi_logloss: 1.56635\n",
      "[48]\ttraining's multi_logloss: 1.47521\tvalid_1's multi_logloss: 1.55228\n",
      "[49]\ttraining's multi_logloss: 1.46067\tvalid_1's multi_logloss: 1.53853\n",
      "[50]\ttraining's multi_logloss: 1.44653\tvalid_1's multi_logloss: 1.52527\n",
      "[51]\ttraining's multi_logloss: 1.43265\tvalid_1's multi_logloss: 1.51217\n",
      "[52]\ttraining's multi_logloss: 1.41908\tvalid_1's multi_logloss: 1.4994\n",
      "[53]\ttraining's multi_logloss: 1.40588\tvalid_1's multi_logloss: 1.487\n",
      "[54]\ttraining's multi_logloss: 1.39293\tvalid_1's multi_logloss: 1.4748\n",
      "[55]\ttraining's multi_logloss: 1.38027\tvalid_1's multi_logloss: 1.4629\n",
      "[56]\ttraining's multi_logloss: 1.36788\tvalid_1's multi_logloss: 1.45119\n",
      "[57]\ttraining's multi_logloss: 1.35577\tvalid_1's multi_logloss: 1.43983\n",
      "[58]\ttraining's multi_logloss: 1.34383\tvalid_1's multi_logloss: 1.42863\n",
      "[59]\ttraining's multi_logloss: 1.33218\tvalid_1's multi_logloss: 1.4177\n",
      "[60]\ttraining's multi_logloss: 1.32076\tvalid_1's multi_logloss: 1.407\n",
      "[61]\ttraining's multi_logloss: 1.30953\tvalid_1's multi_logloss: 1.39644\n",
      "[62]\ttraining's multi_logloss: 1.29858\tvalid_1's multi_logloss: 1.3862\n",
      "[63]\ttraining's multi_logloss: 1.28781\tvalid_1's multi_logloss: 1.37611\n",
      "[64]\ttraining's multi_logloss: 1.27724\tvalid_1's multi_logloss: 1.36619\n",
      "[65]\ttraining's multi_logloss: 1.26693\tvalid_1's multi_logloss: 1.35651\n",
      "[66]\ttraining's multi_logloss: 1.25679\tvalid_1's multi_logloss: 1.34707\n",
      "[67]\ttraining's multi_logloss: 1.24688\tvalid_1's multi_logloss: 1.33782\n",
      "[68]\ttraining's multi_logloss: 1.23718\tvalid_1's multi_logloss: 1.32876\n",
      "[69]\ttraining's multi_logloss: 1.2276\tvalid_1's multi_logloss: 1.31984\n",
      "[70]\ttraining's multi_logloss: 1.21822\tvalid_1's multi_logloss: 1.31112\n",
      "[71]\ttraining's multi_logloss: 1.20905\tvalid_1's multi_logloss: 1.30257\n",
      "[72]\ttraining's multi_logloss: 1.19998\tvalid_1's multi_logloss: 1.29416\n",
      "[73]\ttraining's multi_logloss: 1.19111\tvalid_1's multi_logloss: 1.28594\n",
      "[74]\ttraining's multi_logloss: 1.1824\tvalid_1's multi_logloss: 1.2779\n",
      "[75]\ttraining's multi_logloss: 1.17387\tvalid_1's multi_logloss: 1.27003\n",
      "[76]\ttraining's multi_logloss: 1.16549\tvalid_1's multi_logloss: 1.26232\n",
      "[77]\ttraining's multi_logloss: 1.15724\tvalid_1's multi_logloss: 1.25475\n",
      "[78]\ttraining's multi_logloss: 1.14913\tvalid_1's multi_logloss: 1.24728\n",
      "[79]\ttraining's multi_logloss: 1.14116\tvalid_1's multi_logloss: 1.23996\n",
      "[80]\ttraining's multi_logloss: 1.13334\tvalid_1's multi_logloss: 1.23276\n",
      "[81]\ttraining's multi_logloss: 1.12566\tvalid_1's multi_logloss: 1.22573\n",
      "[82]\ttraining's multi_logloss: 1.11812\tvalid_1's multi_logloss: 1.21883\n",
      "[83]\ttraining's multi_logloss: 1.11073\tvalid_1's multi_logloss: 1.21207\n",
      "[84]\ttraining's multi_logloss: 1.10346\tvalid_1's multi_logloss: 1.20543\n",
      "[85]\ttraining's multi_logloss: 1.09628\tvalid_1's multi_logloss: 1.1989\n",
      "[86]\ttraining's multi_logloss: 1.08921\tvalid_1's multi_logloss: 1.19247\n",
      "[87]\ttraining's multi_logloss: 1.08225\tvalid_1's multi_logloss: 1.18615\n",
      "[88]\ttraining's multi_logloss: 1.07541\tvalid_1's multi_logloss: 1.17994\n",
      "[89]\ttraining's multi_logloss: 1.0687\tvalid_1's multi_logloss: 1.17386\n",
      "[90]\ttraining's multi_logloss: 1.06211\tvalid_1's multi_logloss: 1.16786\n",
      "[91]\ttraining's multi_logloss: 1.05564\tvalid_1's multi_logloss: 1.16197\n",
      "[92]\ttraining's multi_logloss: 1.04925\tvalid_1's multi_logloss: 1.15619\n",
      "[93]\ttraining's multi_logloss: 1.04299\tvalid_1's multi_logloss: 1.15051\n",
      "[94]\ttraining's multi_logloss: 1.0368\tvalid_1's multi_logloss: 1.14494\n",
      "[95]\ttraining's multi_logloss: 1.03073\tvalid_1's multi_logloss: 1.13948\n",
      "[96]\ttraining's multi_logloss: 1.02475\tvalid_1's multi_logloss: 1.13413\n",
      "[97]\ttraining's multi_logloss: 1.01883\tvalid_1's multi_logloss: 1.12884\n",
      "[98]\ttraining's multi_logloss: 1.01308\tvalid_1's multi_logloss: 1.12365\n",
      "[99]\ttraining's multi_logloss: 1.00737\tvalid_1's multi_logloss: 1.11858\n",
      "[100]\ttraining's multi_logloss: 1.00175\tvalid_1's multi_logloss: 1.11355\n",
      "[101]\ttraining's multi_logloss: 0.996246\tvalid_1's multi_logloss: 1.10865\n",
      "[102]\ttraining's multi_logloss: 0.990788\tvalid_1's multi_logloss: 1.10378\n",
      "[103]\ttraining's multi_logloss: 0.985417\tvalid_1's multi_logloss: 1.09901\n",
      "[104]\ttraining's multi_logloss: 0.98013\tvalid_1's multi_logloss: 1.09435\n",
      "[105]\ttraining's multi_logloss: 0.974976\tvalid_1's multi_logloss: 1.08974\n",
      "[106]\ttraining's multi_logloss: 0.969891\tvalid_1's multi_logloss: 1.08522\n",
      "[107]\ttraining's multi_logloss: 0.964794\tvalid_1's multi_logloss: 1.08068\n",
      "[108]\ttraining's multi_logloss: 0.959771\tvalid_1's multi_logloss: 1.07627\n",
      "[109]\ttraining's multi_logloss: 0.954861\tvalid_1's multi_logloss: 1.07191\n",
      "[110]\ttraining's multi_logloss: 0.950018\tvalid_1's multi_logloss: 1.06764\n",
      "[111]\ttraining's multi_logloss: 0.945177\tvalid_1's multi_logloss: 1.06337\n",
      "[112]\ttraining's multi_logloss: 0.940482\tvalid_1's multi_logloss: 1.05923\n",
      "[113]\ttraining's multi_logloss: 0.935867\tvalid_1's multi_logloss: 1.0552\n",
      "[114]\ttraining's multi_logloss: 0.931321\tvalid_1's multi_logloss: 1.05124\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[115]\ttraining's multi_logloss: 0.926766\tvalid_1's multi_logloss: 1.04731\n",
      "[116]\ttraining's multi_logloss: 0.922337\tvalid_1's multi_logloss: 1.04343\n",
      "[117]\ttraining's multi_logloss: 0.917967\tvalid_1's multi_logloss: 1.03961\n",
      "[118]\ttraining's multi_logloss: 0.913677\tvalid_1's multi_logloss: 1.03592\n",
      "[119]\ttraining's multi_logloss: 0.909427\tvalid_1's multi_logloss: 1.03223\n",
      "[120]\ttraining's multi_logloss: 0.905203\tvalid_1's multi_logloss: 1.02856\n",
      "[121]\ttraining's multi_logloss: 0.901077\tvalid_1's multi_logloss: 1.02505\n",
      "[122]\ttraining's multi_logloss: 0.89692\tvalid_1's multi_logloss: 1.02142\n",
      "[123]\ttraining's multi_logloss: 0.892858\tvalid_1's multi_logloss: 1.01791\n",
      "[124]\ttraining's multi_logloss: 0.888836\tvalid_1's multi_logloss: 1.01449\n",
      "[125]\ttraining's multi_logloss: 0.884895\tvalid_1's multi_logloss: 1.01114\n",
      "[126]\ttraining's multi_logloss: 0.881023\tvalid_1's multi_logloss: 1.00782\n",
      "[127]\ttraining's multi_logloss: 0.877205\tvalid_1's multi_logloss: 1.00453\n",
      "[128]\ttraining's multi_logloss: 0.873425\tvalid_1's multi_logloss: 1.00134\n",
      "[129]\ttraining's multi_logloss: 0.869723\tvalid_1's multi_logloss: 0.998207\n",
      "[130]\ttraining's multi_logloss: 0.86605\tvalid_1's multi_logloss: 0.99508\n",
      "[131]\ttraining's multi_logloss: 0.862438\tvalid_1's multi_logloss: 0.992017\n",
      "[132]\ttraining's multi_logloss: 0.858866\tvalid_1's multi_logloss: 0.988977\n",
      "[133]\ttraining's multi_logloss: 0.855313\tvalid_1's multi_logloss: 0.985977\n",
      "[134]\ttraining's multi_logloss: 0.85181\tvalid_1's multi_logloss: 0.982981\n",
      "[135]\ttraining's multi_logloss: 0.848364\tvalid_1's multi_logloss: 0.980107\n",
      "[136]\ttraining's multi_logloss: 0.844985\tvalid_1's multi_logloss: 0.977266\n",
      "[137]\ttraining's multi_logloss: 0.841653\tvalid_1's multi_logloss: 0.974502\n",
      "[138]\ttraining's multi_logloss: 0.83834\tvalid_1's multi_logloss: 0.971739\n",
      "[139]\ttraining's multi_logloss: 0.835067\tvalid_1's multi_logloss: 0.968987\n",
      "[140]\ttraining's multi_logloss: 0.831826\tvalid_1's multi_logloss: 0.96626\n",
      "[141]\ttraining's multi_logloss: 0.828645\tvalid_1's multi_logloss: 0.963627\n",
      "[142]\ttraining's multi_logloss: 0.825471\tvalid_1's multi_logloss: 0.960965\n",
      "[143]\ttraining's multi_logloss: 0.822333\tvalid_1's multi_logloss: 0.958384\n",
      "[144]\ttraining's multi_logloss: 0.81926\tvalid_1's multi_logloss: 0.955875\n",
      "[145]\ttraining's multi_logloss: 0.816212\tvalid_1's multi_logloss: 0.953371\n",
      "[146]\ttraining's multi_logloss: 0.81322\tvalid_1's multi_logloss: 0.950938\n",
      "[147]\ttraining's multi_logloss: 0.810235\tvalid_1's multi_logloss: 0.948521\n",
      "[148]\ttraining's multi_logloss: 0.807298\tvalid_1's multi_logloss: 0.946132\n",
      "[149]\ttraining's multi_logloss: 0.80437\tvalid_1's multi_logloss: 0.943706\n",
      "[150]\ttraining's multi_logloss: 0.801543\tvalid_1's multi_logloss: 0.941425\n",
      "[151]\ttraining's multi_logloss: 0.79875\tvalid_1's multi_logloss: 0.939183\n",
      "[152]\ttraining's multi_logloss: 0.795969\tvalid_1's multi_logloss: 0.936939\n",
      "[153]\ttraining's multi_logloss: 0.793223\tvalid_1's multi_logloss: 0.934725\n",
      "[154]\ttraining's multi_logloss: 0.790496\tvalid_1's multi_logloss: 0.932546\n",
      "[155]\ttraining's multi_logloss: 0.787815\tvalid_1's multi_logloss: 0.930389\n",
      "[156]\ttraining's multi_logloss: 0.785176\tvalid_1's multi_logloss: 0.928237\n",
      "[157]\ttraining's multi_logloss: 0.782543\tvalid_1's multi_logloss: 0.92608\n",
      "[158]\ttraining's multi_logloss: 0.779952\tvalid_1's multi_logloss: 0.924016\n",
      "[159]\ttraining's multi_logloss: 0.777357\tvalid_1's multi_logloss: 0.921916\n",
      "[160]\ttraining's multi_logloss: 0.774848\tvalid_1's multi_logloss: 0.91991\n",
      "[161]\ttraining's multi_logloss: 0.772324\tvalid_1's multi_logloss: 0.917834\n",
      "[162]\ttraining's multi_logloss: 0.769841\tvalid_1's multi_logloss: 0.915837\n",
      "[163]\ttraining's multi_logloss: 0.767415\tvalid_1's multi_logloss: 0.913869\n",
      "[164]\ttraining's multi_logloss: 0.76498\tvalid_1's multi_logloss: 0.91194\n",
      "[165]\ttraining's multi_logloss: 0.762572\tvalid_1's multi_logloss: 0.909998\n",
      "[166]\ttraining's multi_logloss: 0.760186\tvalid_1's multi_logloss: 0.908094\n",
      "[167]\ttraining's multi_logloss: 0.757809\tvalid_1's multi_logloss: 0.906225\n",
      "[168]\ttraining's multi_logloss: 0.755464\tvalid_1's multi_logloss: 0.904358\n",
      "[169]\ttraining's multi_logloss: 0.753146\tvalid_1's multi_logloss: 0.902521\n",
      "[170]\ttraining's multi_logloss: 0.750888\tvalid_1's multi_logloss: 0.900777\n",
      "[171]\ttraining's multi_logloss: 0.748597\tvalid_1's multi_logloss: 0.898953\n",
      "[172]\ttraining's multi_logloss: 0.74637\tvalid_1's multi_logloss: 0.89724\n",
      "[173]\ttraining's multi_logloss: 0.744152\tvalid_1's multi_logloss: 0.895505\n",
      "[174]\ttraining's multi_logloss: 0.741934\tvalid_1's multi_logloss: 0.893798\n",
      "[175]\ttraining's multi_logloss: 0.73979\tvalid_1's multi_logloss: 0.892095\n",
      "[176]\ttraining's multi_logloss: 0.737668\tvalid_1's multi_logloss: 0.890419\n",
      "[177]\ttraining's multi_logloss: 0.735511\tvalid_1's multi_logloss: 0.888725\n",
      "[178]\ttraining's multi_logloss: 0.733383\tvalid_1's multi_logloss: 0.887076\n",
      "[179]\ttraining's multi_logloss: 0.731297\tvalid_1's multi_logloss: 0.885446\n",
      "[180]\ttraining's multi_logloss: 0.729197\tvalid_1's multi_logloss: 0.883884\n",
      "[181]\ttraining's multi_logloss: 0.727104\tvalid_1's multi_logloss: 0.88231\n",
      "[182]\ttraining's multi_logloss: 0.725046\tvalid_1's multi_logloss: 0.880723\n",
      "[183]\ttraining's multi_logloss: 0.723042\tvalid_1's multi_logloss: 0.879208\n",
      "[184]\ttraining's multi_logloss: 0.721008\tvalid_1's multi_logloss: 0.877611\n",
      "[185]\ttraining's multi_logloss: 0.719042\tvalid_1's multi_logloss: 0.876116\n",
      "[186]\ttraining's multi_logloss: 0.717098\tvalid_1's multi_logloss: 0.874647\n",
      "[187]\ttraining's multi_logloss: 0.715151\tvalid_1's multi_logloss: 0.873225\n",
      "[188]\ttraining's multi_logloss: 0.713222\tvalid_1's multi_logloss: 0.871791\n",
      "[189]\ttraining's multi_logloss: 0.711321\tvalid_1's multi_logloss: 0.870334\n",
      "[190]\ttraining's multi_logloss: 0.709417\tvalid_1's multi_logloss: 0.868907\n",
      "[191]\ttraining's multi_logloss: 0.707532\tvalid_1's multi_logloss: 0.867518\n",
      "[192]\ttraining's multi_logloss: 0.705685\tvalid_1's multi_logloss: 0.866156\n",
      "[193]\ttraining's multi_logloss: 0.703835\tvalid_1's multi_logloss: 0.8648\n",
      "[194]\ttraining's multi_logloss: 0.702012\tvalid_1's multi_logloss: 0.863461\n",
      "[195]\ttraining's multi_logloss: 0.700212\tvalid_1's multi_logloss: 0.862133\n",
      "[196]\ttraining's multi_logloss: 0.698441\tvalid_1's multi_logloss: 0.860845\n",
      "[197]\ttraining's multi_logloss: 0.696646\tvalid_1's multi_logloss: 0.859548\n",
      "[198]\ttraining's multi_logloss: 0.694897\tvalid_1's multi_logloss: 0.858273\n",
      "[199]\ttraining's multi_logloss: 0.693159\tvalid_1's multi_logloss: 0.857032\n",
      "[200]\ttraining's multi_logloss: 0.691437\tvalid_1's multi_logloss: 0.855747\n",
      "[201]\ttraining's multi_logloss: 0.689756\tvalid_1's multi_logloss: 0.854538\n",
      "[202]\ttraining's multi_logloss: 0.688056\tvalid_1's multi_logloss: 0.853323\n",
      "[203]\ttraining's multi_logloss: 0.686413\tvalid_1's multi_logloss: 0.852191\n",
      "[204]\ttraining's multi_logloss: 0.684773\tvalid_1's multi_logloss: 0.851028\n",
      "[205]\ttraining's multi_logloss: 0.683131\tvalid_1's multi_logloss: 0.849856\n",
      "[206]\ttraining's multi_logloss: 0.681507\tvalid_1's multi_logloss: 0.848678\n",
      "[207]\ttraining's multi_logloss: 0.67987\tvalid_1's multi_logloss: 0.847506\n",
      "[208]\ttraining's multi_logloss: 0.678284\tvalid_1's multi_logloss: 0.846371\n",
      "[209]\ttraining's multi_logloss: 0.676679\tvalid_1's multi_logloss: 0.84525\n",
      "[210]\ttraining's multi_logloss: 0.675103\tvalid_1's multi_logloss: 0.844166\n",
      "[211]\ttraining's multi_logloss: 0.673537\tvalid_1's multi_logloss: 0.843061\n",
      "[212]\ttraining's multi_logloss: 0.67198\tvalid_1's multi_logloss: 0.841971\n",
      "[213]\ttraining's multi_logloss: 0.670432\tvalid_1's multi_logloss: 0.840856\n",
      "[214]\ttraining's multi_logloss: 0.668924\tvalid_1's multi_logloss: 0.839825\n",
      "[215]\ttraining's multi_logloss: 0.667404\tvalid_1's multi_logloss: 0.838752\n",
      "[216]\ttraining's multi_logloss: 0.665954\tvalid_1's multi_logloss: 0.837793\n",
      "[217]\ttraining's multi_logloss: 0.664472\tvalid_1's multi_logloss: 0.836813\n",
      "[218]\ttraining's multi_logloss: 0.662982\tvalid_1's multi_logloss: 0.835773\n",
      "[219]\ttraining's multi_logloss: 0.661529\tvalid_1's multi_logloss: 0.834779\n",
      "[220]\ttraining's multi_logloss: 0.660071\tvalid_1's multi_logloss: 0.833802\n",
      "[221]\ttraining's multi_logloss: 0.658646\tvalid_1's multi_logloss: 0.832856\n",
      "[222]\ttraining's multi_logloss: 0.65722\tvalid_1's multi_logloss: 0.831865\n",
      "[223]\ttraining's multi_logloss: 0.655793\tvalid_1's multi_logloss: 0.830926\n",
      "[224]\ttraining's multi_logloss: 0.654389\tvalid_1's multi_logloss: 0.829995\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[225]\ttraining's multi_logloss: 0.653006\tvalid_1's multi_logloss: 0.829046\n",
      "[226]\ttraining's multi_logloss: 0.65157\tvalid_1's multi_logloss: 0.82812\n",
      "[227]\ttraining's multi_logloss: 0.650212\tvalid_1's multi_logloss: 0.827244\n",
      "[228]\ttraining's multi_logloss: 0.648855\tvalid_1's multi_logloss: 0.826345\n",
      "[229]\ttraining's multi_logloss: 0.647476\tvalid_1's multi_logloss: 0.825468\n",
      "[230]\ttraining's multi_logloss: 0.646139\tvalid_1's multi_logloss: 0.824593\n",
      "[231]\ttraining's multi_logloss: 0.644817\tvalid_1's multi_logloss: 0.823711\n",
      "[232]\ttraining's multi_logloss: 0.643461\tvalid_1's multi_logloss: 0.822833\n",
      "[233]\ttraining's multi_logloss: 0.642159\tvalid_1's multi_logloss: 0.821982\n",
      "[234]\ttraining's multi_logloss: 0.640842\tvalid_1's multi_logloss: 0.821142\n",
      "[235]\ttraining's multi_logloss: 0.639525\tvalid_1's multi_logloss: 0.820283\n",
      "[236]\ttraining's multi_logloss: 0.638223\tvalid_1's multi_logloss: 0.819483\n",
      "[237]\ttraining's multi_logloss: 0.636941\tvalid_1's multi_logloss: 0.818695\n",
      "[238]\ttraining's multi_logloss: 0.635691\tvalid_1's multi_logloss: 0.817887\n",
      "[239]\ttraining's multi_logloss: 0.634397\tvalid_1's multi_logloss: 0.81709\n",
      "[240]\ttraining's multi_logloss: 0.633163\tvalid_1's multi_logloss: 0.816315\n",
      "[241]\ttraining's multi_logloss: 0.631905\tvalid_1's multi_logloss: 0.815559\n",
      "[242]\ttraining's multi_logloss: 0.630668\tvalid_1's multi_logloss: 0.814771\n",
      "[243]\ttraining's multi_logloss: 0.629425\tvalid_1's multi_logloss: 0.814053\n",
      "[244]\ttraining's multi_logloss: 0.628197\tvalid_1's multi_logloss: 0.813296\n",
      "[245]\ttraining's multi_logloss: 0.626994\tvalid_1's multi_logloss: 0.812568\n",
      "[246]\ttraining's multi_logloss: 0.62577\tvalid_1's multi_logloss: 0.811833\n",
      "[247]\ttraining's multi_logloss: 0.624549\tvalid_1's multi_logloss: 0.811093\n",
      "[248]\ttraining's multi_logloss: 0.623352\tvalid_1's multi_logloss: 0.810359\n",
      "[249]\ttraining's multi_logloss: 0.622179\tvalid_1's multi_logloss: 0.80964\n",
      "[250]\ttraining's multi_logloss: 0.621005\tvalid_1's multi_logloss: 0.808953\n",
      "[251]\ttraining's multi_logloss: 0.61983\tvalid_1's multi_logloss: 0.808207\n",
      "[252]\ttraining's multi_logloss: 0.618654\tvalid_1's multi_logloss: 0.807514\n",
      "[253]\ttraining's multi_logloss: 0.617517\tvalid_1's multi_logloss: 0.806858\n",
      "[254]\ttraining's multi_logloss: 0.616371\tvalid_1's multi_logloss: 0.806227\n",
      "[255]\ttraining's multi_logloss: 0.615238\tvalid_1's multi_logloss: 0.805569\n",
      "[256]\ttraining's multi_logloss: 0.614104\tvalid_1's multi_logloss: 0.804867\n",
      "[257]\ttraining's multi_logloss: 0.612986\tvalid_1's multi_logloss: 0.804231\n",
      "[258]\ttraining's multi_logloss: 0.611882\tvalid_1's multi_logloss: 0.803564\n",
      "[259]\ttraining's multi_logloss: 0.610772\tvalid_1's multi_logloss: 0.80294\n",
      "[260]\ttraining's multi_logloss: 0.609663\tvalid_1's multi_logloss: 0.802286\n",
      "[261]\ttraining's multi_logloss: 0.608572\tvalid_1's multi_logloss: 0.801635\n",
      "[262]\ttraining's multi_logloss: 0.607482\tvalid_1's multi_logloss: 0.801024\n",
      "[263]\ttraining's multi_logloss: 0.606392\tvalid_1's multi_logloss: 0.800398\n",
      "[264]\ttraining's multi_logloss: 0.605337\tvalid_1's multi_logloss: 0.799804\n",
      "[265]\ttraining's multi_logloss: 0.604272\tvalid_1's multi_logloss: 0.7992\n",
      "[266]\ttraining's multi_logloss: 0.603215\tvalid_1's multi_logloss: 0.798602\n",
      "[267]\ttraining's multi_logloss: 0.602162\tvalid_1's multi_logloss: 0.797998\n",
      "[268]\ttraining's multi_logloss: 0.601124\tvalid_1's multi_logloss: 0.797427\n",
      "[269]\ttraining's multi_logloss: 0.600077\tvalid_1's multi_logloss: 0.79683\n",
      "[270]\ttraining's multi_logloss: 0.599066\tvalid_1's multi_logloss: 0.796282\n",
      "[271]\ttraining's multi_logloss: 0.598044\tvalid_1's multi_logloss: 0.795768\n",
      "[272]\ttraining's multi_logloss: 0.597019\tvalid_1's multi_logloss: 0.795176\n",
      "[273]\ttraining's multi_logloss: 0.596012\tvalid_1's multi_logloss: 0.794635\n",
      "[274]\ttraining's multi_logloss: 0.594992\tvalid_1's multi_logloss: 0.794108\n",
      "[275]\ttraining's multi_logloss: 0.594\tvalid_1's multi_logloss: 0.793561\n",
      "[276]\ttraining's multi_logloss: 0.592988\tvalid_1's multi_logloss: 0.793005\n",
      "[277]\ttraining's multi_logloss: 0.592005\tvalid_1's multi_logloss: 0.79249\n",
      "[278]\ttraining's multi_logloss: 0.591031\tvalid_1's multi_logloss: 0.791998\n",
      "[279]\ttraining's multi_logloss: 0.590029\tvalid_1's multi_logloss: 0.791492\n",
      "[280]\ttraining's multi_logloss: 0.589038\tvalid_1's multi_logloss: 0.790972\n",
      "[281]\ttraining's multi_logloss: 0.588055\tvalid_1's multi_logloss: 0.790454\n",
      "[282]\ttraining's multi_logloss: 0.587071\tvalid_1's multi_logloss: 0.789913\n",
      "[283]\ttraining's multi_logloss: 0.586129\tvalid_1's multi_logloss: 0.789413\n",
      "[284]\ttraining's multi_logloss: 0.585161\tvalid_1's multi_logloss: 0.788898\n",
      "[285]\ttraining's multi_logloss: 0.584187\tvalid_1's multi_logloss: 0.788377\n",
      "[286]\ttraining's multi_logloss: 0.58324\tvalid_1's multi_logloss: 0.787909\n",
      "[287]\ttraining's multi_logloss: 0.582275\tvalid_1's multi_logloss: 0.787421\n",
      "[288]\ttraining's multi_logloss: 0.581328\tvalid_1's multi_logloss: 0.786896\n",
      "[289]\ttraining's multi_logloss: 0.580394\tvalid_1's multi_logloss: 0.786393\n",
      "[290]\ttraining's multi_logloss: 0.579439\tvalid_1's multi_logloss: 0.785915\n",
      "[291]\ttraining's multi_logloss: 0.578505\tvalid_1's multi_logloss: 0.785432\n",
      "[292]\ttraining's multi_logloss: 0.577597\tvalid_1's multi_logloss: 0.784984\n",
      "[293]\ttraining's multi_logloss: 0.576671\tvalid_1's multi_logloss: 0.784514\n",
      "[294]\ttraining's multi_logloss: 0.575775\tvalid_1's multi_logloss: 0.784084\n",
      "[295]\ttraining's multi_logloss: 0.574857\tvalid_1's multi_logloss: 0.783614\n",
      "[296]\ttraining's multi_logloss: 0.573956\tvalid_1's multi_logloss: 0.78319\n",
      "[297]\ttraining's multi_logloss: 0.573065\tvalid_1's multi_logloss: 0.782756\n",
      "[298]\ttraining's multi_logloss: 0.572195\tvalid_1's multi_logloss: 0.782328\n",
      "[299]\ttraining's multi_logloss: 0.571296\tvalid_1's multi_logloss: 0.781876\n",
      "[300]\ttraining's multi_logloss: 0.570418\tvalid_1's multi_logloss: 0.781436\n",
      "[301]\ttraining's multi_logloss: 0.56953\tvalid_1's multi_logloss: 0.781003\n",
      "[302]\ttraining's multi_logloss: 0.568652\tvalid_1's multi_logloss: 0.780557\n",
      "[303]\ttraining's multi_logloss: 0.567799\tvalid_1's multi_logloss: 0.780154\n",
      "[304]\ttraining's multi_logloss: 0.56693\tvalid_1's multi_logloss: 0.779725\n",
      "[305]\ttraining's multi_logloss: 0.56608\tvalid_1's multi_logloss: 0.779311\n",
      "[306]\ttraining's multi_logloss: 0.565221\tvalid_1's multi_logloss: 0.778936\n",
      "[307]\ttraining's multi_logloss: 0.564356\tvalid_1's multi_logloss: 0.778534\n",
      "[308]\ttraining's multi_logloss: 0.563495\tvalid_1's multi_logloss: 0.778138\n",
      "[309]\ttraining's multi_logloss: 0.562649\tvalid_1's multi_logloss: 0.777737\n",
      "[310]\ttraining's multi_logloss: 0.561803\tvalid_1's multi_logloss: 0.777323\n",
      "[311]\ttraining's multi_logloss: 0.560965\tvalid_1's multi_logloss: 0.776916\n",
      "[312]\ttraining's multi_logloss: 0.560147\tvalid_1's multi_logloss: 0.776564\n",
      "[313]\ttraining's multi_logloss: 0.559337\tvalid_1's multi_logloss: 0.776176\n",
      "[314]\ttraining's multi_logloss: 0.558512\tvalid_1's multi_logloss: 0.775837\n",
      "[315]\ttraining's multi_logloss: 0.557701\tvalid_1's multi_logloss: 0.775443\n",
      "[316]\ttraining's multi_logloss: 0.556913\tvalid_1's multi_logloss: 0.775088\n",
      "[317]\ttraining's multi_logloss: 0.556105\tvalid_1's multi_logloss: 0.774717\n",
      "[318]\ttraining's multi_logloss: 0.555279\tvalid_1's multi_logloss: 0.774339\n",
      "[319]\ttraining's multi_logloss: 0.554489\tvalid_1's multi_logloss: 0.773965\n",
      "[320]\ttraining's multi_logloss: 0.553674\tvalid_1's multi_logloss: 0.773605\n",
      "[321]\ttraining's multi_logloss: 0.552877\tvalid_1's multi_logloss: 0.773268\n",
      "[322]\ttraining's multi_logloss: 0.552077\tvalid_1's multi_logloss: 0.7729\n",
      "[323]\ttraining's multi_logloss: 0.551289\tvalid_1's multi_logloss: 0.772566\n",
      "[324]\ttraining's multi_logloss: 0.550475\tvalid_1's multi_logloss: 0.772213\n",
      "[325]\ttraining's multi_logloss: 0.549698\tvalid_1's multi_logloss: 0.77186\n",
      "[326]\ttraining's multi_logloss: 0.548923\tvalid_1's multi_logloss: 0.771555\n",
      "[327]\ttraining's multi_logloss: 0.548135\tvalid_1's multi_logloss: 0.771206\n",
      "[328]\ttraining's multi_logloss: 0.547335\tvalid_1's multi_logloss: 0.770873\n",
      "[329]\ttraining's multi_logloss: 0.546563\tvalid_1's multi_logloss: 0.770546\n",
      "[330]\ttraining's multi_logloss: 0.545783\tvalid_1's multi_logloss: 0.770204\n",
      "[331]\ttraining's multi_logloss: 0.545017\tvalid_1's multi_logloss: 0.769882\n",
      "[332]\ttraining's multi_logloss: 0.544262\tvalid_1's multi_logloss: 0.769579\n",
      "[333]\ttraining's multi_logloss: 0.543501\tvalid_1's multi_logloss: 0.7693\n",
      "[334]\ttraining's multi_logloss: 0.542737\tvalid_1's multi_logloss: 0.768991\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[335]\ttraining's multi_logloss: 0.541983\tvalid_1's multi_logloss: 0.768676\n",
      "[336]\ttraining's multi_logloss: 0.541244\tvalid_1's multi_logloss: 0.768369\n",
      "[337]\ttraining's multi_logloss: 0.540494\tvalid_1's multi_logloss: 0.76806\n",
      "[338]\ttraining's multi_logloss: 0.539741\tvalid_1's multi_logloss: 0.767736\n",
      "[339]\ttraining's multi_logloss: 0.538999\tvalid_1's multi_logloss: 0.767447\n",
      "[340]\ttraining's multi_logloss: 0.538281\tvalid_1's multi_logloss: 0.767163\n",
      "[341]\ttraining's multi_logloss: 0.537538\tvalid_1's multi_logloss: 0.766869\n",
      "[342]\ttraining's multi_logloss: 0.536804\tvalid_1's multi_logloss: 0.766578\n",
      "[343]\ttraining's multi_logloss: 0.536062\tvalid_1's multi_logloss: 0.766254\n",
      "[344]\ttraining's multi_logloss: 0.535361\tvalid_1's multi_logloss: 0.765968\n",
      "[345]\ttraining's multi_logloss: 0.534637\tvalid_1's multi_logloss: 0.7657\n",
      "[346]\ttraining's multi_logloss: 0.533927\tvalid_1's multi_logloss: 0.76542\n",
      "[347]\ttraining's multi_logloss: 0.533224\tvalid_1's multi_logloss: 0.765119\n",
      "[348]\ttraining's multi_logloss: 0.532523\tvalid_1's multi_logloss: 0.764865\n",
      "[349]\ttraining's multi_logloss: 0.531817\tvalid_1's multi_logloss: 0.764561\n",
      "[350]\ttraining's multi_logloss: 0.531112\tvalid_1's multi_logloss: 0.764294\n",
      "[351]\ttraining's multi_logloss: 0.530386\tvalid_1's multi_logloss: 0.763997\n",
      "[352]\ttraining's multi_logloss: 0.529691\tvalid_1's multi_logloss: 0.763729\n",
      "[353]\ttraining's multi_logloss: 0.528958\tvalid_1's multi_logloss: 0.763449\n",
      "[354]\ttraining's multi_logloss: 0.528249\tvalid_1's multi_logloss: 0.763195\n",
      "[355]\ttraining's multi_logloss: 0.52757\tvalid_1's multi_logloss: 0.762905\n",
      "[356]\ttraining's multi_logloss: 0.526888\tvalid_1's multi_logloss: 0.762665\n",
      "[357]\ttraining's multi_logloss: 0.526158\tvalid_1's multi_logloss: 0.762377\n",
      "[358]\ttraining's multi_logloss: 0.525445\tvalid_1's multi_logloss: 0.76211\n",
      "[359]\ttraining's multi_logloss: 0.524742\tvalid_1's multi_logloss: 0.761843\n",
      "[360]\ttraining's multi_logloss: 0.524068\tvalid_1's multi_logloss: 0.761586\n",
      "[361]\ttraining's multi_logloss: 0.523367\tvalid_1's multi_logloss: 0.761353\n",
      "[362]\ttraining's multi_logloss: 0.522684\tvalid_1's multi_logloss: 0.761099\n",
      "[363]\ttraining's multi_logloss: 0.521997\tvalid_1's multi_logloss: 0.760839\n",
      "[364]\ttraining's multi_logloss: 0.521325\tvalid_1's multi_logloss: 0.760588\n",
      "[365]\ttraining's multi_logloss: 0.520634\tvalid_1's multi_logloss: 0.760351\n",
      "[366]\ttraining's multi_logloss: 0.51996\tvalid_1's multi_logloss: 0.760096\n",
      "[367]\ttraining's multi_logloss: 0.519282\tvalid_1's multi_logloss: 0.759878\n",
      "[368]\ttraining's multi_logloss: 0.518592\tvalid_1's multi_logloss: 0.759631\n",
      "[369]\ttraining's multi_logloss: 0.517929\tvalid_1's multi_logloss: 0.759391\n",
      "[370]\ttraining's multi_logloss: 0.517254\tvalid_1's multi_logloss: 0.75913\n",
      "[371]\ttraining's multi_logloss: 0.516595\tvalid_1's multi_logloss: 0.758887\n",
      "[372]\ttraining's multi_logloss: 0.515907\tvalid_1's multi_logloss: 0.758659\n",
      "[373]\ttraining's multi_logloss: 0.515255\tvalid_1's multi_logloss: 0.758421\n",
      "[374]\ttraining's multi_logloss: 0.514599\tvalid_1's multi_logloss: 0.758194\n",
      "[375]\ttraining's multi_logloss: 0.513945\tvalid_1's multi_logloss: 0.757967\n",
      "[376]\ttraining's multi_logloss: 0.513285\tvalid_1's multi_logloss: 0.757722\n",
      "[377]\ttraining's multi_logloss: 0.512645\tvalid_1's multi_logloss: 0.757503\n",
      "[378]\ttraining's multi_logloss: 0.512\tvalid_1's multi_logloss: 0.75728\n",
      "[379]\ttraining's multi_logloss: 0.511356\tvalid_1's multi_logloss: 0.757028\n",
      "[380]\ttraining's multi_logloss: 0.510714\tvalid_1's multi_logloss: 0.756849\n",
      "[381]\ttraining's multi_logloss: 0.510081\tvalid_1's multi_logloss: 0.756616\n",
      "[382]\ttraining's multi_logloss: 0.509428\tvalid_1's multi_logloss: 0.756392\n",
      "[383]\ttraining's multi_logloss: 0.508797\tvalid_1's multi_logloss: 0.756172\n",
      "[384]\ttraining's multi_logloss: 0.508131\tvalid_1's multi_logloss: 0.755943\n",
      "[385]\ttraining's multi_logloss: 0.507496\tvalid_1's multi_logloss: 0.755725\n",
      "[386]\ttraining's multi_logloss: 0.506868\tvalid_1's multi_logloss: 0.755501\n",
      "[387]\ttraining's multi_logloss: 0.506241\tvalid_1's multi_logloss: 0.755292\n",
      "[388]\ttraining's multi_logloss: 0.505611\tvalid_1's multi_logloss: 0.755084\n",
      "[389]\ttraining's multi_logloss: 0.504985\tvalid_1's multi_logloss: 0.75488\n",
      "[390]\ttraining's multi_logloss: 0.504366\tvalid_1's multi_logloss: 0.75469\n",
      "[391]\ttraining's multi_logloss: 0.503743\tvalid_1's multi_logloss: 0.754454\n",
      "[392]\ttraining's multi_logloss: 0.50312\tvalid_1's multi_logloss: 0.754216\n",
      "[393]\ttraining's multi_logloss: 0.502515\tvalid_1's multi_logloss: 0.754011\n",
      "[394]\ttraining's multi_logloss: 0.501897\tvalid_1's multi_logloss: 0.753812\n",
      "[395]\ttraining's multi_logloss: 0.501286\tvalid_1's multi_logloss: 0.75358\n",
      "[396]\ttraining's multi_logloss: 0.500691\tvalid_1's multi_logloss: 0.75339\n",
      "[397]\ttraining's multi_logloss: 0.500085\tvalid_1's multi_logloss: 0.753205\n",
      "[398]\ttraining's multi_logloss: 0.499486\tvalid_1's multi_logloss: 0.752987\n",
      "[399]\ttraining's multi_logloss: 0.498885\tvalid_1's multi_logloss: 0.752787\n",
      "[400]\ttraining's multi_logloss: 0.498273\tvalid_1's multi_logloss: 0.752617\n",
      "[401]\ttraining's multi_logloss: 0.49767\tvalid_1's multi_logloss: 0.752418\n",
      "[402]\ttraining's multi_logloss: 0.497064\tvalid_1's multi_logloss: 0.752258\n",
      "[403]\ttraining's multi_logloss: 0.496463\tvalid_1's multi_logloss: 0.752053\n",
      "[404]\ttraining's multi_logloss: 0.495862\tvalid_1's multi_logloss: 0.75188\n",
      "[405]\ttraining's multi_logloss: 0.495252\tvalid_1's multi_logloss: 0.751677\n",
      "[406]\ttraining's multi_logloss: 0.494677\tvalid_1's multi_logloss: 0.751487\n",
      "[407]\ttraining's multi_logloss: 0.494082\tvalid_1's multi_logloss: 0.751302\n",
      "[408]\ttraining's multi_logloss: 0.493464\tvalid_1's multi_logloss: 0.75117\n",
      "[409]\ttraining's multi_logloss: 0.492872\tvalid_1's multi_logloss: 0.750975\n",
      "[410]\ttraining's multi_logloss: 0.492278\tvalid_1's multi_logloss: 0.75077\n",
      "[411]\ttraining's multi_logloss: 0.491701\tvalid_1's multi_logloss: 0.750574\n",
      "[412]\ttraining's multi_logloss: 0.491108\tvalid_1's multi_logloss: 0.750402\n",
      "[413]\ttraining's multi_logloss: 0.490513\tvalid_1's multi_logloss: 0.750263\n",
      "[414]\ttraining's multi_logloss: 0.489937\tvalid_1's multi_logloss: 0.75007\n",
      "[415]\ttraining's multi_logloss: 0.489365\tvalid_1's multi_logloss: 0.749918\n",
      "[416]\ttraining's multi_logloss: 0.488796\tvalid_1's multi_logloss: 0.749756\n",
      "[417]\ttraining's multi_logloss: 0.488217\tvalid_1's multi_logloss: 0.749555\n",
      "[418]\ttraining's multi_logloss: 0.487653\tvalid_1's multi_logloss: 0.749393\n",
      "[419]\ttraining's multi_logloss: 0.487085\tvalid_1's multi_logloss: 0.74923\n",
      "[420]\ttraining's multi_logloss: 0.486516\tvalid_1's multi_logloss: 0.749051\n",
      "[421]\ttraining's multi_logloss: 0.485944\tvalid_1's multi_logloss: 0.74886\n",
      "[422]\ttraining's multi_logloss: 0.485385\tvalid_1's multi_logloss: 0.748684\n",
      "[423]\ttraining's multi_logloss: 0.484803\tvalid_1's multi_logloss: 0.748526\n",
      "[424]\ttraining's multi_logloss: 0.484253\tvalid_1's multi_logloss: 0.74837\n",
      "[425]\ttraining's multi_logloss: 0.483682\tvalid_1's multi_logloss: 0.748178\n",
      "[426]\ttraining's multi_logloss: 0.483116\tvalid_1's multi_logloss: 0.748011\n",
      "[427]\ttraining's multi_logloss: 0.482561\tvalid_1's multi_logloss: 0.747878\n",
      "[428]\ttraining's multi_logloss: 0.481999\tvalid_1's multi_logloss: 0.74773\n",
      "[429]\ttraining's multi_logloss: 0.48145\tvalid_1's multi_logloss: 0.747579\n",
      "[430]\ttraining's multi_logloss: 0.480889\tvalid_1's multi_logloss: 0.74744\n",
      "[431]\ttraining's multi_logloss: 0.480328\tvalid_1's multi_logloss: 0.747287\n",
      "[432]\ttraining's multi_logloss: 0.479793\tvalid_1's multi_logloss: 0.747144\n",
      "[433]\ttraining's multi_logloss: 0.479245\tvalid_1's multi_logloss: 0.747009\n",
      "[434]\ttraining's multi_logloss: 0.478707\tvalid_1's multi_logloss: 0.746874\n",
      "[435]\ttraining's multi_logloss: 0.478157\tvalid_1's multi_logloss: 0.746704\n",
      "[436]\ttraining's multi_logloss: 0.477627\tvalid_1's multi_logloss: 0.746558\n",
      "[437]\ttraining's multi_logloss: 0.477083\tvalid_1's multi_logloss: 0.746399\n",
      "[438]\ttraining's multi_logloss: 0.476532\tvalid_1's multi_logloss: 0.746252\n",
      "[439]\ttraining's multi_logloss: 0.476003\tvalid_1's multi_logloss: 0.746122\n",
      "[440]\ttraining's multi_logloss: 0.475455\tvalid_1's multi_logloss: 0.745984\n",
      "[441]\ttraining's multi_logloss: 0.474925\tvalid_1's multi_logloss: 0.745839\n",
      "[442]\ttraining's multi_logloss: 0.47438\tvalid_1's multi_logloss: 0.745697\n",
      "[443]\ttraining's multi_logloss: 0.473846\tvalid_1's multi_logloss: 0.74556\n",
      "[444]\ttraining's multi_logloss: 0.473314\tvalid_1's multi_logloss: 0.74539\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[445]\ttraining's multi_logloss: 0.472773\tvalid_1's multi_logloss: 0.745248\n",
      "[446]\ttraining's multi_logloss: 0.472243\tvalid_1's multi_logloss: 0.745115\n",
      "[447]\ttraining's multi_logloss: 0.471713\tvalid_1's multi_logloss: 0.744971\n",
      "[448]\ttraining's multi_logloss: 0.471193\tvalid_1's multi_logloss: 0.744854\n",
      "[449]\ttraining's multi_logloss: 0.470652\tvalid_1's multi_logloss: 0.74474\n",
      "[450]\ttraining's multi_logloss: 0.470118\tvalid_1's multi_logloss: 0.744586\n",
      "[451]\ttraining's multi_logloss: 0.469574\tvalid_1's multi_logloss: 0.744457\n",
      "[452]\ttraining's multi_logloss: 0.469038\tvalid_1's multi_logloss: 0.7443\n",
      "[453]\ttraining's multi_logloss: 0.468514\tvalid_1's multi_logloss: 0.744153\n",
      "[454]\ttraining's multi_logloss: 0.46801\tvalid_1's multi_logloss: 0.744028\n",
      "[455]\ttraining's multi_logloss: 0.467487\tvalid_1's multi_logloss: 0.743877\n",
      "[456]\ttraining's multi_logloss: 0.466961\tvalid_1's multi_logloss: 0.743744\n",
      "[457]\ttraining's multi_logloss: 0.466443\tvalid_1's multi_logloss: 0.743617\n",
      "[458]\ttraining's multi_logloss: 0.465927\tvalid_1's multi_logloss: 0.743453\n",
      "[459]\ttraining's multi_logloss: 0.465409\tvalid_1's multi_logloss: 0.743326\n",
      "[460]\ttraining's multi_logloss: 0.464908\tvalid_1's multi_logloss: 0.743186\n",
      "[461]\ttraining's multi_logloss: 0.464402\tvalid_1's multi_logloss: 0.743068\n",
      "[462]\ttraining's multi_logloss: 0.463882\tvalid_1's multi_logloss: 0.742912\n",
      "[463]\ttraining's multi_logloss: 0.46337\tvalid_1's multi_logloss: 0.742797\n",
      "[464]\ttraining's multi_logloss: 0.46287\tvalid_1's multi_logloss: 0.74264\n",
      "[465]\ttraining's multi_logloss: 0.462365\tvalid_1's multi_logloss: 0.742525\n",
      "[466]\ttraining's multi_logloss: 0.46187\tvalid_1's multi_logloss: 0.742437\n",
      "[467]\ttraining's multi_logloss: 0.461388\tvalid_1's multi_logloss: 0.742336\n",
      "[468]\ttraining's multi_logloss: 0.460878\tvalid_1's multi_logloss: 0.742194\n",
      "[469]\ttraining's multi_logloss: 0.460378\tvalid_1's multi_logloss: 0.742033\n",
      "[470]\ttraining's multi_logloss: 0.459884\tvalid_1's multi_logloss: 0.741891\n",
      "[471]\ttraining's multi_logloss: 0.45938\tvalid_1's multi_logloss: 0.741761\n",
      "[472]\ttraining's multi_logloss: 0.458882\tvalid_1's multi_logloss: 0.74163\n",
      "[473]\ttraining's multi_logloss: 0.4584\tvalid_1's multi_logloss: 0.741523\n",
      "[474]\ttraining's multi_logloss: 0.457905\tvalid_1's multi_logloss: 0.741402\n",
      "[475]\ttraining's multi_logloss: 0.457427\tvalid_1's multi_logloss: 0.74131\n",
      "[476]\ttraining's multi_logloss: 0.456937\tvalid_1's multi_logloss: 0.741178\n",
      "[477]\ttraining's multi_logloss: 0.456462\tvalid_1's multi_logloss: 0.741099\n",
      "[478]\ttraining's multi_logloss: 0.455973\tvalid_1's multi_logloss: 0.740978\n",
      "[479]\ttraining's multi_logloss: 0.455493\tvalid_1's multi_logloss: 0.740875\n",
      "[480]\ttraining's multi_logloss: 0.455014\tvalid_1's multi_logloss: 0.740746\n",
      "[481]\ttraining's multi_logloss: 0.454551\tvalid_1's multi_logloss: 0.740643\n",
      "[482]\ttraining's multi_logloss: 0.454056\tvalid_1's multi_logloss: 0.7405\n",
      "[483]\ttraining's multi_logloss: 0.453574\tvalid_1's multi_logloss: 0.740413\n",
      "[484]\ttraining's multi_logloss: 0.453102\tvalid_1's multi_logloss: 0.740305\n",
      "[485]\ttraining's multi_logloss: 0.452617\tvalid_1's multi_logloss: 0.740206\n",
      "[486]\ttraining's multi_logloss: 0.452151\tvalid_1's multi_logloss: 0.740109\n",
      "[487]\ttraining's multi_logloss: 0.451668\tvalid_1's multi_logloss: 0.740011\n",
      "[488]\ttraining's multi_logloss: 0.451189\tvalid_1's multi_logloss: 0.739911\n",
      "[489]\ttraining's multi_logloss: 0.450708\tvalid_1's multi_logloss: 0.739794\n",
      "[490]\ttraining's multi_logloss: 0.450248\tvalid_1's multi_logloss: 0.739719\n",
      "[491]\ttraining's multi_logloss: 0.449772\tvalid_1's multi_logloss: 0.739603\n",
      "[492]\ttraining's multi_logloss: 0.449295\tvalid_1's multi_logloss: 0.739539\n",
      "[493]\ttraining's multi_logloss: 0.448828\tvalid_1's multi_logloss: 0.739431\n",
      "[494]\ttraining's multi_logloss: 0.448373\tvalid_1's multi_logloss: 0.739334\n",
      "[495]\ttraining's multi_logloss: 0.447921\tvalid_1's multi_logloss: 0.739243\n",
      "[496]\ttraining's multi_logloss: 0.447449\tvalid_1's multi_logloss: 0.739122\n",
      "[497]\ttraining's multi_logloss: 0.446987\tvalid_1's multi_logloss: 0.739024\n",
      "[498]\ttraining's multi_logloss: 0.44653\tvalid_1's multi_logloss: 0.738926\n",
      "[499]\ttraining's multi_logloss: 0.446087\tvalid_1's multi_logloss: 0.738835\n",
      "[500]\ttraining's multi_logloss: 0.445612\tvalid_1's multi_logloss: 0.738737\n",
      "[501]\ttraining's multi_logloss: 0.445164\tvalid_1's multi_logloss: 0.738626\n",
      "[502]\ttraining's multi_logloss: 0.444703\tvalid_1's multi_logloss: 0.738552\n",
      "[503]\ttraining's multi_logloss: 0.444259\tvalid_1's multi_logloss: 0.738454\n",
      "[504]\ttraining's multi_logloss: 0.443805\tvalid_1's multi_logloss: 0.738359\n",
      "[505]\ttraining's multi_logloss: 0.443353\tvalid_1's multi_logloss: 0.738251\n",
      "[506]\ttraining's multi_logloss: 0.4429\tvalid_1's multi_logloss: 0.738128\n",
      "[507]\ttraining's multi_logloss: 0.442445\tvalid_1's multi_logloss: 0.738002\n",
      "[508]\ttraining's multi_logloss: 0.441974\tvalid_1's multi_logloss: 0.737924\n",
      "[509]\ttraining's multi_logloss: 0.441504\tvalid_1's multi_logloss: 0.737838\n",
      "[510]\ttraining's multi_logloss: 0.441053\tvalid_1's multi_logloss: 0.737738\n",
      "[511]\ttraining's multi_logloss: 0.440608\tvalid_1's multi_logloss: 0.737632\n",
      "[512]\ttraining's multi_logloss: 0.440155\tvalid_1's multi_logloss: 0.737569\n",
      "[513]\ttraining's multi_logloss: 0.439712\tvalid_1's multi_logloss: 0.73749\n",
      "[514]\ttraining's multi_logloss: 0.439262\tvalid_1's multi_logloss: 0.737386\n",
      "[515]\ttraining's multi_logloss: 0.438817\tvalid_1's multi_logloss: 0.737268\n",
      "[516]\ttraining's multi_logloss: 0.438385\tvalid_1's multi_logloss: 0.737188\n",
      "[517]\ttraining's multi_logloss: 0.437934\tvalid_1's multi_logloss: 0.73708\n",
      "[518]\ttraining's multi_logloss: 0.437477\tvalid_1's multi_logloss: 0.736972\n",
      "[519]\ttraining's multi_logloss: 0.437049\tvalid_1's multi_logloss: 0.736898\n",
      "[520]\ttraining's multi_logloss: 0.4366\tvalid_1's multi_logloss: 0.736815\n",
      "[521]\ttraining's multi_logloss: 0.436151\tvalid_1's multi_logloss: 0.736703\n",
      "[522]\ttraining's multi_logloss: 0.435727\tvalid_1's multi_logloss: 0.736602\n",
      "[523]\ttraining's multi_logloss: 0.43528\tvalid_1's multi_logloss: 0.736507\n",
      "[524]\ttraining's multi_logloss: 0.434858\tvalid_1's multi_logloss: 0.736392\n",
      "[525]\ttraining's multi_logloss: 0.434421\tvalid_1's multi_logloss: 0.736293\n",
      "[526]\ttraining's multi_logloss: 0.433997\tvalid_1's multi_logloss: 0.736216\n",
      "[527]\ttraining's multi_logloss: 0.433544\tvalid_1's multi_logloss: 0.73612\n",
      "[528]\ttraining's multi_logloss: 0.433121\tvalid_1's multi_logloss: 0.73603\n",
      "[529]\ttraining's multi_logloss: 0.432669\tvalid_1's multi_logloss: 0.73595\n",
      "[530]\ttraining's multi_logloss: 0.432254\tvalid_1's multi_logloss: 0.735893\n",
      "[531]\ttraining's multi_logloss: 0.431827\tvalid_1's multi_logloss: 0.73582\n",
      "[532]\ttraining's multi_logloss: 0.431388\tvalid_1's multi_logloss: 0.735719\n",
      "[533]\ttraining's multi_logloss: 0.430956\tvalid_1's multi_logloss: 0.735608\n",
      "[534]\ttraining's multi_logloss: 0.430525\tvalid_1's multi_logloss: 0.735521\n",
      "[535]\ttraining's multi_logloss: 0.430099\tvalid_1's multi_logloss: 0.735415\n",
      "[536]\ttraining's multi_logloss: 0.429685\tvalid_1's multi_logloss: 0.735334\n",
      "[537]\ttraining's multi_logloss: 0.42926\tvalid_1's multi_logloss: 0.735227\n",
      "[538]\ttraining's multi_logloss: 0.428847\tvalid_1's multi_logloss: 0.735149\n",
      "[539]\ttraining's multi_logloss: 0.428411\tvalid_1's multi_logloss: 0.735094\n",
      "[540]\ttraining's multi_logloss: 0.427986\tvalid_1's multi_logloss: 0.734987\n",
      "[541]\ttraining's multi_logloss: 0.427565\tvalid_1's multi_logloss: 0.734897\n",
      "[542]\ttraining's multi_logloss: 0.427151\tvalid_1's multi_logloss: 0.734802\n",
      "[543]\ttraining's multi_logloss: 0.426722\tvalid_1's multi_logloss: 0.734703\n",
      "[544]\ttraining's multi_logloss: 0.426313\tvalid_1's multi_logloss: 0.734624\n",
      "[545]\ttraining's multi_logloss: 0.425904\tvalid_1's multi_logloss: 0.734561\n",
      "[546]\ttraining's multi_logloss: 0.42548\tvalid_1's multi_logloss: 0.734479\n",
      "[547]\ttraining's multi_logloss: 0.425077\tvalid_1's multi_logloss: 0.734387\n",
      "[548]\ttraining's multi_logloss: 0.424666\tvalid_1's multi_logloss: 0.734324\n",
      "[549]\ttraining's multi_logloss: 0.42424\tvalid_1's multi_logloss: 0.734222\n",
      "[550]\ttraining's multi_logloss: 0.423849\tvalid_1's multi_logloss: 0.734149\n",
      "[551]\ttraining's multi_logloss: 0.423446\tvalid_1's multi_logloss: 0.734064\n",
      "[552]\ttraining's multi_logloss: 0.423025\tvalid_1's multi_logloss: 0.73399\n",
      "[553]\ttraining's multi_logloss: 0.422603\tvalid_1's multi_logloss: 0.733892\n",
      "[554]\ttraining's multi_logloss: 0.422202\tvalid_1's multi_logloss: 0.7338\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[555]\ttraining's multi_logloss: 0.4218\tvalid_1's multi_logloss: 0.73373\n",
      "[556]\ttraining's multi_logloss: 0.421392\tvalid_1's multi_logloss: 0.73367\n",
      "[557]\ttraining's multi_logloss: 0.420976\tvalid_1's multi_logloss: 0.733597\n",
      "[558]\ttraining's multi_logloss: 0.420572\tvalid_1's multi_logloss: 0.733506\n",
      "[559]\ttraining's multi_logloss: 0.420169\tvalid_1's multi_logloss: 0.733443\n",
      "[560]\ttraining's multi_logloss: 0.419762\tvalid_1's multi_logloss: 0.733388\n",
      "[561]\ttraining's multi_logloss: 0.41935\tvalid_1's multi_logloss: 0.733331\n",
      "[562]\ttraining's multi_logloss: 0.418939\tvalid_1's multi_logloss: 0.733252\n",
      "[563]\ttraining's multi_logloss: 0.418533\tvalid_1's multi_logloss: 0.733175\n",
      "[564]\ttraining's multi_logloss: 0.418143\tvalid_1's multi_logloss: 0.733088\n",
      "[565]\ttraining's multi_logloss: 0.41774\tvalid_1's multi_logloss: 0.732991\n",
      "[566]\ttraining's multi_logloss: 0.417337\tvalid_1's multi_logloss: 0.732933\n",
      "[567]\ttraining's multi_logloss: 0.416934\tvalid_1's multi_logloss: 0.732841\n",
      "[568]\ttraining's multi_logloss: 0.41653\tvalid_1's multi_logloss: 0.732781\n",
      "[569]\ttraining's multi_logloss: 0.416133\tvalid_1's multi_logloss: 0.732725\n",
      "[570]\ttraining's multi_logloss: 0.415754\tvalid_1's multi_logloss: 0.732675\n",
      "[571]\ttraining's multi_logloss: 0.415367\tvalid_1's multi_logloss: 0.73259\n",
      "[572]\ttraining's multi_logloss: 0.414958\tvalid_1's multi_logloss: 0.732519\n",
      "[573]\ttraining's multi_logloss: 0.414562\tvalid_1's multi_logloss: 0.732439\n",
      "[574]\ttraining's multi_logloss: 0.414183\tvalid_1's multi_logloss: 0.732375\n",
      "[575]\ttraining's multi_logloss: 0.413794\tvalid_1's multi_logloss: 0.732292\n",
      "[576]\ttraining's multi_logloss: 0.4134\tvalid_1's multi_logloss: 0.732218\n",
      "[577]\ttraining's multi_logloss: 0.413023\tvalid_1's multi_logloss: 0.732144\n",
      "[578]\ttraining's multi_logloss: 0.412629\tvalid_1's multi_logloss: 0.732067\n",
      "[579]\ttraining's multi_logloss: 0.41225\tvalid_1's multi_logloss: 0.732017\n",
      "[580]\ttraining's multi_logloss: 0.411851\tvalid_1's multi_logloss: 0.731947\n",
      "[581]\ttraining's multi_logloss: 0.411457\tvalid_1's multi_logloss: 0.731864\n",
      "[582]\ttraining's multi_logloss: 0.411084\tvalid_1's multi_logloss: 0.731781\n",
      "[583]\ttraining's multi_logloss: 0.4107\tvalid_1's multi_logloss: 0.731714\n",
      "[584]\ttraining's multi_logloss: 0.410322\tvalid_1's multi_logloss: 0.731659\n",
      "[585]\ttraining's multi_logloss: 0.409947\tvalid_1's multi_logloss: 0.731585\n",
      "[586]\ttraining's multi_logloss: 0.409575\tvalid_1's multi_logloss: 0.731551\n",
      "[587]\ttraining's multi_logloss: 0.409201\tvalid_1's multi_logloss: 0.731463\n",
      "[588]\ttraining's multi_logloss: 0.408825\tvalid_1's multi_logloss: 0.731403\n",
      "[589]\ttraining's multi_logloss: 0.408443\tvalid_1's multi_logloss: 0.731343\n",
      "[590]\ttraining's multi_logloss: 0.408074\tvalid_1's multi_logloss: 0.731279\n",
      "[591]\ttraining's multi_logloss: 0.407688\tvalid_1's multi_logloss: 0.73124\n",
      "[592]\ttraining's multi_logloss: 0.407324\tvalid_1's multi_logloss: 0.731182\n",
      "[593]\ttraining's multi_logloss: 0.406926\tvalid_1's multi_logloss: 0.731109\n",
      "[594]\ttraining's multi_logloss: 0.406564\tvalid_1's multi_logloss: 0.731055\n",
      "[595]\ttraining's multi_logloss: 0.40619\tvalid_1's multi_logloss: 0.731004\n",
      "[596]\ttraining's multi_logloss: 0.405822\tvalid_1's multi_logloss: 0.730941\n",
      "[597]\ttraining's multi_logloss: 0.40545\tvalid_1's multi_logloss: 0.730886\n",
      "[598]\ttraining's multi_logloss: 0.405072\tvalid_1's multi_logloss: 0.730825\n",
      "[599]\ttraining's multi_logloss: 0.404699\tvalid_1's multi_logloss: 0.730785\n",
      "[600]\ttraining's multi_logloss: 0.404327\tvalid_1's multi_logloss: 0.730742\n",
      "[601]\ttraining's multi_logloss: 0.403959\tvalid_1's multi_logloss: 0.730671\n",
      "[602]\ttraining's multi_logloss: 0.403591\tvalid_1's multi_logloss: 0.730608\n",
      "[603]\ttraining's multi_logloss: 0.40323\tvalid_1's multi_logloss: 0.730554\n",
      "[604]\ttraining's multi_logloss: 0.402874\tvalid_1's multi_logloss: 0.730519\n",
      "[605]\ttraining's multi_logloss: 0.4025\tvalid_1's multi_logloss: 0.730468\n",
      "[606]\ttraining's multi_logloss: 0.402141\tvalid_1's multi_logloss: 0.730394\n",
      "[607]\ttraining's multi_logloss: 0.401776\tvalid_1's multi_logloss: 0.730344\n",
      "[608]\ttraining's multi_logloss: 0.401414\tvalid_1's multi_logloss: 0.730298\n",
      "[609]\ttraining's multi_logloss: 0.401056\tvalid_1's multi_logloss: 0.730215\n",
      "[610]\ttraining's multi_logloss: 0.400699\tvalid_1's multi_logloss: 0.730156\n",
      "[611]\ttraining's multi_logloss: 0.400343\tvalid_1's multi_logloss: 0.730099\n",
      "[612]\ttraining's multi_logloss: 0.399986\tvalid_1's multi_logloss: 0.73004\n",
      "[613]\ttraining's multi_logloss: 0.399627\tvalid_1's multi_logloss: 0.729994\n",
      "[614]\ttraining's multi_logloss: 0.399264\tvalid_1's multi_logloss: 0.729926\n",
      "[615]\ttraining's multi_logloss: 0.398913\tvalid_1's multi_logloss: 0.729903\n",
      "[616]\ttraining's multi_logloss: 0.398562\tvalid_1's multi_logloss: 0.729851\n",
      "[617]\ttraining's multi_logloss: 0.398207\tvalid_1's multi_logloss: 0.729831\n",
      "[618]\ttraining's multi_logloss: 0.397844\tvalid_1's multi_logloss: 0.729784\n",
      "[619]\ttraining's multi_logloss: 0.397496\tvalid_1's multi_logloss: 0.729718\n",
      "[620]\ttraining's multi_logloss: 0.397133\tvalid_1's multi_logloss: 0.729669\n",
      "[621]\ttraining's multi_logloss: 0.396775\tvalid_1's multi_logloss: 0.729602\n",
      "[622]\ttraining's multi_logloss: 0.39643\tvalid_1's multi_logloss: 0.729522\n",
      "[623]\ttraining's multi_logloss: 0.396082\tvalid_1's multi_logloss: 0.729492\n",
      "[624]\ttraining's multi_logloss: 0.395728\tvalid_1's multi_logloss: 0.729456\n",
      "[625]\ttraining's multi_logloss: 0.39539\tvalid_1's multi_logloss: 0.729399\n",
      "[626]\ttraining's multi_logloss: 0.395043\tvalid_1's multi_logloss: 0.729331\n",
      "[627]\ttraining's multi_logloss: 0.394692\tvalid_1's multi_logloss: 0.729282\n",
      "[628]\ttraining's multi_logloss: 0.394338\tvalid_1's multi_logloss: 0.729244\n",
      "[629]\ttraining's multi_logloss: 0.393995\tvalid_1's multi_logloss: 0.729173\n",
      "[630]\ttraining's multi_logloss: 0.393655\tvalid_1's multi_logloss: 0.729101\n",
      "[631]\ttraining's multi_logloss: 0.393317\tvalid_1's multi_logloss: 0.729057\n",
      "[632]\ttraining's multi_logloss: 0.392973\tvalid_1's multi_logloss: 0.728982\n",
      "[633]\ttraining's multi_logloss: 0.392624\tvalid_1's multi_logloss: 0.72893\n",
      "[634]\ttraining's multi_logloss: 0.392285\tvalid_1's multi_logloss: 0.728897\n",
      "[635]\ttraining's multi_logloss: 0.391942\tvalid_1's multi_logloss: 0.728819\n",
      "[636]\ttraining's multi_logloss: 0.391586\tvalid_1's multi_logloss: 0.728768\n",
      "[637]\ttraining's multi_logloss: 0.391254\tvalid_1's multi_logloss: 0.728737\n",
      "[638]\ttraining's multi_logloss: 0.390916\tvalid_1's multi_logloss: 0.728668\n",
      "[639]\ttraining's multi_logloss: 0.390584\tvalid_1's multi_logloss: 0.72863\n",
      "[640]\ttraining's multi_logloss: 0.390254\tvalid_1's multi_logloss: 0.728572\n",
      "[641]\ttraining's multi_logloss: 0.389916\tvalid_1's multi_logloss: 0.728539\n",
      "[642]\ttraining's multi_logloss: 0.389581\tvalid_1's multi_logloss: 0.728507\n",
      "[643]\ttraining's multi_logloss: 0.389242\tvalid_1's multi_logloss: 0.728487\n",
      "[644]\ttraining's multi_logloss: 0.388906\tvalid_1's multi_logloss: 0.728443\n",
      "[645]\ttraining's multi_logloss: 0.388574\tvalid_1's multi_logloss: 0.728403\n",
      "[646]\ttraining's multi_logloss: 0.388241\tvalid_1's multi_logloss: 0.728382\n",
      "[647]\ttraining's multi_logloss: 0.387916\tvalid_1's multi_logloss: 0.728344\n",
      "[648]\ttraining's multi_logloss: 0.387585\tvalid_1's multi_logloss: 0.728321\n",
      "[649]\ttraining's multi_logloss: 0.387245\tvalid_1's multi_logloss: 0.728302\n",
      "[650]\ttraining's multi_logloss: 0.386902\tvalid_1's multi_logloss: 0.728252\n",
      "[651]\ttraining's multi_logloss: 0.386567\tvalid_1's multi_logloss: 0.728213\n",
      "[652]\ttraining's multi_logloss: 0.386226\tvalid_1's multi_logloss: 0.728159\n",
      "[653]\ttraining's multi_logloss: 0.38589\tvalid_1's multi_logloss: 0.728117\n",
      "[654]\ttraining's multi_logloss: 0.385559\tvalid_1's multi_logloss: 0.728062\n",
      "[655]\ttraining's multi_logloss: 0.385222\tvalid_1's multi_logloss: 0.728021\n",
      "[656]\ttraining's multi_logloss: 0.384887\tvalid_1's multi_logloss: 0.72799\n",
      "[657]\ttraining's multi_logloss: 0.384559\tvalid_1's multi_logloss: 0.727949\n",
      "[658]\ttraining's multi_logloss: 0.38423\tvalid_1's multi_logloss: 0.727926\n",
      "[659]\ttraining's multi_logloss: 0.383904\tvalid_1's multi_logloss: 0.727878\n",
      "[660]\ttraining's multi_logloss: 0.38357\tvalid_1's multi_logloss: 0.727836\n",
      "[661]\ttraining's multi_logloss: 0.383252\tvalid_1's multi_logloss: 0.727775\n",
      "[662]\ttraining's multi_logloss: 0.382931\tvalid_1's multi_logloss: 0.727725\n",
      "[663]\ttraining's multi_logloss: 0.382608\tvalid_1's multi_logloss: 0.727685\n",
      "[664]\ttraining's multi_logloss: 0.38228\tvalid_1's multi_logloss: 0.727668\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[665]\ttraining's multi_logloss: 0.381961\tvalid_1's multi_logloss: 0.727632\n",
      "[666]\ttraining's multi_logloss: 0.381616\tvalid_1's multi_logloss: 0.727576\n",
      "[667]\ttraining's multi_logloss: 0.38131\tvalid_1's multi_logloss: 0.727499\n",
      "[668]\ttraining's multi_logloss: 0.380995\tvalid_1's multi_logloss: 0.727444\n",
      "[669]\ttraining's multi_logloss: 0.380677\tvalid_1's multi_logloss: 0.727381\n",
      "[670]\ttraining's multi_logloss: 0.380353\tvalid_1's multi_logloss: 0.727366\n",
      "[671]\ttraining's multi_logloss: 0.380025\tvalid_1's multi_logloss: 0.727338\n",
      "[672]\ttraining's multi_logloss: 0.379711\tvalid_1's multi_logloss: 0.727299\n",
      "[673]\ttraining's multi_logloss: 0.379388\tvalid_1's multi_logloss: 0.727251\n",
      "[674]\ttraining's multi_logloss: 0.37907\tvalid_1's multi_logloss: 0.727213\n",
      "[675]\ttraining's multi_logloss: 0.378754\tvalid_1's multi_logloss: 0.727184\n",
      "[676]\ttraining's multi_logloss: 0.378442\tvalid_1's multi_logloss: 0.727161\n",
      "[677]\ttraining's multi_logloss: 0.378117\tvalid_1's multi_logloss: 0.727139\n",
      "[678]\ttraining's multi_logloss: 0.377801\tvalid_1's multi_logloss: 0.727095\n",
      "[679]\ttraining's multi_logloss: 0.377478\tvalid_1's multi_logloss: 0.72706\n",
      "[680]\ttraining's multi_logloss: 0.377149\tvalid_1's multi_logloss: 0.727012\n",
      "[681]\ttraining's multi_logloss: 0.376843\tvalid_1's multi_logloss: 0.726987\n",
      "[682]\ttraining's multi_logloss: 0.376531\tvalid_1's multi_logloss: 0.726937\n",
      "[683]\ttraining's multi_logloss: 0.376225\tvalid_1's multi_logloss: 0.7269\n",
      "[684]\ttraining's multi_logloss: 0.375901\tvalid_1's multi_logloss: 0.726864\n",
      "[685]\ttraining's multi_logloss: 0.375602\tvalid_1's multi_logloss: 0.726827\n",
      "[686]\ttraining's multi_logloss: 0.375296\tvalid_1's multi_logloss: 0.726788\n",
      "[687]\ttraining's multi_logloss: 0.374991\tvalid_1's multi_logloss: 0.726756\n",
      "[688]\ttraining's multi_logloss: 0.374688\tvalid_1's multi_logloss: 0.726726\n",
      "[689]\ttraining's multi_logloss: 0.374373\tvalid_1's multi_logloss: 0.726682\n",
      "[690]\ttraining's multi_logloss: 0.374071\tvalid_1's multi_logloss: 0.726653\n",
      "[691]\ttraining's multi_logloss: 0.373757\tvalid_1's multi_logloss: 0.726601\n",
      "[692]\ttraining's multi_logloss: 0.373454\tvalid_1's multi_logloss: 0.726563\n",
      "[693]\ttraining's multi_logloss: 0.373135\tvalid_1's multi_logloss: 0.726523\n",
      "[694]\ttraining's multi_logloss: 0.372826\tvalid_1's multi_logloss: 0.726485\n",
      "[695]\ttraining's multi_logloss: 0.372527\tvalid_1's multi_logloss: 0.726459\n",
      "[696]\ttraining's multi_logloss: 0.372209\tvalid_1's multi_logloss: 0.726418\n",
      "[697]\ttraining's multi_logloss: 0.37189\tvalid_1's multi_logloss: 0.726343\n",
      "[698]\ttraining's multi_logloss: 0.37159\tvalid_1's multi_logloss: 0.726305\n",
      "[699]\ttraining's multi_logloss: 0.371285\tvalid_1's multi_logloss: 0.726255\n",
      "[700]\ttraining's multi_logloss: 0.370981\tvalid_1's multi_logloss: 0.72622\n",
      "[701]\ttraining's multi_logloss: 0.370665\tvalid_1's multi_logloss: 0.726207\n",
      "[702]\ttraining's multi_logloss: 0.370362\tvalid_1's multi_logloss: 0.726186\n",
      "[703]\ttraining's multi_logloss: 0.370067\tvalid_1's multi_logloss: 0.726152\n",
      "[704]\ttraining's multi_logloss: 0.369764\tvalid_1's multi_logloss: 0.726129\n",
      "[705]\ttraining's multi_logloss: 0.369452\tvalid_1's multi_logloss: 0.726071\n",
      "[706]\ttraining's multi_logloss: 0.369153\tvalid_1's multi_logloss: 0.726035\n",
      "[707]\ttraining's multi_logloss: 0.368859\tvalid_1's multi_logloss: 0.725996\n",
      "[708]\ttraining's multi_logloss: 0.368552\tvalid_1's multi_logloss: 0.725965\n",
      "[709]\ttraining's multi_logloss: 0.36826\tvalid_1's multi_logloss: 0.725961\n",
      "[710]\ttraining's multi_logloss: 0.367971\tvalid_1's multi_logloss: 0.725929\n",
      "[711]\ttraining's multi_logloss: 0.367668\tvalid_1's multi_logloss: 0.72592\n",
      "[712]\ttraining's multi_logloss: 0.367366\tvalid_1's multi_logloss: 0.725883\n",
      "[713]\ttraining's multi_logloss: 0.367077\tvalid_1's multi_logloss: 0.725851\n",
      "[714]\ttraining's multi_logloss: 0.366785\tvalid_1's multi_logloss: 0.72582\n",
      "[715]\ttraining's multi_logloss: 0.366482\tvalid_1's multi_logloss: 0.725783\n",
      "[716]\ttraining's multi_logloss: 0.366183\tvalid_1's multi_logloss: 0.72573\n",
      "[717]\ttraining's multi_logloss: 0.365889\tvalid_1's multi_logloss: 0.725702\n",
      "[718]\ttraining's multi_logloss: 0.365592\tvalid_1's multi_logloss: 0.725673\n",
      "[719]\ttraining's multi_logloss: 0.365302\tvalid_1's multi_logloss: 0.725644\n",
      "[720]\ttraining's multi_logloss: 0.36502\tvalid_1's multi_logloss: 0.725628\n",
      "[721]\ttraining's multi_logloss: 0.364737\tvalid_1's multi_logloss: 0.725597\n",
      "[722]\ttraining's multi_logloss: 0.364454\tvalid_1's multi_logloss: 0.725552\n",
      "[723]\ttraining's multi_logloss: 0.36416\tvalid_1's multi_logloss: 0.725515\n",
      "[724]\ttraining's multi_logloss: 0.363862\tvalid_1's multi_logloss: 0.725481\n",
      "[725]\ttraining's multi_logloss: 0.363572\tvalid_1's multi_logloss: 0.725455\n",
      "[726]\ttraining's multi_logloss: 0.363275\tvalid_1's multi_logloss: 0.725438\n",
      "[727]\ttraining's multi_logloss: 0.36299\tvalid_1's multi_logloss: 0.725399\n",
      "[728]\ttraining's multi_logloss: 0.362707\tvalid_1's multi_logloss: 0.72536\n",
      "[729]\ttraining's multi_logloss: 0.362418\tvalid_1's multi_logloss: 0.725319\n",
      "[730]\ttraining's multi_logloss: 0.36213\tvalid_1's multi_logloss: 0.72529\n",
      "[731]\ttraining's multi_logloss: 0.361842\tvalid_1's multi_logloss: 0.725264\n",
      "[732]\ttraining's multi_logloss: 0.361565\tvalid_1's multi_logloss: 0.725238\n",
      "[733]\ttraining's multi_logloss: 0.361281\tvalid_1's multi_logloss: 0.72522\n",
      "[734]\ttraining's multi_logloss: 0.360983\tvalid_1's multi_logloss: 0.725187\n",
      "[735]\ttraining's multi_logloss: 0.360694\tvalid_1's multi_logloss: 0.72515\n",
      "[736]\ttraining's multi_logloss: 0.360406\tvalid_1's multi_logloss: 0.725115\n",
      "[737]\ttraining's multi_logloss: 0.360115\tvalid_1's multi_logloss: 0.725083\n",
      "[738]\ttraining's multi_logloss: 0.359827\tvalid_1's multi_logloss: 0.72505\n",
      "[739]\ttraining's multi_logloss: 0.359529\tvalid_1's multi_logloss: 0.725044\n",
      "[740]\ttraining's multi_logloss: 0.359246\tvalid_1's multi_logloss: 0.725013\n",
      "[741]\ttraining's multi_logloss: 0.358972\tvalid_1's multi_logloss: 0.725002\n",
      "[742]\ttraining's multi_logloss: 0.358692\tvalid_1's multi_logloss: 0.724955\n",
      "[743]\ttraining's multi_logloss: 0.358421\tvalid_1's multi_logloss: 0.724918\n",
      "[744]\ttraining's multi_logloss: 0.358132\tvalid_1's multi_logloss: 0.72489\n",
      "[745]\ttraining's multi_logloss: 0.35785\tvalid_1's multi_logloss: 0.724896\n",
      "[746]\ttraining's multi_logloss: 0.35758\tvalid_1's multi_logloss: 0.724877\n",
      "[747]\ttraining's multi_logloss: 0.357302\tvalid_1's multi_logloss: 0.724847\n",
      "[748]\ttraining's multi_logloss: 0.35702\tvalid_1's multi_logloss: 0.724824\n",
      "[749]\ttraining's multi_logloss: 0.356735\tvalid_1's multi_logloss: 0.724793\n",
      "[750]\ttraining's multi_logloss: 0.35646\tvalid_1's multi_logloss: 0.724791\n",
      "[751]\ttraining's multi_logloss: 0.356184\tvalid_1's multi_logloss: 0.724769\n",
      "[752]\ttraining's multi_logloss: 0.355904\tvalid_1's multi_logloss: 0.72476\n",
      "[753]\ttraining's multi_logloss: 0.355631\tvalid_1's multi_logloss: 0.72472\n",
      "[754]\ttraining's multi_logloss: 0.355362\tvalid_1's multi_logloss: 0.724719\n",
      "[755]\ttraining's multi_logloss: 0.35509\tvalid_1's multi_logloss: 0.724688\n",
      "[756]\ttraining's multi_logloss: 0.35481\tvalid_1's multi_logloss: 0.724673\n",
      "[757]\ttraining's multi_logloss: 0.354531\tvalid_1's multi_logloss: 0.724639\n",
      "[758]\ttraining's multi_logloss: 0.354259\tvalid_1's multi_logloss: 0.724619\n",
      "[759]\ttraining's multi_logloss: 0.353978\tvalid_1's multi_logloss: 0.724592\n",
      "[760]\ttraining's multi_logloss: 0.353709\tvalid_1's multi_logloss: 0.724597\n",
      "[761]\ttraining's multi_logloss: 0.353433\tvalid_1's multi_logloss: 0.724571\n",
      "[762]\ttraining's multi_logloss: 0.353161\tvalid_1's multi_logloss: 0.724526\n",
      "[763]\ttraining's multi_logloss: 0.352902\tvalid_1's multi_logloss: 0.724504\n",
      "[764]\ttraining's multi_logloss: 0.352624\tvalid_1's multi_logloss: 0.7245\n",
      "[765]\ttraining's multi_logloss: 0.352353\tvalid_1's multi_logloss: 0.724492\n",
      "[766]\ttraining's multi_logloss: 0.35208\tvalid_1's multi_logloss: 0.724474\n",
      "[767]\ttraining's multi_logloss: 0.351816\tvalid_1's multi_logloss: 0.724451\n",
      "[768]\ttraining's multi_logloss: 0.351539\tvalid_1's multi_logloss: 0.724431\n",
      "[769]\ttraining's multi_logloss: 0.351271\tvalid_1's multi_logloss: 0.72442\n",
      "[770]\ttraining's multi_logloss: 0.350998\tvalid_1's multi_logloss: 0.724403\n",
      "[771]\ttraining's multi_logloss: 0.35072\tvalid_1's multi_logloss: 0.7244\n",
      "[772]\ttraining's multi_logloss: 0.350454\tvalid_1's multi_logloss: 0.724373\n",
      "[773]\ttraining's multi_logloss: 0.350188\tvalid_1's multi_logloss: 0.724365\n",
      "[774]\ttraining's multi_logloss: 0.349918\tvalid_1's multi_logloss: 0.724343\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[775]\ttraining's multi_logloss: 0.349652\tvalid_1's multi_logloss: 0.72433\n",
      "[776]\ttraining's multi_logloss: 0.349389\tvalid_1's multi_logloss: 0.724329\n",
      "[777]\ttraining's multi_logloss: 0.349117\tvalid_1's multi_logloss: 0.724312\n",
      "[778]\ttraining's multi_logloss: 0.348849\tvalid_1's multi_logloss: 0.724301\n",
      "[779]\ttraining's multi_logloss: 0.348584\tvalid_1's multi_logloss: 0.72428\n",
      "[780]\ttraining's multi_logloss: 0.348318\tvalid_1's multi_logloss: 0.724253\n",
      "[781]\ttraining's multi_logloss: 0.348056\tvalid_1's multi_logloss: 0.724217\n",
      "[782]\ttraining's multi_logloss: 0.347792\tvalid_1's multi_logloss: 0.72421\n",
      "[783]\ttraining's multi_logloss: 0.347533\tvalid_1's multi_logloss: 0.724196\n",
      "[784]\ttraining's multi_logloss: 0.347252\tvalid_1's multi_logloss: 0.724187\n",
      "[785]\ttraining's multi_logloss: 0.346989\tvalid_1's multi_logloss: 0.724171\n",
      "[786]\ttraining's multi_logloss: 0.346721\tvalid_1's multi_logloss: 0.724162\n",
      "[787]\ttraining's multi_logloss: 0.346447\tvalid_1's multi_logloss: 0.724155\n",
      "[788]\ttraining's multi_logloss: 0.346181\tvalid_1's multi_logloss: 0.724116\n",
      "[789]\ttraining's multi_logloss: 0.34591\tvalid_1's multi_logloss: 0.724111\n",
      "[790]\ttraining's multi_logloss: 0.345644\tvalid_1's multi_logloss: 0.724109\n",
      "[791]\ttraining's multi_logloss: 0.345389\tvalid_1's multi_logloss: 0.724104\n",
      "[792]\ttraining's multi_logloss: 0.345127\tvalid_1's multi_logloss: 0.724087\n",
      "[793]\ttraining's multi_logloss: 0.344852\tvalid_1's multi_logloss: 0.724072\n",
      "[794]\ttraining's multi_logloss: 0.344594\tvalid_1's multi_logloss: 0.72407\n",
      "[795]\ttraining's multi_logloss: 0.344329\tvalid_1's multi_logloss: 0.724051\n",
      "[796]\ttraining's multi_logloss: 0.34407\tvalid_1's multi_logloss: 0.724041\n",
      "[797]\ttraining's multi_logloss: 0.343811\tvalid_1's multi_logloss: 0.724021\n",
      "[798]\ttraining's multi_logloss: 0.343552\tvalid_1's multi_logloss: 0.724003\n",
      "[799]\ttraining's multi_logloss: 0.343298\tvalid_1's multi_logloss: 0.723994\n",
      "[800]\ttraining's multi_logloss: 0.343046\tvalid_1's multi_logloss: 0.723976\n",
      "[801]\ttraining's multi_logloss: 0.342793\tvalid_1's multi_logloss: 0.723949\n",
      "[802]\ttraining's multi_logloss: 0.342535\tvalid_1's multi_logloss: 0.723909\n",
      "[803]\ttraining's multi_logloss: 0.342275\tvalid_1's multi_logloss: 0.723913\n",
      "[804]\ttraining's multi_logloss: 0.342018\tvalid_1's multi_logloss: 0.723883\n",
      "[805]\ttraining's multi_logloss: 0.341762\tvalid_1's multi_logloss: 0.723876\n",
      "[806]\ttraining's multi_logloss: 0.341508\tvalid_1's multi_logloss: 0.723858\n",
      "[807]\ttraining's multi_logloss: 0.341245\tvalid_1's multi_logloss: 0.723819\n",
      "[808]\ttraining's multi_logloss: 0.340993\tvalid_1's multi_logloss: 0.723804\n",
      "[809]\ttraining's multi_logloss: 0.340739\tvalid_1's multi_logloss: 0.7238\n",
      "[810]\ttraining's multi_logloss: 0.340492\tvalid_1's multi_logloss: 0.723792\n",
      "[811]\ttraining's multi_logloss: 0.34023\tvalid_1's multi_logloss: 0.723778\n",
      "[812]\ttraining's multi_logloss: 0.339974\tvalid_1's multi_logloss: 0.723761\n",
      "[813]\ttraining's multi_logloss: 0.339718\tvalid_1's multi_logloss: 0.723736\n",
      "[814]\ttraining's multi_logloss: 0.339467\tvalid_1's multi_logloss: 0.723743\n",
      "[815]\ttraining's multi_logloss: 0.339212\tvalid_1's multi_logloss: 0.723739\n",
      "[816]\ttraining's multi_logloss: 0.338967\tvalid_1's multi_logloss: 0.723724\n",
      "[817]\ttraining's multi_logloss: 0.338718\tvalid_1's multi_logloss: 0.723714\n",
      "[818]\ttraining's multi_logloss: 0.338459\tvalid_1's multi_logloss: 0.723696\n",
      "[819]\ttraining's multi_logloss: 0.338201\tvalid_1's multi_logloss: 0.723667\n",
      "[820]\ttraining's multi_logloss: 0.337951\tvalid_1's multi_logloss: 0.723648\n",
      "[821]\ttraining's multi_logloss: 0.337705\tvalid_1's multi_logloss: 0.723647\n",
      "[822]\ttraining's multi_logloss: 0.337454\tvalid_1's multi_logloss: 0.723648\n",
      "[823]\ttraining's multi_logloss: 0.337212\tvalid_1's multi_logloss: 0.723616\n",
      "[824]\ttraining's multi_logloss: 0.336966\tvalid_1's multi_logloss: 0.723617\n",
      "[825]\ttraining's multi_logloss: 0.336721\tvalid_1's multi_logloss: 0.723618\n",
      "[826]\ttraining's multi_logloss: 0.336467\tvalid_1's multi_logloss: 0.723609\n",
      "[827]\ttraining's multi_logloss: 0.336214\tvalid_1's multi_logloss: 0.723594\n",
      "[828]\ttraining's multi_logloss: 0.335966\tvalid_1's multi_logloss: 0.723578\n",
      "[829]\ttraining's multi_logloss: 0.335718\tvalid_1's multi_logloss: 0.723577\n",
      "[830]\ttraining's multi_logloss: 0.33547\tvalid_1's multi_logloss: 0.723563\n",
      "[831]\ttraining's multi_logloss: 0.335217\tvalid_1's multi_logloss: 0.723539\n",
      "[832]\ttraining's multi_logloss: 0.334962\tvalid_1's multi_logloss: 0.723523\n",
      "[833]\ttraining's multi_logloss: 0.334722\tvalid_1's multi_logloss: 0.723518\n",
      "[834]\ttraining's multi_logloss: 0.334477\tvalid_1's multi_logloss: 0.723501\n",
      "[835]\ttraining's multi_logloss: 0.334237\tvalid_1's multi_logloss: 0.72351\n",
      "[836]\ttraining's multi_logloss: 0.333994\tvalid_1's multi_logloss: 0.7235\n",
      "[837]\ttraining's multi_logloss: 0.333755\tvalid_1's multi_logloss: 0.723468\n",
      "[838]\ttraining's multi_logloss: 0.333508\tvalid_1's multi_logloss: 0.723454\n",
      "[839]\ttraining's multi_logloss: 0.333266\tvalid_1's multi_logloss: 0.723442\n",
      "[840]\ttraining's multi_logloss: 0.333027\tvalid_1's multi_logloss: 0.723429\n",
      "[841]\ttraining's multi_logloss: 0.332777\tvalid_1's multi_logloss: 0.723397\n",
      "[842]\ttraining's multi_logloss: 0.332526\tvalid_1's multi_logloss: 0.723386\n",
      "[843]\ttraining's multi_logloss: 0.332285\tvalid_1's multi_logloss: 0.723376\n",
      "[844]\ttraining's multi_logloss: 0.332045\tvalid_1's multi_logloss: 0.723376\n",
      "[845]\ttraining's multi_logloss: 0.331802\tvalid_1's multi_logloss: 0.723364\n",
      "[846]\ttraining's multi_logloss: 0.331562\tvalid_1's multi_logloss: 0.723366\n",
      "[847]\ttraining's multi_logloss: 0.331324\tvalid_1's multi_logloss: 0.723345\n",
      "[848]\ttraining's multi_logloss: 0.331085\tvalid_1's multi_logloss: 0.723341\n",
      "[849]\ttraining's multi_logloss: 0.330851\tvalid_1's multi_logloss: 0.72334\n",
      "[850]\ttraining's multi_logloss: 0.330614\tvalid_1's multi_logloss: 0.723336\n",
      "[851]\ttraining's multi_logloss: 0.33038\tvalid_1's multi_logloss: 0.723336\n",
      "[852]\ttraining's multi_logloss: 0.330141\tvalid_1's multi_logloss: 0.72333\n",
      "[853]\ttraining's multi_logloss: 0.329903\tvalid_1's multi_logloss: 0.723319\n",
      "[854]\ttraining's multi_logloss: 0.329666\tvalid_1's multi_logloss: 0.723292\n",
      "[855]\ttraining's multi_logloss: 0.32943\tvalid_1's multi_logloss: 0.723278\n",
      "[856]\ttraining's multi_logloss: 0.329194\tvalid_1's multi_logloss: 0.723284\n",
      "[857]\ttraining's multi_logloss: 0.328955\tvalid_1's multi_logloss: 0.723262\n",
      "[858]\ttraining's multi_logloss: 0.328719\tvalid_1's multi_logloss: 0.723272\n",
      "[859]\ttraining's multi_logloss: 0.328485\tvalid_1's multi_logloss: 0.723282\n",
      "[860]\ttraining's multi_logloss: 0.328257\tvalid_1's multi_logloss: 0.72329\n",
      "[861]\ttraining's multi_logloss: 0.328017\tvalid_1's multi_logloss: 0.723283\n",
      "[862]\ttraining's multi_logloss: 0.327787\tvalid_1's multi_logloss: 0.723257\n",
      "[863]\ttraining's multi_logloss: 0.327552\tvalid_1's multi_logloss: 0.723264\n",
      "[864]\ttraining's multi_logloss: 0.327321\tvalid_1's multi_logloss: 0.723261\n",
      "[865]\ttraining's multi_logloss: 0.327089\tvalid_1's multi_logloss: 0.723245\n",
      "[866]\ttraining's multi_logloss: 0.326856\tvalid_1's multi_logloss: 0.723256\n",
      "[867]\ttraining's multi_logloss: 0.326616\tvalid_1's multi_logloss: 0.723252\n",
      "[868]\ttraining's multi_logloss: 0.326382\tvalid_1's multi_logloss: 0.723246\n",
      "[869]\ttraining's multi_logloss: 0.326158\tvalid_1's multi_logloss: 0.723233\n",
      "[870]\ttraining's multi_logloss: 0.325924\tvalid_1's multi_logloss: 0.72321\n",
      "[871]\ttraining's multi_logloss: 0.325697\tvalid_1's multi_logloss: 0.723181\n",
      "[872]\ttraining's multi_logloss: 0.325463\tvalid_1's multi_logloss: 0.723172\n",
      "[873]\ttraining's multi_logloss: 0.325233\tvalid_1's multi_logloss: 0.723162\n",
      "[874]\ttraining's multi_logloss: 0.325009\tvalid_1's multi_logloss: 0.723178\n",
      "[875]\ttraining's multi_logloss: 0.324782\tvalid_1's multi_logloss: 0.7232\n",
      "[876]\ttraining's multi_logloss: 0.324546\tvalid_1's multi_logloss: 0.723203\n",
      "[877]\ttraining's multi_logloss: 0.324314\tvalid_1's multi_logloss: 0.72322\n",
      "[878]\ttraining's multi_logloss: 0.324086\tvalid_1's multi_logloss: 0.723209\n",
      "[879]\ttraining's multi_logloss: 0.32386\tvalid_1's multi_logloss: 0.723206\n",
      "[880]\ttraining's multi_logloss: 0.323638\tvalid_1's multi_logloss: 0.723191\n",
      "[881]\ttraining's multi_logloss: 0.323402\tvalid_1's multi_logloss: 0.723179\n",
      "[882]\ttraining's multi_logloss: 0.323167\tvalid_1's multi_logloss: 0.723192\n",
      "[883]\ttraining's multi_logloss: 0.322943\tvalid_1's multi_logloss: 0.723195\n",
      "Early stopping, best iteration is:\n",
      "[873]\ttraining's multi_logloss: 0.325233\tvalid_1's multi_logloss: 0.723162\n"
     ]
    }
   ],
   "source": [
    "num_boost_round = 4000\n",
    "max_delta_step=0\n",
    "learning_rate=0.02\n",
    "\n",
    "params = {'objective':'multiclass',\n",
    "          'boosting_type': 'gbdt',\n",
    "          'max_depth' : -1,\n",
    "          'nthread': 4,\n",
    "          'metric': 'multi_logloss',\n",
    "          'num_class':38,\n",
    "          'learning_rate':learning_rate,\n",
    "          'max_delta_step':max_delta_step,\n",
    "          }\n",
    "\n",
    "# evals = [(dtrain, 'train'), (dtest, 'test')]\n",
    "\n",
    "# %%time\n",
    "# 4000, 0.008\n",
    "lightgbm_model = lightgbm.train(params = params,\n",
    "                                train_set = dtrain, \n",
    "                                valid_sets = [dtrain, dtest],\n",
    "                                num_boost_round = num_boost_round,\n",
    "                                early_stopping_rounds=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fl(>median), company(>median), item_nbr(>mean) dummies 6425 컬럼. 0.723162"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fl, company dummie들의 컬럼으로 Sum한 값을 확인해서 둘다 median 값 이상으로 팔린 아이템만 남긴 feature로 돌렸다. 컬럼은 3748 점수는 0.756773"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's multi_logloss: 3.42656\tvalid_1's multi_logloss: 3.43305\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[2]\ttraining's multi_logloss: 3.26719\tvalid_1's multi_logloss: 3.27824\n",
      "[3]\ttraining's multi_logloss: 3.13593\tvalid_1's multi_logloss: 3.15062\n",
      "[4]\ttraining's multi_logloss: 3.02374\tvalid_1's multi_logloss: 3.04172\n",
      "[5]\ttraining's multi_logloss: 2.92567\tvalid_1's multi_logloss: 2.94663\n",
      "[6]\ttraining's multi_logloss: 2.83838\tvalid_1's multi_logloss: 2.86201\n",
      "[7]\ttraining's multi_logloss: 2.75914\tvalid_1's multi_logloss: 2.78528\n",
      "[8]\ttraining's multi_logloss: 2.6869\tvalid_1's multi_logloss: 2.71532\n",
      "[9]\ttraining's multi_logloss: 2.62058\tvalid_1's multi_logloss: 2.65115\n",
      "[10]\ttraining's multi_logloss: 2.5592\tvalid_1's multi_logloss: 2.59203\n",
      "[11]\ttraining's multi_logloss: 2.5021\tvalid_1's multi_logloss: 2.53673\n",
      "[12]\ttraining's multi_logloss: 2.44853\tvalid_1's multi_logloss: 2.48512\n",
      "[13]\ttraining's multi_logloss: 2.39816\tvalid_1's multi_logloss: 2.43668\n",
      "[14]\ttraining's multi_logloss: 2.35084\tvalid_1's multi_logloss: 2.39102\n",
      "[15]\ttraining's multi_logloss: 2.30616\tvalid_1's multi_logloss: 2.34792\n",
      "[16]\ttraining's multi_logloss: 2.26375\tvalid_1's multi_logloss: 2.30698\n",
      "[17]\ttraining's multi_logloss: 2.22335\tvalid_1's multi_logloss: 2.26802\n",
      "[18]\ttraining's multi_logloss: 2.18485\tvalid_1's multi_logloss: 2.23087\n",
      "[19]\ttraining's multi_logloss: 2.14805\tvalid_1's multi_logloss: 2.19531\n",
      "[20]\ttraining's multi_logloss: 2.11276\tvalid_1's multi_logloss: 2.1613\n",
      "[21]\ttraining's multi_logloss: 2.07923\tvalid_1's multi_logloss: 2.12907\n",
      "[22]\ttraining's multi_logloss: 2.04683\tvalid_1's multi_logloss: 2.09786\n",
      "[23]\ttraining's multi_logloss: 2.01577\tvalid_1's multi_logloss: 2.06801\n",
      "[24]\ttraining's multi_logloss: 1.98585\tvalid_1's multi_logloss: 2.03928\n",
      "[25]\ttraining's multi_logloss: 1.95694\tvalid_1's multi_logloss: 2.01155\n",
      "[26]\ttraining's multi_logloss: 1.92909\tvalid_1's multi_logloss: 1.9849\n",
      "[27]\ttraining's multi_logloss: 1.90219\tvalid_1's multi_logloss: 1.95905\n",
      "[28]\ttraining's multi_logloss: 1.87612\tvalid_1's multi_logloss: 1.93401\n",
      "[29]\ttraining's multi_logloss: 1.85105\tvalid_1's multi_logloss: 1.90995\n",
      "[30]\ttraining's multi_logloss: 1.82687\tvalid_1's multi_logloss: 1.88675\n",
      "[31]\ttraining's multi_logloss: 1.80329\tvalid_1's multi_logloss: 1.86424\n",
      "[32]\ttraining's multi_logloss: 1.78059\tvalid_1's multi_logloss: 1.84244\n",
      "[33]\ttraining's multi_logloss: 1.75849\tvalid_1's multi_logloss: 1.82133\n",
      "[34]\ttraining's multi_logloss: 1.73715\tvalid_1's multi_logloss: 1.80087\n",
      "[35]\ttraining's multi_logloss: 1.71633\tvalid_1's multi_logloss: 1.78106\n",
      "[36]\ttraining's multi_logloss: 1.69622\tvalid_1's multi_logloss: 1.76186\n",
      "[37]\ttraining's multi_logloss: 1.67668\tvalid_1's multi_logloss: 1.74325\n",
      "[38]\ttraining's multi_logloss: 1.6576\tvalid_1's multi_logloss: 1.72506\n",
      "[39]\ttraining's multi_logloss: 1.63911\tvalid_1's multi_logloss: 1.70745\n",
      "[40]\ttraining's multi_logloss: 1.62105\tvalid_1's multi_logloss: 1.69024\n",
      "[41]\ttraining's multi_logloss: 1.60346\tvalid_1's multi_logloss: 1.6735\n",
      "[42]\ttraining's multi_logloss: 1.58633\tvalid_1's multi_logloss: 1.65719\n",
      "[43]\ttraining's multi_logloss: 1.5696\tvalid_1's multi_logloss: 1.64129\n",
      "[44]\ttraining's multi_logloss: 1.55338\tvalid_1's multi_logloss: 1.62593\n",
      "[45]\ttraining's multi_logloss: 1.53748\tvalid_1's multi_logloss: 1.61083\n",
      "[46]\ttraining's multi_logloss: 1.52206\tvalid_1's multi_logloss: 1.5962\n",
      "[47]\ttraining's multi_logloss: 1.507\tvalid_1's multi_logloss: 1.58188\n",
      "[48]\ttraining's multi_logloss: 1.49229\tvalid_1's multi_logloss: 1.56799\n",
      "[49]\ttraining's multi_logloss: 1.47791\tvalid_1's multi_logloss: 1.5544\n",
      "[50]\ttraining's multi_logloss: 1.46381\tvalid_1's multi_logloss: 1.5411\n",
      "[51]\ttraining's multi_logloss: 1.45005\tvalid_1's multi_logloss: 1.5281\n",
      "[52]\ttraining's multi_logloss: 1.43658\tvalid_1's multi_logloss: 1.51537\n",
      "[53]\ttraining's multi_logloss: 1.42342\tvalid_1's multi_logloss: 1.50298\n",
      "[54]\ttraining's multi_logloss: 1.41055\tvalid_1's multi_logloss: 1.4908\n",
      "[55]\ttraining's multi_logloss: 1.39799\tvalid_1's multi_logloss: 1.47904\n",
      "[56]\ttraining's multi_logloss: 1.3857\tvalid_1's multi_logloss: 1.46742\n",
      "[57]\ttraining's multi_logloss: 1.37362\tvalid_1's multi_logloss: 1.45606\n",
      "[58]\ttraining's multi_logloss: 1.36187\tvalid_1's multi_logloss: 1.44499\n",
      "[59]\ttraining's multi_logloss: 1.35035\tvalid_1's multi_logloss: 1.43418\n",
      "[60]\ttraining's multi_logloss: 1.33904\tvalid_1's multi_logloss: 1.42354\n",
      "[61]\ttraining's multi_logloss: 1.32797\tvalid_1's multi_logloss: 1.41313\n",
      "[62]\ttraining's multi_logloss: 1.31711\tvalid_1's multi_logloss: 1.40298\n",
      "[63]\ttraining's multi_logloss: 1.30645\tvalid_1's multi_logloss: 1.39299\n",
      "[64]\ttraining's multi_logloss: 1.296\tvalid_1's multi_logloss: 1.38321\n",
      "[65]\ttraining's multi_logloss: 1.28575\tvalid_1's multi_logloss: 1.37365\n",
      "[66]\ttraining's multi_logloss: 1.27572\tvalid_1's multi_logloss: 1.36431\n",
      "[67]\ttraining's multi_logloss: 1.26589\tvalid_1's multi_logloss: 1.3551\n",
      "[68]\ttraining's multi_logloss: 1.25627\tvalid_1's multi_logloss: 1.34611\n",
      "[69]\ttraining's multi_logloss: 1.24679\tvalid_1's multi_logloss: 1.33729\n",
      "[70]\ttraining's multi_logloss: 1.23755\tvalid_1's multi_logloss: 1.32866\n",
      "[71]\ttraining's multi_logloss: 1.22846\tvalid_1's multi_logloss: 1.32021\n",
      "[72]\ttraining's multi_logloss: 1.2195\tvalid_1's multi_logloss: 1.31192\n",
      "[73]\ttraining's multi_logloss: 1.2107\tvalid_1's multi_logloss: 1.30379\n",
      "[74]\ttraining's multi_logloss: 1.20209\tvalid_1's multi_logloss: 1.2958\n",
      "[75]\ttraining's multi_logloss: 1.19363\tvalid_1's multi_logloss: 1.288\n",
      "[76]\ttraining's multi_logloss: 1.18534\tvalid_1's multi_logloss: 1.28037\n",
      "[77]\ttraining's multi_logloss: 1.1772\tvalid_1's multi_logloss: 1.27286\n",
      "[78]\ttraining's multi_logloss: 1.1692\tvalid_1's multi_logloss: 1.26548\n",
      "[79]\ttraining's multi_logloss: 1.16135\tvalid_1's multi_logloss: 1.25823\n",
      "[80]\ttraining's multi_logloss: 1.15365\tvalid_1's multi_logloss: 1.25116\n",
      "[81]\ttraining's multi_logloss: 1.14609\tvalid_1's multi_logloss: 1.24418\n",
      "[82]\ttraining's multi_logloss: 1.13868\tvalid_1's multi_logloss: 1.23738\n",
      "[83]\ttraining's multi_logloss: 1.13139\tvalid_1's multi_logloss: 1.23067\n",
      "[84]\ttraining's multi_logloss: 1.1242\tvalid_1's multi_logloss: 1.22412\n",
      "[85]\ttraining's multi_logloss: 1.11711\tvalid_1's multi_logloss: 1.21766\n",
      "[86]\ttraining's multi_logloss: 1.11013\tvalid_1's multi_logloss: 1.21135\n",
      "[87]\ttraining's multi_logloss: 1.10327\tvalid_1's multi_logloss: 1.20508\n",
      "[88]\ttraining's multi_logloss: 1.09656\tvalid_1's multi_logloss: 1.199\n",
      "[89]\ttraining's multi_logloss: 1.08995\tvalid_1's multi_logloss: 1.193\n",
      "[90]\ttraining's multi_logloss: 1.0834\tvalid_1's multi_logloss: 1.18708\n",
      "[91]\ttraining's multi_logloss: 1.077\tvalid_1's multi_logloss: 1.18131\n",
      "[92]\ttraining's multi_logloss: 1.0707\tvalid_1's multi_logloss: 1.17562\n",
      "[93]\ttraining's multi_logloss: 1.06447\tvalid_1's multi_logloss: 1.17002\n",
      "[94]\ttraining's multi_logloss: 1.05836\tvalid_1's multi_logloss: 1.16453\n",
      "[95]\ttraining's multi_logloss: 1.05239\tvalid_1's multi_logloss: 1.1592\n",
      "[96]\ttraining's multi_logloss: 1.04651\tvalid_1's multi_logloss: 1.15388\n",
      "[97]\ttraining's multi_logloss: 1.04068\tvalid_1's multi_logloss: 1.14862\n",
      "[98]\ttraining's multi_logloss: 1.03497\tvalid_1's multi_logloss: 1.14354\n",
      "[99]\ttraining's multi_logloss: 1.02936\tvalid_1's multi_logloss: 1.13853\n",
      "[100]\ttraining's multi_logloss: 1.02386\tvalid_1's multi_logloss: 1.13361\n",
      "[101]\ttraining's multi_logloss: 1.01838\tvalid_1's multi_logloss: 1.12874\n",
      "[102]\ttraining's multi_logloss: 1.013\tvalid_1's multi_logloss: 1.124\n",
      "[103]\ttraining's multi_logloss: 1.00772\tvalid_1's multi_logloss: 1.11934\n",
      "[104]\ttraining's multi_logloss: 1.00254\tvalid_1's multi_logloss: 1.11476\n",
      "[105]\ttraining's multi_logloss: 0.997394\tvalid_1's multi_logloss: 1.11026\n",
      "[106]\ttraining's multi_logloss: 0.992364\tvalid_1's multi_logloss: 1.10584\n",
      "[107]\ttraining's multi_logloss: 0.987386\tvalid_1's multi_logloss: 1.10143\n",
      "[108]\ttraining's multi_logloss: 0.98246\tvalid_1's multi_logloss: 1.09713\n",
      "[109]\ttraining's multi_logloss: 0.977583\tvalid_1's multi_logloss: 1.09279\n",
      "[110]\ttraining's multi_logloss: 0.972813\tvalid_1's multi_logloss: 1.08857\n",
      "[111]\ttraining's multi_logloss: 0.968122\tvalid_1's multi_logloss: 1.08446\n",
      "[112]\ttraining's multi_logloss: 0.963486\tvalid_1's multi_logloss: 1.08037\n",
      "[113]\ttraining's multi_logloss: 0.95891\tvalid_1's multi_logloss: 1.07634\n",
      "[114]\ttraining's multi_logloss: 0.954417\tvalid_1's multi_logloss: 1.07241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[115]\ttraining's multi_logloss: 0.949936\tvalid_1's multi_logloss: 1.06851\n",
      "[116]\ttraining's multi_logloss: 0.945594\tvalid_1's multi_logloss: 1.06474\n",
      "[117]\ttraining's multi_logloss: 0.94125\tvalid_1's multi_logloss: 1.06094\n",
      "[118]\ttraining's multi_logloss: 0.937037\tvalid_1's multi_logloss: 1.05729\n",
      "[119]\ttraining's multi_logloss: 0.932854\tvalid_1's multi_logloss: 1.05367\n",
      "[120]\ttraining's multi_logloss: 0.928741\tvalid_1's multi_logloss: 1.05013\n",
      "[121]\ttraining's multi_logloss: 0.924665\tvalid_1's multi_logloss: 1.04661\n",
      "[122]\ttraining's multi_logloss: 0.920642\tvalid_1's multi_logloss: 1.04317\n",
      "[123]\ttraining's multi_logloss: 0.916685\tvalid_1's multi_logloss: 1.03974\n",
      "[124]\ttraining's multi_logloss: 0.912806\tvalid_1's multi_logloss: 1.03639\n",
      "[125]\ttraining's multi_logloss: 0.908961\tvalid_1's multi_logloss: 1.0331\n",
      "[126]\ttraining's multi_logloss: 0.905178\tvalid_1's multi_logloss: 1.02985\n",
      "[127]\ttraining's multi_logloss: 0.90137\tvalid_1's multi_logloss: 1.02664\n",
      "[128]\ttraining's multi_logloss: 0.897668\tvalid_1's multi_logloss: 1.02353\n",
      "[129]\ttraining's multi_logloss: 0.894028\tvalid_1's multi_logloss: 1.02043\n",
      "[130]\ttraining's multi_logloss: 0.890424\tvalid_1's multi_logloss: 1.01737\n",
      "[131]\ttraining's multi_logloss: 0.886875\tvalid_1's multi_logloss: 1.01436\n",
      "[132]\ttraining's multi_logloss: 0.883346\tvalid_1's multi_logloss: 1.01136\n",
      "[133]\ttraining's multi_logloss: 0.87987\tvalid_1's multi_logloss: 1.00841\n",
      "[134]\ttraining's multi_logloss: 0.87643\tvalid_1's multi_logloss: 1.00552\n",
      "[135]\ttraining's multi_logloss: 0.873024\tvalid_1's multi_logloss: 1.00267\n",
      "[136]\ttraining's multi_logloss: 0.869687\tvalid_1's multi_logloss: 0.999866\n",
      "[137]\ttraining's multi_logloss: 0.866378\tvalid_1's multi_logloss: 0.997064\n",
      "[138]\ttraining's multi_logloss: 0.863158\tvalid_1's multi_logloss: 0.994365\n",
      "[139]\ttraining's multi_logloss: 0.859944\tvalid_1's multi_logloss: 0.991669\n",
      "[140]\ttraining's multi_logloss: 0.85678\tvalid_1's multi_logloss: 0.989057\n",
      "[141]\ttraining's multi_logloss: 0.853637\tvalid_1's multi_logloss: 0.98643\n",
      "[142]\ttraining's multi_logloss: 0.850545\tvalid_1's multi_logloss: 0.98388\n",
      "[143]\ttraining's multi_logloss: 0.8475\tvalid_1's multi_logloss: 0.981341\n",
      "[144]\ttraining's multi_logloss: 0.84448\tvalid_1's multi_logloss: 0.978876\n",
      "[145]\ttraining's multi_logloss: 0.841523\tvalid_1's multi_logloss: 0.976441\n",
      "[146]\ttraining's multi_logloss: 0.838579\tvalid_1's multi_logloss: 0.97399\n",
      "[147]\ttraining's multi_logloss: 0.83567\tvalid_1's multi_logloss: 0.971577\n",
      "[148]\ttraining's multi_logloss: 0.832812\tvalid_1's multi_logloss: 0.969226\n",
      "[149]\ttraining's multi_logloss: 0.829991\tvalid_1's multi_logloss: 0.966913\n",
      "[150]\ttraining's multi_logloss: 0.827189\tvalid_1's multi_logloss: 0.964603\n",
      "[151]\ttraining's multi_logloss: 0.824416\tvalid_1's multi_logloss: 0.962371\n",
      "[152]\ttraining's multi_logloss: 0.821717\tvalid_1's multi_logloss: 0.96013\n",
      "[153]\ttraining's multi_logloss: 0.819017\tvalid_1's multi_logloss: 0.957962\n",
      "[154]\ttraining's multi_logloss: 0.816343\tvalid_1's multi_logloss: 0.955758\n",
      "[155]\ttraining's multi_logloss: 0.813742\tvalid_1's multi_logloss: 0.953692\n",
      "[156]\ttraining's multi_logloss: 0.811137\tvalid_1's multi_logloss: 0.951572\n",
      "[157]\ttraining's multi_logloss: 0.808585\tvalid_1's multi_logloss: 0.949481\n",
      "[158]\ttraining's multi_logloss: 0.806046\tvalid_1's multi_logloss: 0.947435\n",
      "[159]\ttraining's multi_logloss: 0.803566\tvalid_1's multi_logloss: 0.945439\n",
      "[160]\ttraining's multi_logloss: 0.80109\tvalid_1's multi_logloss: 0.943461\n",
      "[161]\ttraining's multi_logloss: 0.798619\tvalid_1's multi_logloss: 0.941448\n",
      "[162]\ttraining's multi_logloss: 0.796186\tvalid_1's multi_logloss: 0.939499\n",
      "[163]\ttraining's multi_logloss: 0.793792\tvalid_1's multi_logloss: 0.937598\n",
      "[164]\ttraining's multi_logloss: 0.791425\tvalid_1's multi_logloss: 0.935693\n",
      "[165]\ttraining's multi_logloss: 0.78907\tvalid_1's multi_logloss: 0.933844\n",
      "[166]\ttraining's multi_logloss: 0.786768\tvalid_1's multi_logloss: 0.932019\n",
      "[167]\ttraining's multi_logloss: 0.784471\tvalid_1's multi_logloss: 0.930207\n",
      "[168]\ttraining's multi_logloss: 0.78221\tvalid_1's multi_logloss: 0.928391\n",
      "[169]\ttraining's multi_logloss: 0.779978\tvalid_1's multi_logloss: 0.926666\n",
      "[170]\ttraining's multi_logloss: 0.777748\tvalid_1's multi_logloss: 0.92493\n",
      "[171]\ttraining's multi_logloss: 0.775564\tvalid_1's multi_logloss: 0.923191\n",
      "[172]\ttraining's multi_logloss: 0.773402\tvalid_1's multi_logloss: 0.921485\n",
      "[173]\ttraining's multi_logloss: 0.771265\tvalid_1's multi_logloss: 0.91981\n",
      "[174]\ttraining's multi_logloss: 0.769158\tvalid_1's multi_logloss: 0.918197\n",
      "[175]\ttraining's multi_logloss: 0.767046\tvalid_1's multi_logloss: 0.916531\n",
      "[176]\ttraining's multi_logloss: 0.764985\tvalid_1's multi_logloss: 0.914932\n",
      "[177]\ttraining's multi_logloss: 0.762915\tvalid_1's multi_logloss: 0.913358\n",
      "[178]\ttraining's multi_logloss: 0.760875\tvalid_1's multi_logloss: 0.911787\n",
      "[179]\ttraining's multi_logloss: 0.75883\tvalid_1's multi_logloss: 0.910209\n",
      "[180]\ttraining's multi_logloss: 0.756843\tvalid_1's multi_logloss: 0.90866\n",
      "[181]\ttraining's multi_logloss: 0.754871\tvalid_1's multi_logloss: 0.907173\n",
      "[182]\ttraining's multi_logloss: 0.752903\tvalid_1's multi_logloss: 0.905643\n",
      "[183]\ttraining's multi_logloss: 0.750976\tvalid_1's multi_logloss: 0.904165\n",
      "[184]\ttraining's multi_logloss: 0.749059\tvalid_1's multi_logloss: 0.902699\n",
      "[185]\ttraining's multi_logloss: 0.747173\tvalid_1's multi_logloss: 0.901285\n",
      "[186]\ttraining's multi_logloss: 0.745294\tvalid_1's multi_logloss: 0.899895\n",
      "[187]\ttraining's multi_logloss: 0.743442\tvalid_1's multi_logloss: 0.898503\n",
      "[188]\ttraining's multi_logloss: 0.741589\tvalid_1's multi_logloss: 0.897142\n",
      "[189]\ttraining's multi_logloss: 0.739758\tvalid_1's multi_logloss: 0.895775\n",
      "[190]\ttraining's multi_logloss: 0.737969\tvalid_1's multi_logloss: 0.894435\n",
      "[191]\ttraining's multi_logloss: 0.736183\tvalid_1's multi_logloss: 0.893103\n",
      "[192]\ttraining's multi_logloss: 0.734415\tvalid_1's multi_logloss: 0.891805\n",
      "[193]\ttraining's multi_logloss: 0.732616\tvalid_1's multi_logloss: 0.890438\n",
      "[194]\ttraining's multi_logloss: 0.73084\tvalid_1's multi_logloss: 0.889114\n",
      "[195]\ttraining's multi_logloss: 0.729125\tvalid_1's multi_logloss: 0.887874\n",
      "[196]\ttraining's multi_logloss: 0.727394\tvalid_1's multi_logloss: 0.886625\n",
      "[197]\ttraining's multi_logloss: 0.725653\tvalid_1's multi_logloss: 0.885322\n",
      "[198]\ttraining's multi_logloss: 0.723977\tvalid_1's multi_logloss: 0.884134\n",
      "[199]\ttraining's multi_logloss: 0.722311\tvalid_1's multi_logloss: 0.882953\n",
      "[200]\ttraining's multi_logloss: 0.720654\tvalid_1's multi_logloss: 0.881737\n",
      "[201]\ttraining's multi_logloss: 0.719005\tvalid_1's multi_logloss: 0.880538\n",
      "[202]\ttraining's multi_logloss: 0.717406\tvalid_1's multi_logloss: 0.87941\n",
      "[203]\ttraining's multi_logloss: 0.715792\tvalid_1's multi_logloss: 0.878268\n",
      "[204]\ttraining's multi_logloss: 0.714168\tvalid_1's multi_logloss: 0.877088\n",
      "[205]\ttraining's multi_logloss: 0.712612\tvalid_1's multi_logloss: 0.875985\n",
      "[206]\ttraining's multi_logloss: 0.711049\tvalid_1's multi_logloss: 0.874865\n",
      "[207]\ttraining's multi_logloss: 0.709508\tvalid_1's multi_logloss: 0.873803\n",
      "[208]\ttraining's multi_logloss: 0.707972\tvalid_1's multi_logloss: 0.872731\n",
      "[209]\ttraining's multi_logloss: 0.706427\tvalid_1's multi_logloss: 0.871637\n",
      "[210]\ttraining's multi_logloss: 0.704924\tvalid_1's multi_logloss: 0.870576\n",
      "[211]\ttraining's multi_logloss: 0.703442\tvalid_1's multi_logloss: 0.86957\n",
      "[212]\ttraining's multi_logloss: 0.701958\tvalid_1's multi_logloss: 0.868541\n",
      "[213]\ttraining's multi_logloss: 0.700484\tvalid_1's multi_logloss: 0.867512\n",
      "[214]\ttraining's multi_logloss: 0.699027\tvalid_1's multi_logloss: 0.866487\n",
      "[215]\ttraining's multi_logloss: 0.697585\tvalid_1's multi_logloss: 0.865505\n",
      "[216]\ttraining's multi_logloss: 0.696173\tvalid_1's multi_logloss: 0.864523\n",
      "[217]\ttraining's multi_logloss: 0.694728\tvalid_1's multi_logloss: 0.863531\n",
      "[218]\ttraining's multi_logloss: 0.693362\tvalid_1's multi_logloss: 0.862588\n",
      "[219]\ttraining's multi_logloss: 0.691978\tvalid_1's multi_logloss: 0.86167\n",
      "[220]\ttraining's multi_logloss: 0.690597\tvalid_1's multi_logloss: 0.860728\n",
      "[221]\ttraining's multi_logloss: 0.689241\tvalid_1's multi_logloss: 0.859806\n",
      "[222]\ttraining's multi_logloss: 0.687878\tvalid_1's multi_logloss: 0.858909\n",
      "[223]\ttraining's multi_logloss: 0.686525\tvalid_1's multi_logloss: 0.857997\n",
      "[224]\ttraining's multi_logloss: 0.685184\tvalid_1's multi_logloss: 0.857146\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[225]\ttraining's multi_logloss: 0.683836\tvalid_1's multi_logloss: 0.856278\n",
      "[226]\ttraining's multi_logloss: 0.682519\tvalid_1's multi_logloss: 0.855447\n",
      "[227]\ttraining's multi_logloss: 0.681212\tvalid_1's multi_logloss: 0.854638\n",
      "[228]\ttraining's multi_logloss: 0.679923\tvalid_1's multi_logloss: 0.853804\n",
      "[229]\ttraining's multi_logloss: 0.678612\tvalid_1's multi_logloss: 0.852938\n",
      "[230]\ttraining's multi_logloss: 0.677315\tvalid_1's multi_logloss: 0.852145\n",
      "[231]\ttraining's multi_logloss: 0.676056\tvalid_1's multi_logloss: 0.851357\n",
      "[232]\ttraining's multi_logloss: 0.674766\tvalid_1's multi_logloss: 0.850575\n",
      "[233]\ttraining's multi_logloss: 0.673539\tvalid_1's multi_logloss: 0.849806\n",
      "[234]\ttraining's multi_logloss: 0.672311\tvalid_1's multi_logloss: 0.849043\n",
      "[235]\ttraining's multi_logloss: 0.671044\tvalid_1's multi_logloss: 0.84827\n",
      "[236]\ttraining's multi_logloss: 0.669818\tvalid_1's multi_logloss: 0.847509\n",
      "[237]\ttraining's multi_logloss: 0.668607\tvalid_1's multi_logloss: 0.846789\n",
      "[238]\ttraining's multi_logloss: 0.667387\tvalid_1's multi_logloss: 0.846025\n",
      "[239]\ttraining's multi_logloss: 0.666184\tvalid_1's multi_logloss: 0.845242\n",
      "[240]\ttraining's multi_logloss: 0.664981\tvalid_1's multi_logloss: 0.844493\n",
      "[241]\ttraining's multi_logloss: 0.663798\tvalid_1's multi_logloss: 0.843779\n",
      "[242]\ttraining's multi_logloss: 0.662622\tvalid_1's multi_logloss: 0.843085\n",
      "[243]\ttraining's multi_logloss: 0.661454\tvalid_1's multi_logloss: 0.842389\n",
      "[244]\ttraining's multi_logloss: 0.660301\tvalid_1's multi_logloss: 0.84169\n",
      "[245]\ttraining's multi_logloss: 0.659146\tvalid_1's multi_logloss: 0.840995\n",
      "[246]\ttraining's multi_logloss: 0.658008\tvalid_1's multi_logloss: 0.840308\n",
      "[247]\ttraining's multi_logloss: 0.656886\tvalid_1's multi_logloss: 0.839646\n",
      "[248]\ttraining's multi_logloss: 0.65577\tvalid_1's multi_logloss: 0.838998\n",
      "[249]\ttraining's multi_logloss: 0.654653\tvalid_1's multi_logloss: 0.838312\n",
      "[250]\ttraining's multi_logloss: 0.65355\tvalid_1's multi_logloss: 0.837643\n",
      "[251]\ttraining's multi_logloss: 0.652453\tvalid_1's multi_logloss: 0.836977\n",
      "[252]\ttraining's multi_logloss: 0.651359\tvalid_1's multi_logloss: 0.836354\n",
      "[253]\ttraining's multi_logloss: 0.650273\tvalid_1's multi_logloss: 0.835718\n",
      "[254]\ttraining's multi_logloss: 0.649201\tvalid_1's multi_logloss: 0.835067\n",
      "[255]\ttraining's multi_logloss: 0.648096\tvalid_1's multi_logloss: 0.834419\n",
      "[256]\ttraining's multi_logloss: 0.647043\tvalid_1's multi_logloss: 0.833825\n",
      "[257]\ttraining's multi_logloss: 0.64596\tvalid_1's multi_logloss: 0.833172\n",
      "[258]\ttraining's multi_logloss: 0.644924\tvalid_1's multi_logloss: 0.832607\n",
      "[259]\ttraining's multi_logloss: 0.643856\tvalid_1's multi_logloss: 0.832002\n",
      "[260]\ttraining's multi_logloss: 0.642823\tvalid_1's multi_logloss: 0.831388\n",
      "[261]\ttraining's multi_logloss: 0.641784\tvalid_1's multi_logloss: 0.830823\n",
      "[262]\ttraining's multi_logloss: 0.640756\tvalid_1's multi_logloss: 0.83027\n",
      "[263]\ttraining's multi_logloss: 0.639742\tvalid_1's multi_logloss: 0.829666\n",
      "[264]\ttraining's multi_logloss: 0.638725\tvalid_1's multi_logloss: 0.829122\n",
      "[265]\ttraining's multi_logloss: 0.637736\tvalid_1's multi_logloss: 0.828519\n",
      "[266]\ttraining's multi_logloss: 0.636731\tvalid_1's multi_logloss: 0.827953\n",
      "[267]\ttraining's multi_logloss: 0.63575\tvalid_1's multi_logloss: 0.827408\n",
      "[268]\ttraining's multi_logloss: 0.634762\tvalid_1's multi_logloss: 0.826879\n",
      "[269]\ttraining's multi_logloss: 0.633764\tvalid_1's multi_logloss: 0.826336\n",
      "[270]\ttraining's multi_logloss: 0.63281\tvalid_1's multi_logloss: 0.825814\n",
      "[271]\ttraining's multi_logloss: 0.631841\tvalid_1's multi_logloss: 0.825303\n",
      "[272]\ttraining's multi_logloss: 0.630884\tvalid_1's multi_logloss: 0.824756\n",
      "[273]\ttraining's multi_logloss: 0.629919\tvalid_1's multi_logloss: 0.82426\n",
      "[274]\ttraining's multi_logloss: 0.62897\tvalid_1's multi_logloss: 0.82377\n",
      "[275]\ttraining's multi_logloss: 0.628023\tvalid_1's multi_logloss: 0.823248\n",
      "[276]\ttraining's multi_logloss: 0.627064\tvalid_1's multi_logloss: 0.822679\n",
      "[277]\ttraining's multi_logloss: 0.626129\tvalid_1's multi_logloss: 0.822195\n",
      "[278]\ttraining's multi_logloss: 0.625177\tvalid_1's multi_logloss: 0.82171\n",
      "[279]\ttraining's multi_logloss: 0.624269\tvalid_1's multi_logloss: 0.821235\n",
      "[280]\ttraining's multi_logloss: 0.623356\tvalid_1's multi_logloss: 0.820736\n",
      "[281]\ttraining's multi_logloss: 0.622469\tvalid_1's multi_logloss: 0.820261\n",
      "[282]\ttraining's multi_logloss: 0.621555\tvalid_1's multi_logloss: 0.819819\n",
      "[283]\ttraining's multi_logloss: 0.620645\tvalid_1's multi_logloss: 0.819325\n",
      "[284]\ttraining's multi_logloss: 0.619763\tvalid_1's multi_logloss: 0.818897\n",
      "[285]\ttraining's multi_logloss: 0.618872\tvalid_1's multi_logloss: 0.818416\n",
      "[286]\ttraining's multi_logloss: 0.617965\tvalid_1's multi_logloss: 0.817943\n",
      "[287]\ttraining's multi_logloss: 0.617067\tvalid_1's multi_logloss: 0.817504\n",
      "[288]\ttraining's multi_logloss: 0.616186\tvalid_1's multi_logloss: 0.817079\n",
      "[289]\ttraining's multi_logloss: 0.615312\tvalid_1's multi_logloss: 0.816622\n",
      "[290]\ttraining's multi_logloss: 0.614457\tvalid_1's multi_logloss: 0.816182\n",
      "[291]\ttraining's multi_logloss: 0.613567\tvalid_1's multi_logloss: 0.815766\n",
      "[292]\ttraining's multi_logloss: 0.612711\tvalid_1's multi_logloss: 0.815369\n",
      "[293]\ttraining's multi_logloss: 0.611847\tvalid_1's multi_logloss: 0.814926\n",
      "[294]\ttraining's multi_logloss: 0.611008\tvalid_1's multi_logloss: 0.814506\n",
      "[295]\ttraining's multi_logloss: 0.610135\tvalid_1's multi_logloss: 0.814099\n",
      "[296]\ttraining's multi_logloss: 0.609303\tvalid_1's multi_logloss: 0.813715\n",
      "[297]\ttraining's multi_logloss: 0.60848\tvalid_1's multi_logloss: 0.813292\n",
      "[298]\ttraining's multi_logloss: 0.607653\tvalid_1's multi_logloss: 0.812882\n",
      "[299]\ttraining's multi_logloss: 0.60682\tvalid_1's multi_logloss: 0.812458\n",
      "[300]\ttraining's multi_logloss: 0.60599\tvalid_1's multi_logloss: 0.812065\n",
      "[301]\ttraining's multi_logloss: 0.605154\tvalid_1's multi_logloss: 0.81167\n",
      "[302]\ttraining's multi_logloss: 0.604338\tvalid_1's multi_logloss: 0.811244\n",
      "[303]\ttraining's multi_logloss: 0.603535\tvalid_1's multi_logloss: 0.810859\n",
      "[304]\ttraining's multi_logloss: 0.602753\tvalid_1's multi_logloss: 0.810455\n",
      "[305]\ttraining's multi_logloss: 0.60197\tvalid_1's multi_logloss: 0.810103\n",
      "[306]\ttraining's multi_logloss: 0.601188\tvalid_1's multi_logloss: 0.809713\n",
      "[307]\ttraining's multi_logloss: 0.600404\tvalid_1's multi_logloss: 0.80937\n",
      "[308]\ttraining's multi_logloss: 0.599604\tvalid_1's multi_logloss: 0.808968\n",
      "[309]\ttraining's multi_logloss: 0.59882\tvalid_1's multi_logloss: 0.808591\n",
      "[310]\ttraining's multi_logloss: 0.59803\tvalid_1's multi_logloss: 0.808246\n",
      "[311]\ttraining's multi_logloss: 0.597265\tvalid_1's multi_logloss: 0.807902\n",
      "[312]\ttraining's multi_logloss: 0.596476\tvalid_1's multi_logloss: 0.807567\n",
      "[313]\ttraining's multi_logloss: 0.595695\tvalid_1's multi_logloss: 0.807217\n",
      "[314]\ttraining's multi_logloss: 0.594939\tvalid_1's multi_logloss: 0.806897\n",
      "[315]\ttraining's multi_logloss: 0.594169\tvalid_1's multi_logloss: 0.806534\n",
      "[316]\ttraining's multi_logloss: 0.593422\tvalid_1's multi_logloss: 0.806216\n",
      "[317]\ttraining's multi_logloss: 0.59266\tvalid_1's multi_logloss: 0.805884\n",
      "[318]\ttraining's multi_logloss: 0.5919\tvalid_1's multi_logloss: 0.805573\n",
      "[319]\ttraining's multi_logloss: 0.59115\tvalid_1's multi_logloss: 0.805249\n",
      "[320]\ttraining's multi_logloss: 0.590407\tvalid_1's multi_logloss: 0.804917\n",
      "[321]\ttraining's multi_logloss: 0.589649\tvalid_1's multi_logloss: 0.804598\n",
      "[322]\ttraining's multi_logloss: 0.58892\tvalid_1's multi_logloss: 0.80426\n",
      "[323]\ttraining's multi_logloss: 0.588203\tvalid_1's multi_logloss: 0.80396\n",
      "[324]\ttraining's multi_logloss: 0.587486\tvalid_1's multi_logloss: 0.803634\n",
      "[325]\ttraining's multi_logloss: 0.586774\tvalid_1's multi_logloss: 0.803303\n",
      "[326]\ttraining's multi_logloss: 0.586062\tvalid_1's multi_logloss: 0.803012\n",
      "[327]\ttraining's multi_logloss: 0.585348\tvalid_1's multi_logloss: 0.802697\n",
      "[328]\ttraining's multi_logloss: 0.584641\tvalid_1's multi_logloss: 0.802399\n",
      "[329]\ttraining's multi_logloss: 0.583917\tvalid_1's multi_logloss: 0.802106\n",
      "[330]\ttraining's multi_logloss: 0.583225\tvalid_1's multi_logloss: 0.801831\n",
      "[331]\ttraining's multi_logloss: 0.582514\tvalid_1's multi_logloss: 0.801536\n",
      "[332]\ttraining's multi_logloss: 0.581804\tvalid_1's multi_logloss: 0.801233\n",
      "[333]\ttraining's multi_logloss: 0.581095\tvalid_1's multi_logloss: 0.800975\n",
      "[334]\ttraining's multi_logloss: 0.580405\tvalid_1's multi_logloss: 0.800683\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[335]\ttraining's multi_logloss: 0.579725\tvalid_1's multi_logloss: 0.800407\n",
      "[336]\ttraining's multi_logloss: 0.579016\tvalid_1's multi_logloss: 0.800111\n",
      "[337]\ttraining's multi_logloss: 0.578353\tvalid_1's multi_logloss: 0.799847\n",
      "[338]\ttraining's multi_logloss: 0.577666\tvalid_1's multi_logloss: 0.799572\n",
      "[339]\ttraining's multi_logloss: 0.576983\tvalid_1's multi_logloss: 0.799305\n",
      "[340]\ttraining's multi_logloss: 0.576324\tvalid_1's multi_logloss: 0.799013\n",
      "[341]\ttraining's multi_logloss: 0.575644\tvalid_1's multi_logloss: 0.798756\n",
      "[342]\ttraining's multi_logloss: 0.57495\tvalid_1's multi_logloss: 0.798489\n",
      "[343]\ttraining's multi_logloss: 0.574284\tvalid_1's multi_logloss: 0.798209\n",
      "[344]\ttraining's multi_logloss: 0.573611\tvalid_1's multi_logloss: 0.797945\n",
      "[345]\ttraining's multi_logloss: 0.572947\tvalid_1's multi_logloss: 0.797671\n",
      "[346]\ttraining's multi_logloss: 0.572302\tvalid_1's multi_logloss: 0.797416\n",
      "[347]\ttraining's multi_logloss: 0.571648\tvalid_1's multi_logloss: 0.797132\n",
      "[348]\ttraining's multi_logloss: 0.570986\tvalid_1's multi_logloss: 0.796886\n",
      "[349]\ttraining's multi_logloss: 0.570326\tvalid_1's multi_logloss: 0.79664\n",
      "[350]\ttraining's multi_logloss: 0.569679\tvalid_1's multi_logloss: 0.796401\n",
      "[351]\ttraining's multi_logloss: 0.569038\tvalid_1's multi_logloss: 0.796139\n",
      "[352]\ttraining's multi_logloss: 0.568397\tvalid_1's multi_logloss: 0.795881\n",
      "[353]\ttraining's multi_logloss: 0.567767\tvalid_1's multi_logloss: 0.795636\n",
      "[354]\ttraining's multi_logloss: 0.567126\tvalid_1's multi_logloss: 0.795424\n",
      "[355]\ttraining's multi_logloss: 0.566486\tvalid_1's multi_logloss: 0.795195\n",
      "[356]\ttraining's multi_logloss: 0.565843\tvalid_1's multi_logloss: 0.794983\n",
      "[357]\ttraining's multi_logloss: 0.565203\tvalid_1's multi_logloss: 0.794759\n",
      "[358]\ttraining's multi_logloss: 0.564563\tvalid_1's multi_logloss: 0.794564\n",
      "[359]\ttraining's multi_logloss: 0.563941\tvalid_1's multi_logloss: 0.794333\n",
      "[360]\ttraining's multi_logloss: 0.563298\tvalid_1's multi_logloss: 0.794085\n",
      "[361]\ttraining's multi_logloss: 0.562677\tvalid_1's multi_logloss: 0.793862\n",
      "[362]\ttraining's multi_logloss: 0.562063\tvalid_1's multi_logloss: 0.793625\n",
      "[363]\ttraining's multi_logloss: 0.561433\tvalid_1's multi_logloss: 0.793447\n",
      "[364]\ttraining's multi_logloss: 0.560821\tvalid_1's multi_logloss: 0.793225\n",
      "[365]\ttraining's multi_logloss: 0.560222\tvalid_1's multi_logloss: 0.793023\n",
      "[366]\ttraining's multi_logloss: 0.559608\tvalid_1's multi_logloss: 0.792836\n",
      "[367]\ttraining's multi_logloss: 0.559003\tvalid_1's multi_logloss: 0.792625\n",
      "[368]\ttraining's multi_logloss: 0.558403\tvalid_1's multi_logloss: 0.792419\n",
      "[369]\ttraining's multi_logloss: 0.557789\tvalid_1's multi_logloss: 0.792222\n",
      "[370]\ttraining's multi_logloss: 0.557162\tvalid_1's multi_logloss: 0.792001\n",
      "[371]\ttraining's multi_logloss: 0.556564\tvalid_1's multi_logloss: 0.791827\n",
      "[372]\ttraining's multi_logloss: 0.555949\tvalid_1's multi_logloss: 0.791627\n",
      "[373]\ttraining's multi_logloss: 0.555348\tvalid_1's multi_logloss: 0.791422\n",
      "[374]\ttraining's multi_logloss: 0.554752\tvalid_1's multi_logloss: 0.791229\n",
      "[375]\ttraining's multi_logloss: 0.554147\tvalid_1's multi_logloss: 0.791053\n",
      "[376]\ttraining's multi_logloss: 0.553568\tvalid_1's multi_logloss: 0.790839\n",
      "[377]\ttraining's multi_logloss: 0.552988\tvalid_1's multi_logloss: 0.790676\n",
      "[378]\ttraining's multi_logloss: 0.552397\tvalid_1's multi_logloss: 0.790488\n",
      "[379]\ttraining's multi_logloss: 0.551827\tvalid_1's multi_logloss: 0.790303\n",
      "[380]\ttraining's multi_logloss: 0.55124\tvalid_1's multi_logloss: 0.790106\n",
      "[381]\ttraining's multi_logloss: 0.550641\tvalid_1's multi_logloss: 0.789913\n",
      "[382]\ttraining's multi_logloss: 0.550063\tvalid_1's multi_logloss: 0.789746\n",
      "[383]\ttraining's multi_logloss: 0.549485\tvalid_1's multi_logloss: 0.789566\n",
      "[384]\ttraining's multi_logloss: 0.548925\tvalid_1's multi_logloss: 0.789361\n",
      "[385]\ttraining's multi_logloss: 0.548348\tvalid_1's multi_logloss: 0.789169\n",
      "[386]\ttraining's multi_logloss: 0.547779\tvalid_1's multi_logloss: 0.789003\n",
      "[387]\ttraining's multi_logloss: 0.547199\tvalid_1's multi_logloss: 0.788835\n",
      "[388]\ttraining's multi_logloss: 0.546628\tvalid_1's multi_logloss: 0.788645\n",
      "[389]\ttraining's multi_logloss: 0.546051\tvalid_1's multi_logloss: 0.788486\n",
      "[390]\ttraining's multi_logloss: 0.545481\tvalid_1's multi_logloss: 0.788317\n",
      "[391]\ttraining's multi_logloss: 0.544913\tvalid_1's multi_logloss: 0.788151\n",
      "[392]\ttraining's multi_logloss: 0.544352\tvalid_1's multi_logloss: 0.787996\n",
      "[393]\ttraining's multi_logloss: 0.543795\tvalid_1's multi_logloss: 0.787842\n",
      "[394]\ttraining's multi_logloss: 0.543221\tvalid_1's multi_logloss: 0.78767\n",
      "[395]\ttraining's multi_logloss: 0.542678\tvalid_1's multi_logloss: 0.787502\n",
      "[396]\ttraining's multi_logloss: 0.542117\tvalid_1's multi_logloss: 0.78735\n",
      "[397]\ttraining's multi_logloss: 0.541569\tvalid_1's multi_logloss: 0.787181\n",
      "[398]\ttraining's multi_logloss: 0.54101\tvalid_1's multi_logloss: 0.78701\n",
      "[399]\ttraining's multi_logloss: 0.540458\tvalid_1's multi_logloss: 0.786849\n",
      "[400]\ttraining's multi_logloss: 0.539916\tvalid_1's multi_logloss: 0.786684\n",
      "[401]\ttraining's multi_logloss: 0.539361\tvalid_1's multi_logloss: 0.786513\n",
      "[402]\ttraining's multi_logloss: 0.53882\tvalid_1's multi_logloss: 0.786355\n",
      "[403]\ttraining's multi_logloss: 0.538272\tvalid_1's multi_logloss: 0.786227\n",
      "[404]\ttraining's multi_logloss: 0.537724\tvalid_1's multi_logloss: 0.78605\n",
      "[405]\ttraining's multi_logloss: 0.537197\tvalid_1's multi_logloss: 0.785869\n",
      "[406]\ttraining's multi_logloss: 0.53666\tvalid_1's multi_logloss: 0.785684\n",
      "[407]\ttraining's multi_logloss: 0.536115\tvalid_1's multi_logloss: 0.785512\n",
      "[408]\ttraining's multi_logloss: 0.53559\tvalid_1's multi_logloss: 0.785382\n",
      "[409]\ttraining's multi_logloss: 0.535056\tvalid_1's multi_logloss: 0.785247\n",
      "[410]\ttraining's multi_logloss: 0.53453\tvalid_1's multi_logloss: 0.785117\n",
      "[411]\ttraining's multi_logloss: 0.534003\tvalid_1's multi_logloss: 0.784996\n",
      "[412]\ttraining's multi_logloss: 0.533485\tvalid_1's multi_logloss: 0.784854\n",
      "[413]\ttraining's multi_logloss: 0.532954\tvalid_1's multi_logloss: 0.784732\n",
      "[414]\ttraining's multi_logloss: 0.53242\tvalid_1's multi_logloss: 0.784582\n",
      "[415]\ttraining's multi_logloss: 0.531893\tvalid_1's multi_logloss: 0.78445\n",
      "[416]\ttraining's multi_logloss: 0.531375\tvalid_1's multi_logloss: 0.784303\n",
      "[417]\ttraining's multi_logloss: 0.530848\tvalid_1's multi_logloss: 0.784176\n",
      "[418]\ttraining's multi_logloss: 0.530342\tvalid_1's multi_logloss: 0.784031\n",
      "[419]\ttraining's multi_logloss: 0.529834\tvalid_1's multi_logloss: 0.78391\n",
      "[420]\ttraining's multi_logloss: 0.529323\tvalid_1's multi_logloss: 0.783815\n",
      "[421]\ttraining's multi_logloss: 0.528815\tvalid_1's multi_logloss: 0.783688\n",
      "[422]\ttraining's multi_logloss: 0.528321\tvalid_1's multi_logloss: 0.783558\n",
      "[423]\ttraining's multi_logloss: 0.52783\tvalid_1's multi_logloss: 0.783457\n",
      "[424]\ttraining's multi_logloss: 0.527308\tvalid_1's multi_logloss: 0.783251\n",
      "[425]\ttraining's multi_logloss: 0.526806\tvalid_1's multi_logloss: 0.783142\n",
      "[426]\ttraining's multi_logloss: 0.526311\tvalid_1's multi_logloss: 0.783022\n",
      "[427]\ttraining's multi_logloss: 0.525808\tvalid_1's multi_logloss: 0.782905\n",
      "[428]\ttraining's multi_logloss: 0.525315\tvalid_1's multi_logloss: 0.782757\n",
      "[429]\ttraining's multi_logloss: 0.524825\tvalid_1's multi_logloss: 0.782629\n",
      "[430]\ttraining's multi_logloss: 0.52433\tvalid_1's multi_logloss: 0.782517\n",
      "[431]\ttraining's multi_logloss: 0.52384\tvalid_1's multi_logloss: 0.782388\n",
      "[432]\ttraining's multi_logloss: 0.523354\tvalid_1's multi_logloss: 0.782286\n",
      "[433]\ttraining's multi_logloss: 0.522864\tvalid_1's multi_logloss: 0.782186\n",
      "[434]\ttraining's multi_logloss: 0.522398\tvalid_1's multi_logloss: 0.782061\n",
      "[435]\ttraining's multi_logloss: 0.521922\tvalid_1's multi_logloss: 0.781967\n",
      "[436]\ttraining's multi_logloss: 0.521427\tvalid_1's multi_logloss: 0.781831\n",
      "[437]\ttraining's multi_logloss: 0.520942\tvalid_1's multi_logloss: 0.781723\n",
      "[438]\ttraining's multi_logloss: 0.52047\tvalid_1's multi_logloss: 0.781581\n",
      "[439]\ttraining's multi_logloss: 0.51998\tvalid_1's multi_logloss: 0.781433\n",
      "[440]\ttraining's multi_logloss: 0.519511\tvalid_1's multi_logloss: 0.781313\n",
      "[441]\ttraining's multi_logloss: 0.51904\tvalid_1's multi_logloss: 0.781207\n",
      "[442]\ttraining's multi_logloss: 0.51857\tvalid_1's multi_logloss: 0.781139\n",
      "[443]\ttraining's multi_logloss: 0.518096\tvalid_1's multi_logloss: 0.781034\n",
      "[444]\ttraining's multi_logloss: 0.51763\tvalid_1's multi_logloss: 0.780923\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[445]\ttraining's multi_logloss: 0.517159\tvalid_1's multi_logloss: 0.78083\n",
      "[446]\ttraining's multi_logloss: 0.51668\tvalid_1's multi_logloss: 0.780717\n",
      "[447]\ttraining's multi_logloss: 0.516218\tvalid_1's multi_logloss: 0.780599\n",
      "[448]\ttraining's multi_logloss: 0.515743\tvalid_1's multi_logloss: 0.780528\n",
      "[449]\ttraining's multi_logloss: 0.515282\tvalid_1's multi_logloss: 0.780416\n",
      "[450]\ttraining's multi_logloss: 0.51481\tvalid_1's multi_logloss: 0.78032\n",
      "[451]\ttraining's multi_logloss: 0.514359\tvalid_1's multi_logloss: 0.780226\n",
      "[452]\ttraining's multi_logloss: 0.513894\tvalid_1's multi_logloss: 0.780134\n",
      "[453]\ttraining's multi_logloss: 0.513439\tvalid_1's multi_logloss: 0.780033\n",
      "[454]\ttraining's multi_logloss: 0.512972\tvalid_1's multi_logloss: 0.779957\n",
      "[455]\ttraining's multi_logloss: 0.512528\tvalid_1's multi_logloss: 0.779872\n",
      "[456]\ttraining's multi_logloss: 0.512079\tvalid_1's multi_logloss: 0.779789\n",
      "[457]\ttraining's multi_logloss: 0.511616\tvalid_1's multi_logloss: 0.779711\n",
      "[458]\ttraining's multi_logloss: 0.511174\tvalid_1's multi_logloss: 0.779628\n",
      "[459]\ttraining's multi_logloss: 0.51073\tvalid_1's multi_logloss: 0.779522\n",
      "[460]\ttraining's multi_logloss: 0.510267\tvalid_1's multi_logloss: 0.779433\n",
      "[461]\ttraining's multi_logloss: 0.509813\tvalid_1's multi_logloss: 0.779337\n",
      "[462]\ttraining's multi_logloss: 0.509374\tvalid_1's multi_logloss: 0.779247\n",
      "[463]\ttraining's multi_logloss: 0.508915\tvalid_1's multi_logloss: 0.779144\n",
      "[464]\ttraining's multi_logloss: 0.508469\tvalid_1's multi_logloss: 0.779053\n",
      "[465]\ttraining's multi_logloss: 0.508021\tvalid_1's multi_logloss: 0.778948\n",
      "[466]\ttraining's multi_logloss: 0.507587\tvalid_1's multi_logloss: 0.77886\n",
      "[467]\ttraining's multi_logloss: 0.507133\tvalid_1's multi_logloss: 0.778763\n",
      "[468]\ttraining's multi_logloss: 0.506673\tvalid_1's multi_logloss: 0.778677\n",
      "[469]\ttraining's multi_logloss: 0.506238\tvalid_1's multi_logloss: 0.778564\n",
      "[470]\ttraining's multi_logloss: 0.505784\tvalid_1's multi_logloss: 0.778508\n",
      "[471]\ttraining's multi_logloss: 0.505347\tvalid_1's multi_logloss: 0.77844\n",
      "[472]\ttraining's multi_logloss: 0.5049\tvalid_1's multi_logloss: 0.778358\n",
      "[473]\ttraining's multi_logloss: 0.50447\tvalid_1's multi_logloss: 0.778271\n",
      "[474]\ttraining's multi_logloss: 0.504014\tvalid_1's multi_logloss: 0.778183\n",
      "[475]\ttraining's multi_logloss: 0.503585\tvalid_1's multi_logloss: 0.778102\n",
      "[476]\ttraining's multi_logloss: 0.503164\tvalid_1's multi_logloss: 0.77802\n",
      "[477]\ttraining's multi_logloss: 0.502738\tvalid_1's multi_logloss: 0.777925\n",
      "[478]\ttraining's multi_logloss: 0.502313\tvalid_1's multi_logloss: 0.777862\n",
      "[479]\ttraining's multi_logloss: 0.50188\tvalid_1's multi_logloss: 0.777811\n",
      "[480]\ttraining's multi_logloss: 0.501461\tvalid_1's multi_logloss: 0.777743\n",
      "[481]\ttraining's multi_logloss: 0.501044\tvalid_1's multi_logloss: 0.777656\n",
      "[482]\ttraining's multi_logloss: 0.500611\tvalid_1's multi_logloss: 0.777555\n",
      "[483]\ttraining's multi_logloss: 0.500205\tvalid_1's multi_logloss: 0.777478\n",
      "[484]\ttraining's multi_logloss: 0.499779\tvalid_1's multi_logloss: 0.777394\n",
      "[485]\ttraining's multi_logloss: 0.499348\tvalid_1's multi_logloss: 0.777312\n",
      "[486]\ttraining's multi_logloss: 0.498921\tvalid_1's multi_logloss: 0.777225\n",
      "[487]\ttraining's multi_logloss: 0.498491\tvalid_1's multi_logloss: 0.777164\n",
      "[488]\ttraining's multi_logloss: 0.498076\tvalid_1's multi_logloss: 0.777098\n",
      "[489]\ttraining's multi_logloss: 0.497653\tvalid_1's multi_logloss: 0.777013\n",
      "[490]\ttraining's multi_logloss: 0.497227\tvalid_1's multi_logloss: 0.776952\n",
      "[491]\ttraining's multi_logloss: 0.49682\tvalid_1's multi_logloss: 0.776885\n",
      "[492]\ttraining's multi_logloss: 0.496405\tvalid_1's multi_logloss: 0.776835\n",
      "[493]\ttraining's multi_logloss: 0.495987\tvalid_1's multi_logloss: 0.776767\n",
      "[494]\ttraining's multi_logloss: 0.49557\tvalid_1's multi_logloss: 0.776699\n",
      "[495]\ttraining's multi_logloss: 0.495152\tvalid_1's multi_logloss: 0.776612\n",
      "[496]\ttraining's multi_logloss: 0.494728\tvalid_1's multi_logloss: 0.77656\n",
      "[497]\ttraining's multi_logloss: 0.494299\tvalid_1's multi_logloss: 0.776485\n",
      "[498]\ttraining's multi_logloss: 0.493877\tvalid_1's multi_logloss: 0.776431\n",
      "[499]\ttraining's multi_logloss: 0.493441\tvalid_1's multi_logloss: 0.776358\n",
      "[500]\ttraining's multi_logloss: 0.493046\tvalid_1's multi_logloss: 0.776298\n",
      "[501]\ttraining's multi_logloss: 0.492643\tvalid_1's multi_logloss: 0.776242\n",
      "[502]\ttraining's multi_logloss: 0.492238\tvalid_1's multi_logloss: 0.776204\n",
      "[503]\ttraining's multi_logloss: 0.491833\tvalid_1's multi_logloss: 0.776142\n",
      "[504]\ttraining's multi_logloss: 0.491428\tvalid_1's multi_logloss: 0.776092\n",
      "[505]\ttraining's multi_logloss: 0.491037\tvalid_1's multi_logloss: 0.776021\n",
      "[506]\ttraining's multi_logloss: 0.490632\tvalid_1's multi_logloss: 0.775919\n",
      "[507]\ttraining's multi_logloss: 0.490224\tvalid_1's multi_logloss: 0.775878\n",
      "[508]\ttraining's multi_logloss: 0.489803\tvalid_1's multi_logloss: 0.775807\n",
      "[509]\ttraining's multi_logloss: 0.489411\tvalid_1's multi_logloss: 0.775758\n",
      "[510]\ttraining's multi_logloss: 0.489003\tvalid_1's multi_logloss: 0.775703\n",
      "[511]\ttraining's multi_logloss: 0.488592\tvalid_1's multi_logloss: 0.775637\n",
      "[512]\ttraining's multi_logloss: 0.4882\tvalid_1's multi_logloss: 0.775593\n",
      "[513]\ttraining's multi_logloss: 0.487805\tvalid_1's multi_logloss: 0.775544\n",
      "[514]\ttraining's multi_logloss: 0.4874\tvalid_1's multi_logloss: 0.775497\n",
      "[515]\ttraining's multi_logloss: 0.486997\tvalid_1's multi_logloss: 0.775446\n",
      "[516]\ttraining's multi_logloss: 0.486612\tvalid_1's multi_logloss: 0.775397\n",
      "[517]\ttraining's multi_logloss: 0.486233\tvalid_1's multi_logloss: 0.775349\n",
      "[518]\ttraining's multi_logloss: 0.485843\tvalid_1's multi_logloss: 0.77531\n",
      "[519]\ttraining's multi_logloss: 0.485453\tvalid_1's multi_logloss: 0.775233\n",
      "[520]\ttraining's multi_logloss: 0.485059\tvalid_1's multi_logloss: 0.775192\n",
      "[521]\ttraining's multi_logloss: 0.484669\tvalid_1's multi_logloss: 0.77514\n",
      "[522]\ttraining's multi_logloss: 0.484275\tvalid_1's multi_logloss: 0.7751\n",
      "[523]\ttraining's multi_logloss: 0.483884\tvalid_1's multi_logloss: 0.77505\n",
      "[524]\ttraining's multi_logloss: 0.483501\tvalid_1's multi_logloss: 0.77501\n",
      "[525]\ttraining's multi_logloss: 0.483123\tvalid_1's multi_logloss: 0.774952\n",
      "[526]\ttraining's multi_logloss: 0.482744\tvalid_1's multi_logloss: 0.774911\n",
      "[527]\ttraining's multi_logloss: 0.482358\tvalid_1's multi_logloss: 0.774846\n",
      "[528]\ttraining's multi_logloss: 0.481971\tvalid_1's multi_logloss: 0.774785\n",
      "[529]\ttraining's multi_logloss: 0.481602\tvalid_1's multi_logloss: 0.774742\n",
      "[530]\ttraining's multi_logloss: 0.481224\tvalid_1's multi_logloss: 0.774682\n",
      "[531]\ttraining's multi_logloss: 0.480862\tvalid_1's multi_logloss: 0.774641\n",
      "[532]\ttraining's multi_logloss: 0.480484\tvalid_1's multi_logloss: 0.774621\n",
      "[533]\ttraining's multi_logloss: 0.480119\tvalid_1's multi_logloss: 0.774565\n",
      "[534]\ttraining's multi_logloss: 0.479757\tvalid_1's multi_logloss: 0.774515\n",
      "[535]\ttraining's multi_logloss: 0.479376\tvalid_1's multi_logloss: 0.774491\n",
      "[536]\ttraining's multi_logloss: 0.479008\tvalid_1's multi_logloss: 0.774459\n",
      "[537]\ttraining's multi_logloss: 0.478634\tvalid_1's multi_logloss: 0.7744\n",
      "[538]\ttraining's multi_logloss: 0.478261\tvalid_1's multi_logloss: 0.774345\n",
      "[539]\ttraining's multi_logloss: 0.477872\tvalid_1's multi_logloss: 0.774314\n",
      "[540]\ttraining's multi_logloss: 0.477515\tvalid_1's multi_logloss: 0.774281\n",
      "[541]\ttraining's multi_logloss: 0.477143\tvalid_1's multi_logloss: 0.774236\n",
      "[542]\ttraining's multi_logloss: 0.476777\tvalid_1's multi_logloss: 0.774188\n",
      "[543]\ttraining's multi_logloss: 0.476411\tvalid_1's multi_logloss: 0.77414\n",
      "[544]\ttraining's multi_logloss: 0.476031\tvalid_1's multi_logloss: 0.774074\n",
      "[545]\ttraining's multi_logloss: 0.475665\tvalid_1's multi_logloss: 0.774027\n",
      "[546]\ttraining's multi_logloss: 0.475292\tvalid_1's multi_logloss: 0.773987\n",
      "[547]\ttraining's multi_logloss: 0.474919\tvalid_1's multi_logloss: 0.773951\n",
      "[548]\ttraining's multi_logloss: 0.474543\tvalid_1's multi_logloss: 0.773942\n",
      "[549]\ttraining's multi_logloss: 0.474183\tvalid_1's multi_logloss: 0.773882\n",
      "[550]\ttraining's multi_logloss: 0.473805\tvalid_1's multi_logloss: 0.77386\n",
      "[551]\ttraining's multi_logloss: 0.47344\tvalid_1's multi_logloss: 0.773844\n",
      "[552]\ttraining's multi_logloss: 0.473087\tvalid_1's multi_logloss: 0.773798\n",
      "[553]\ttraining's multi_logloss: 0.472737\tvalid_1's multi_logloss: 0.773769\n",
      "[554]\ttraining's multi_logloss: 0.472373\tvalid_1's multi_logloss: 0.773713\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[555]\ttraining's multi_logloss: 0.472012\tvalid_1's multi_logloss: 0.773671\n",
      "[556]\ttraining's multi_logloss: 0.471664\tvalid_1's multi_logloss: 0.7736\n",
      "[557]\ttraining's multi_logloss: 0.471309\tvalid_1's multi_logloss: 0.773563\n",
      "[558]\ttraining's multi_logloss: 0.470956\tvalid_1's multi_logloss: 0.77353\n",
      "[559]\ttraining's multi_logloss: 0.470589\tvalid_1's multi_logloss: 0.773511\n",
      "[560]\ttraining's multi_logloss: 0.470214\tvalid_1's multi_logloss: 0.77346\n",
      "[561]\ttraining's multi_logloss: 0.469865\tvalid_1's multi_logloss: 0.773429\n",
      "[562]\ttraining's multi_logloss: 0.469508\tvalid_1's multi_logloss: 0.773373\n",
      "[563]\ttraining's multi_logloss: 0.469139\tvalid_1's multi_logloss: 0.773351\n",
      "[564]\ttraining's multi_logloss: 0.468784\tvalid_1's multi_logloss: 0.773342\n",
      "[565]\ttraining's multi_logloss: 0.468433\tvalid_1's multi_logloss: 0.77329\n",
      "[566]\ttraining's multi_logloss: 0.468085\tvalid_1's multi_logloss: 0.773265\n",
      "[567]\ttraining's multi_logloss: 0.467727\tvalid_1's multi_logloss: 0.77324\n",
      "[568]\ttraining's multi_logloss: 0.467374\tvalid_1's multi_logloss: 0.773206\n",
      "[569]\ttraining's multi_logloss: 0.467034\tvalid_1's multi_logloss: 0.773176\n",
      "[570]\ttraining's multi_logloss: 0.466682\tvalid_1's multi_logloss: 0.773161\n",
      "[571]\ttraining's multi_logloss: 0.466336\tvalid_1's multi_logloss: 0.773113\n",
      "[572]\ttraining's multi_logloss: 0.465998\tvalid_1's multi_logloss: 0.773087\n",
      "[573]\ttraining's multi_logloss: 0.465647\tvalid_1's multi_logloss: 0.773091\n",
      "[574]\ttraining's multi_logloss: 0.465306\tvalid_1's multi_logloss: 0.773049\n",
      "[575]\ttraining's multi_logloss: 0.464962\tvalid_1's multi_logloss: 0.773031\n",
      "[576]\ttraining's multi_logloss: 0.464631\tvalid_1's multi_logloss: 0.773005\n",
      "[577]\ttraining's multi_logloss: 0.464294\tvalid_1's multi_logloss: 0.772958\n",
      "[578]\ttraining's multi_logloss: 0.46394\tvalid_1's multi_logloss: 0.772935\n",
      "[579]\ttraining's multi_logloss: 0.46359\tvalid_1's multi_logloss: 0.772902\n",
      "[580]\ttraining's multi_logloss: 0.463252\tvalid_1's multi_logloss: 0.772882\n",
      "[581]\ttraining's multi_logloss: 0.462903\tvalid_1's multi_logloss: 0.772844\n",
      "[582]\ttraining's multi_logloss: 0.46255\tvalid_1's multi_logloss: 0.772822\n",
      "[583]\ttraining's multi_logloss: 0.462196\tvalid_1's multi_logloss: 0.772783\n",
      "[584]\ttraining's multi_logloss: 0.461861\tvalid_1's multi_logloss: 0.772764\n",
      "[585]\ttraining's multi_logloss: 0.46152\tvalid_1's multi_logloss: 0.772725\n",
      "[586]\ttraining's multi_logloss: 0.461181\tvalid_1's multi_logloss: 0.77269\n",
      "[587]\ttraining's multi_logloss: 0.460842\tvalid_1's multi_logloss: 0.772651\n",
      "[588]\ttraining's multi_logloss: 0.460505\tvalid_1's multi_logloss: 0.772631\n",
      "[589]\ttraining's multi_logloss: 0.46017\tvalid_1's multi_logloss: 0.772604\n",
      "[590]\ttraining's multi_logloss: 0.459841\tvalid_1's multi_logloss: 0.77256\n",
      "[591]\ttraining's multi_logloss: 0.459499\tvalid_1's multi_logloss: 0.772553\n",
      "[592]\ttraining's multi_logloss: 0.459166\tvalid_1's multi_logloss: 0.772525\n",
      "[593]\ttraining's multi_logloss: 0.458843\tvalid_1's multi_logloss: 0.772523\n",
      "[594]\ttraining's multi_logloss: 0.458514\tvalid_1's multi_logloss: 0.772494\n",
      "[595]\ttraining's multi_logloss: 0.458189\tvalid_1's multi_logloss: 0.772494\n",
      "[596]\ttraining's multi_logloss: 0.45786\tvalid_1's multi_logloss: 0.772468\n",
      "[597]\ttraining's multi_logloss: 0.457528\tvalid_1's multi_logloss: 0.772448\n",
      "[598]\ttraining's multi_logloss: 0.457203\tvalid_1's multi_logloss: 0.77242\n",
      "[599]\ttraining's multi_logloss: 0.456859\tvalid_1's multi_logloss: 0.772383\n",
      "[600]\ttraining's multi_logloss: 0.45654\tvalid_1's multi_logloss: 0.772349\n",
      "[601]\ttraining's multi_logloss: 0.456198\tvalid_1's multi_logloss: 0.772326\n",
      "[602]\ttraining's multi_logloss: 0.455876\tvalid_1's multi_logloss: 0.772288\n",
      "[603]\ttraining's multi_logloss: 0.455538\tvalid_1's multi_logloss: 0.772274\n",
      "[604]\ttraining's multi_logloss: 0.455218\tvalid_1's multi_logloss: 0.772263\n",
      "[605]\ttraining's multi_logloss: 0.454883\tvalid_1's multi_logloss: 0.77223\n",
      "[606]\ttraining's multi_logloss: 0.454564\tvalid_1's multi_logloss: 0.772237\n",
      "[607]\ttraining's multi_logloss: 0.454234\tvalid_1's multi_logloss: 0.772205\n",
      "[608]\ttraining's multi_logloss: 0.453911\tvalid_1's multi_logloss: 0.772187\n",
      "[609]\ttraining's multi_logloss: 0.453582\tvalid_1's multi_logloss: 0.772184\n",
      "[610]\ttraining's multi_logloss: 0.453245\tvalid_1's multi_logloss: 0.772175\n",
      "[611]\ttraining's multi_logloss: 0.452921\tvalid_1's multi_logloss: 0.772143\n",
      "[612]\ttraining's multi_logloss: 0.452602\tvalid_1's multi_logloss: 0.772132\n",
      "[613]\ttraining's multi_logloss: 0.452274\tvalid_1's multi_logloss: 0.772116\n",
      "[614]\ttraining's multi_logloss: 0.451963\tvalid_1's multi_logloss: 0.772085\n",
      "[615]\ttraining's multi_logloss: 0.451637\tvalid_1's multi_logloss: 0.772058\n",
      "[616]\ttraining's multi_logloss: 0.451332\tvalid_1's multi_logloss: 0.772045\n",
      "[617]\ttraining's multi_logloss: 0.451014\tvalid_1's multi_logloss: 0.772018\n",
      "[618]\ttraining's multi_logloss: 0.450701\tvalid_1's multi_logloss: 0.771986\n",
      "[619]\ttraining's multi_logloss: 0.450384\tvalid_1's multi_logloss: 0.771957\n",
      "[620]\ttraining's multi_logloss: 0.450071\tvalid_1's multi_logloss: 0.77192\n",
      "[621]\ttraining's multi_logloss: 0.449757\tvalid_1's multi_logloss: 0.771891\n",
      "[622]\ttraining's multi_logloss: 0.449431\tvalid_1's multi_logloss: 0.771867\n",
      "[623]\ttraining's multi_logloss: 0.449109\tvalid_1's multi_logloss: 0.771858\n",
      "[624]\ttraining's multi_logloss: 0.448799\tvalid_1's multi_logloss: 0.771844\n",
      "[625]\ttraining's multi_logloss: 0.448496\tvalid_1's multi_logloss: 0.771827\n",
      "[626]\ttraining's multi_logloss: 0.448185\tvalid_1's multi_logloss: 0.771833\n",
      "[627]\ttraining's multi_logloss: 0.447873\tvalid_1's multi_logloss: 0.771821\n",
      "[628]\ttraining's multi_logloss: 0.44756\tvalid_1's multi_logloss: 0.771801\n",
      "[629]\ttraining's multi_logloss: 0.447249\tvalid_1's multi_logloss: 0.771788\n",
      "[630]\ttraining's multi_logloss: 0.446934\tvalid_1's multi_logloss: 0.771759\n",
      "[631]\ttraining's multi_logloss: 0.44662\tvalid_1's multi_logloss: 0.771761\n",
      "[632]\ttraining's multi_logloss: 0.446304\tvalid_1's multi_logloss: 0.771747\n",
      "[633]\ttraining's multi_logloss: 0.445988\tvalid_1's multi_logloss: 0.771708\n",
      "[634]\ttraining's multi_logloss: 0.445677\tvalid_1's multi_logloss: 0.771683\n",
      "[635]\ttraining's multi_logloss: 0.445372\tvalid_1's multi_logloss: 0.771671\n",
      "[636]\ttraining's multi_logloss: 0.445057\tvalid_1's multi_logloss: 0.771655\n",
      "[637]\ttraining's multi_logloss: 0.444757\tvalid_1's multi_logloss: 0.771629\n",
      "[638]\ttraining's multi_logloss: 0.444448\tvalid_1's multi_logloss: 0.771614\n",
      "[639]\ttraining's multi_logloss: 0.44414\tvalid_1's multi_logloss: 0.771595\n",
      "[640]\ttraining's multi_logloss: 0.443835\tvalid_1's multi_logloss: 0.771582\n",
      "[641]\ttraining's multi_logloss: 0.443532\tvalid_1's multi_logloss: 0.771588\n",
      "[642]\ttraining's multi_logloss: 0.443239\tvalid_1's multi_logloss: 0.771566\n",
      "[643]\ttraining's multi_logloss: 0.442933\tvalid_1's multi_logloss: 0.771573\n",
      "[644]\ttraining's multi_logloss: 0.442625\tvalid_1's multi_logloss: 0.771558\n",
      "[645]\ttraining's multi_logloss: 0.442329\tvalid_1's multi_logloss: 0.771541\n",
      "[646]\ttraining's multi_logloss: 0.442031\tvalid_1's multi_logloss: 0.771522\n",
      "[647]\ttraining's multi_logloss: 0.44173\tvalid_1's multi_logloss: 0.771513\n",
      "[648]\ttraining's multi_logloss: 0.441437\tvalid_1's multi_logloss: 0.771509\n",
      "[649]\ttraining's multi_logloss: 0.441136\tvalid_1's multi_logloss: 0.771498\n",
      "[650]\ttraining's multi_logloss: 0.440841\tvalid_1's multi_logloss: 0.771504\n",
      "[651]\ttraining's multi_logloss: 0.440546\tvalid_1's multi_logloss: 0.771489\n",
      "[652]\ttraining's multi_logloss: 0.44025\tvalid_1's multi_logloss: 0.771481\n",
      "[653]\ttraining's multi_logloss: 0.439956\tvalid_1's multi_logloss: 0.771467\n",
      "[654]\ttraining's multi_logloss: 0.439653\tvalid_1's multi_logloss: 0.771451\n",
      "[655]\ttraining's multi_logloss: 0.439357\tvalid_1's multi_logloss: 0.771423\n",
      "[656]\ttraining's multi_logloss: 0.439063\tvalid_1's multi_logloss: 0.771413\n",
      "[657]\ttraining's multi_logloss: 0.438779\tvalid_1's multi_logloss: 0.771405\n",
      "[658]\ttraining's multi_logloss: 0.438492\tvalid_1's multi_logloss: 0.7714\n",
      "[659]\ttraining's multi_logloss: 0.438201\tvalid_1's multi_logloss: 0.771404\n",
      "[660]\ttraining's multi_logloss: 0.437908\tvalid_1's multi_logloss: 0.771398\n",
      "[661]\ttraining's multi_logloss: 0.437616\tvalid_1's multi_logloss: 0.771384\n",
      "[662]\ttraining's multi_logloss: 0.437323\tvalid_1's multi_logloss: 0.771379\n",
      "[663]\ttraining's multi_logloss: 0.437032\tvalid_1's multi_logloss: 0.771363\n",
      "[664]\ttraining's multi_logloss: 0.436734\tvalid_1's multi_logloss: 0.771356\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[665]\ttraining's multi_logloss: 0.436445\tvalid_1's multi_logloss: 0.771343\n",
      "[666]\ttraining's multi_logloss: 0.436155\tvalid_1's multi_logloss: 0.771334\n",
      "[667]\ttraining's multi_logloss: 0.43587\tvalid_1's multi_logloss: 0.771307\n",
      "[668]\ttraining's multi_logloss: 0.435574\tvalid_1's multi_logloss: 0.771288\n",
      "[669]\ttraining's multi_logloss: 0.43528\tvalid_1's multi_logloss: 0.771267\n",
      "[670]\ttraining's multi_logloss: 0.434989\tvalid_1's multi_logloss: 0.771249\n",
      "[671]\ttraining's multi_logloss: 0.434692\tvalid_1's multi_logloss: 0.771244\n",
      "[672]\ttraining's multi_logloss: 0.434394\tvalid_1's multi_logloss: 0.771224\n",
      "[673]\ttraining's multi_logloss: 0.434126\tvalid_1's multi_logloss: 0.771213\n",
      "[674]\ttraining's multi_logloss: 0.433838\tvalid_1's multi_logloss: 0.771211\n",
      "[675]\ttraining's multi_logloss: 0.433543\tvalid_1's multi_logloss: 0.771212\n",
      "[676]\ttraining's multi_logloss: 0.433261\tvalid_1's multi_logloss: 0.771208\n",
      "[677]\ttraining's multi_logloss: 0.432969\tvalid_1's multi_logloss: 0.771225\n",
      "[678]\ttraining's multi_logloss: 0.432674\tvalid_1's multi_logloss: 0.77122\n",
      "[679]\ttraining's multi_logloss: 0.432384\tvalid_1's multi_logloss: 0.771209\n",
      "[680]\ttraining's multi_logloss: 0.432115\tvalid_1's multi_logloss: 0.771204\n",
      "[681]\ttraining's multi_logloss: 0.431823\tvalid_1's multi_logloss: 0.771219\n",
      "[682]\ttraining's multi_logloss: 0.431542\tvalid_1's multi_logloss: 0.771203\n",
      "[683]\ttraining's multi_logloss: 0.431262\tvalid_1's multi_logloss: 0.771218\n",
      "[684]\ttraining's multi_logloss: 0.430975\tvalid_1's multi_logloss: 0.771206\n",
      "[685]\ttraining's multi_logloss: 0.43069\tvalid_1's multi_logloss: 0.771213\n",
      "[686]\ttraining's multi_logloss: 0.430405\tvalid_1's multi_logloss: 0.771194\n",
      "[687]\ttraining's multi_logloss: 0.430124\tvalid_1's multi_logloss: 0.771201\n",
      "[688]\ttraining's multi_logloss: 0.429844\tvalid_1's multi_logloss: 0.771206\n",
      "[689]\ttraining's multi_logloss: 0.429562\tvalid_1's multi_logloss: 0.771194\n",
      "[690]\ttraining's multi_logloss: 0.429284\tvalid_1's multi_logloss: 0.77118\n",
      "[691]\ttraining's multi_logloss: 0.429013\tvalid_1's multi_logloss: 0.771178\n",
      "[692]\ttraining's multi_logloss: 0.428734\tvalid_1's multi_logloss: 0.77118\n",
      "[693]\ttraining's multi_logloss: 0.428455\tvalid_1's multi_logloss: 0.771172\n",
      "[694]\ttraining's multi_logloss: 0.428172\tvalid_1's multi_logloss: 0.771156\n",
      "[695]\ttraining's multi_logloss: 0.427873\tvalid_1's multi_logloss: 0.771142\n",
      "[696]\ttraining's multi_logloss: 0.427605\tvalid_1's multi_logloss: 0.771152\n",
      "[697]\ttraining's multi_logloss: 0.427336\tvalid_1's multi_logloss: 0.771162\n",
      "[698]\ttraining's multi_logloss: 0.427049\tvalid_1's multi_logloss: 0.77115\n",
      "[699]\ttraining's multi_logloss: 0.426775\tvalid_1's multi_logloss: 0.771144\n",
      "[700]\ttraining's multi_logloss: 0.426498\tvalid_1's multi_logloss: 0.771147\n",
      "[701]\ttraining's multi_logloss: 0.426222\tvalid_1's multi_logloss: 0.771165\n",
      "[702]\ttraining's multi_logloss: 0.425948\tvalid_1's multi_logloss: 0.771167\n",
      "[703]\ttraining's multi_logloss: 0.42568\tvalid_1's multi_logloss: 0.77115\n",
      "[704]\ttraining's multi_logloss: 0.425417\tvalid_1's multi_logloss: 0.771144\n",
      "[705]\ttraining's multi_logloss: 0.425155\tvalid_1's multi_logloss: 0.771157\n",
      "Early stopping, best iteration is:\n",
      "[695]\ttraining's multi_logloss: 0.427873\tvalid_1's multi_logloss: 0.771142\n"
     ]
    }
   ],
   "source": [
    "num_boost_round = 4000\n",
    "max_delta_step=0\n",
    "learning_rate=0.02\n",
    "\n",
    "params = {'objective':'multiclass',\n",
    "          'boosting_type': 'gbdt',\n",
    "          'max_depth' : -1,\n",
    "          'nthread': 4,\n",
    "          'metric': 'multi_logloss',\n",
    "          'max_delta_step': 3, \n",
    "          'num_class':38,\n",
    "          'learning_rate':learning_rate,\n",
    "          'max_delta_step':max_delta_step,\n",
    "          }\n",
    "\n",
    "# evals = [(dtrain, 'train'), (dtest, 'test')]\n",
    "\n",
    "# %%time\n",
    "# 4000, 0.008\n",
    "lightgbm_model = lightgbm.train(params = params,\n",
    "                                train_set = dtrain, \n",
    "                                valid_sets = [dtrain, dtest],\n",
    "                                num_boost_round = num_boost_round,\n",
    "                                early_stopping_rounds=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<71755x1374 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1059322 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fl, company dummie들의 컬럼으로 Sum한 값을 확인해서 둘다 mean 값 이상으로 팔린 아이템만 남긴 feature로 돌렸다. 컬럼은 1374 점수는 0.771142"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's multi_logloss: 3.42595\tvalid_1's multi_logloss: 3.43262\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[2]\ttraining's multi_logloss: 3.2662\tvalid_1's multi_logloss: 3.27737\n",
      "[3]\ttraining's multi_logloss: 3.13468\tvalid_1's multi_logloss: 3.14957\n",
      "[4]\ttraining's multi_logloss: 3.02222\tvalid_1's multi_logloss: 3.04044\n",
      "[5]\ttraining's multi_logloss: 2.92399\tvalid_1's multi_logloss: 2.94528\n",
      "[6]\ttraining's multi_logloss: 2.83658\tvalid_1's multi_logloss: 2.86055\n",
      "[7]\ttraining's multi_logloss: 2.75722\tvalid_1's multi_logloss: 2.78367\n",
      "[8]\ttraining's multi_logloss: 2.68489\tvalid_1's multi_logloss: 2.7137\n",
      "[9]\ttraining's multi_logloss: 2.61845\tvalid_1's multi_logloss: 2.64948\n",
      "[10]\ttraining's multi_logloss: 2.55698\tvalid_1's multi_logloss: 2.59027\n",
      "[11]\ttraining's multi_logloss: 2.49978\tvalid_1's multi_logloss: 2.53488\n",
      "[12]\ttraining's multi_logloss: 2.44612\tvalid_1's multi_logloss: 2.48318\n",
      "[13]\ttraining's multi_logloss: 2.39571\tvalid_1's multi_logloss: 2.43481\n",
      "[14]\ttraining's multi_logloss: 2.34826\tvalid_1's multi_logloss: 2.389\n",
      "[15]\ttraining's multi_logloss: 2.30351\tvalid_1's multi_logloss: 2.3459\n",
      "[16]\ttraining's multi_logloss: 2.26106\tvalid_1's multi_logloss: 2.30497\n",
      "[17]\ttraining's multi_logloss: 2.22064\tvalid_1's multi_logloss: 2.26596\n",
      "[18]\ttraining's multi_logloss: 2.18211\tvalid_1's multi_logloss: 2.22885\n",
      "[19]\ttraining's multi_logloss: 2.14528\tvalid_1's multi_logloss: 2.19326\n",
      "[20]\ttraining's multi_logloss: 2.11003\tvalid_1's multi_logloss: 2.15938\n",
      "[21]\ttraining's multi_logloss: 2.0764\tvalid_1's multi_logloss: 2.12706\n",
      "[22]\ttraining's multi_logloss: 2.04407\tvalid_1's multi_logloss: 2.09592\n",
      "[23]\ttraining's multi_logloss: 2.013\tvalid_1's multi_logloss: 2.06611\n",
      "[24]\ttraining's multi_logloss: 1.98305\tvalid_1's multi_logloss: 2.03733\n",
      "[25]\ttraining's multi_logloss: 1.95413\tvalid_1's multi_logloss: 2.0096\n",
      "[26]\ttraining's multi_logloss: 1.92632\tvalid_1's multi_logloss: 1.98291\n",
      "[27]\ttraining's multi_logloss: 1.8993\tvalid_1's multi_logloss: 1.95701\n",
      "[28]\ttraining's multi_logloss: 1.87325\tvalid_1's multi_logloss: 1.93203\n",
      "[29]\ttraining's multi_logloss: 1.84818\tvalid_1's multi_logloss: 1.90798\n",
      "[30]\ttraining's multi_logloss: 1.82392\tvalid_1's multi_logloss: 1.88467\n",
      "[31]\ttraining's multi_logloss: 1.80041\tvalid_1's multi_logloss: 1.86221\n",
      "[32]\ttraining's multi_logloss: 1.77764\tvalid_1's multi_logloss: 1.84034\n",
      "[33]\ttraining's multi_logloss: 1.75547\tvalid_1's multi_logloss: 1.81916\n",
      "[34]\ttraining's multi_logloss: 1.7341\tvalid_1's multi_logloss: 1.79873\n",
      "[35]\ttraining's multi_logloss: 1.71327\tvalid_1's multi_logloss: 1.77888\n",
      "[36]\ttraining's multi_logloss: 1.6931\tvalid_1's multi_logloss: 1.75966\n",
      "[37]\ttraining's multi_logloss: 1.67353\tvalid_1's multi_logloss: 1.74097\n",
      "[38]\ttraining's multi_logloss: 1.65443\tvalid_1's multi_logloss: 1.72277\n",
      "[39]\ttraining's multi_logloss: 1.63591\tvalid_1's multi_logloss: 1.70515\n",
      "[40]\ttraining's multi_logloss: 1.61787\tvalid_1's multi_logloss: 1.68792\n",
      "[41]\ttraining's multi_logloss: 1.60034\tvalid_1's multi_logloss: 1.67121\n",
      "[42]\ttraining's multi_logloss: 1.58311\tvalid_1's multi_logloss: 1.6548\n",
      "[43]\ttraining's multi_logloss: 1.56637\tvalid_1's multi_logloss: 1.63885\n",
      "[44]\ttraining's multi_logloss: 1.55013\tvalid_1's multi_logloss: 1.62342\n",
      "[45]\ttraining's multi_logloss: 1.53428\tvalid_1's multi_logloss: 1.60838\n",
      "[46]\ttraining's multi_logloss: 1.51882\tvalid_1's multi_logloss: 1.59367\n",
      "[47]\ttraining's multi_logloss: 1.50368\tvalid_1's multi_logloss: 1.57934\n",
      "[48]\ttraining's multi_logloss: 1.48896\tvalid_1's multi_logloss: 1.56536\n",
      "[49]\ttraining's multi_logloss: 1.47456\tvalid_1's multi_logloss: 1.55179\n",
      "[50]\ttraining's multi_logloss: 1.46046\tvalid_1's multi_logloss: 1.53847\n",
      "[51]\ttraining's multi_logloss: 1.44666\tvalid_1's multi_logloss: 1.52542\n",
      "[52]\ttraining's multi_logloss: 1.43319\tvalid_1's multi_logloss: 1.51269\n",
      "[53]\ttraining's multi_logloss: 1.41997\tvalid_1's multi_logloss: 1.50028\n",
      "[54]\ttraining's multi_logloss: 1.4071\tvalid_1's multi_logloss: 1.48811\n",
      "[55]\ttraining's multi_logloss: 1.39453\tvalid_1's multi_logloss: 1.47631\n",
      "[56]\ttraining's multi_logloss: 1.38219\tvalid_1's multi_logloss: 1.46471\n",
      "[57]\ttraining's multi_logloss: 1.37015\tvalid_1's multi_logloss: 1.45338\n",
      "[58]\ttraining's multi_logloss: 1.35834\tvalid_1's multi_logloss: 1.44227\n",
      "[59]\ttraining's multi_logloss: 1.34674\tvalid_1's multi_logloss: 1.43136\n",
      "[60]\ttraining's multi_logloss: 1.33547\tvalid_1's multi_logloss: 1.42079\n",
      "[61]\ttraining's multi_logloss: 1.32435\tvalid_1's multi_logloss: 1.41037\n",
      "[62]\ttraining's multi_logloss: 1.31347\tvalid_1's multi_logloss: 1.40022\n",
      "[63]\ttraining's multi_logloss: 1.3028\tvalid_1's multi_logloss: 1.39023\n",
      "[64]\ttraining's multi_logloss: 1.29234\tvalid_1's multi_logloss: 1.38042\n",
      "[65]\ttraining's multi_logloss: 1.28208\tvalid_1's multi_logloss: 1.3708\n",
      "[66]\ttraining's multi_logloss: 1.27202\tvalid_1's multi_logloss: 1.3614\n",
      "[67]\ttraining's multi_logloss: 1.26219\tvalid_1's multi_logloss: 1.35217\n",
      "[68]\ttraining's multi_logloss: 1.25249\tvalid_1's multi_logloss: 1.34309\n",
      "[69]\ttraining's multi_logloss: 1.24302\tvalid_1's multi_logloss: 1.33422\n",
      "[70]\ttraining's multi_logloss: 1.23373\tvalid_1's multi_logloss: 1.32558\n",
      "[71]\ttraining's multi_logloss: 1.22456\tvalid_1's multi_logloss: 1.31703\n",
      "[72]\ttraining's multi_logloss: 1.21561\tvalid_1's multi_logloss: 1.30869\n",
      "[73]\ttraining's multi_logloss: 1.20686\tvalid_1's multi_logloss: 1.30056\n",
      "[74]\ttraining's multi_logloss: 1.1982\tvalid_1's multi_logloss: 1.29259\n",
      "[75]\ttraining's multi_logloss: 1.18971\tvalid_1's multi_logloss: 1.28473\n",
      "[76]\ttraining's multi_logloss: 1.1814\tvalid_1's multi_logloss: 1.27704\n",
      "[77]\ttraining's multi_logloss: 1.17327\tvalid_1's multi_logloss: 1.26958\n",
      "[78]\ttraining's multi_logloss: 1.16524\tvalid_1's multi_logloss: 1.26221\n",
      "[79]\ttraining's multi_logloss: 1.15737\tvalid_1's multi_logloss: 1.25494\n",
      "[80]\ttraining's multi_logloss: 1.14964\tvalid_1's multi_logloss: 1.24784\n",
      "[81]\ttraining's multi_logloss: 1.14204\tvalid_1's multi_logloss: 1.24084\n",
      "[82]\ttraining's multi_logloss: 1.13459\tvalid_1's multi_logloss: 1.23403\n",
      "[83]\ttraining's multi_logloss: 1.12726\tvalid_1's multi_logloss: 1.22729\n",
      "[84]\ttraining's multi_logloss: 1.12002\tvalid_1's multi_logloss: 1.2207\n",
      "[85]\ttraining's multi_logloss: 1.11289\tvalid_1's multi_logloss: 1.21418\n",
      "[86]\ttraining's multi_logloss: 1.10594\tvalid_1's multi_logloss: 1.20784\n",
      "[87]\ttraining's multi_logloss: 1.0991\tvalid_1's multi_logloss: 1.20157\n",
      "[88]\ttraining's multi_logloss: 1.09235\tvalid_1's multi_logloss: 1.19539\n",
      "[89]\ttraining's multi_logloss: 1.08567\tvalid_1's multi_logloss: 1.18932\n",
      "[90]\ttraining's multi_logloss: 1.07914\tvalid_1's multi_logloss: 1.18338\n",
      "[91]\ttraining's multi_logloss: 1.07273\tvalid_1's multi_logloss: 1.17758\n",
      "[92]\ttraining's multi_logloss: 1.06641\tvalid_1's multi_logloss: 1.17185\n",
      "[93]\ttraining's multi_logloss: 1.06018\tvalid_1's multi_logloss: 1.16618\n",
      "[94]\ttraining's multi_logloss: 1.05405\tvalid_1's multi_logloss: 1.16069\n",
      "[95]\ttraining's multi_logloss: 1.04807\tvalid_1's multi_logloss: 1.15532\n",
      "[96]\ttraining's multi_logloss: 1.04213\tvalid_1's multi_logloss: 1.14995\n",
      "[97]\ttraining's multi_logloss: 1.03634\tvalid_1's multi_logloss: 1.14471\n",
      "[98]\ttraining's multi_logloss: 1.03058\tvalid_1's multi_logloss: 1.13951\n",
      "[99]\ttraining's multi_logloss: 1.02489\tvalid_1's multi_logloss: 1.13446\n",
      "[100]\ttraining's multi_logloss: 1.01935\tvalid_1's multi_logloss: 1.12951\n",
      "[101]\ttraining's multi_logloss: 1.01389\tvalid_1's multi_logloss: 1.12466\n",
      "[102]\ttraining's multi_logloss: 1.0085\tvalid_1's multi_logloss: 1.11984\n",
      "[103]\ttraining's multi_logloss: 1.00316\tvalid_1's multi_logloss: 1.11509\n",
      "[104]\ttraining's multi_logloss: 0.997967\tvalid_1's multi_logloss: 1.11047\n",
      "[105]\ttraining's multi_logloss: 0.992837\tvalid_1's multi_logloss: 1.10592\n",
      "[106]\ttraining's multi_logloss: 0.987782\tvalid_1's multi_logloss: 1.10143\n",
      "[107]\ttraining's multi_logloss: 0.982794\tvalid_1's multi_logloss: 1.09701\n",
      "[108]\ttraining's multi_logloss: 0.977817\tvalid_1's multi_logloss: 1.09261\n",
      "[109]\ttraining's multi_logloss: 0.972976\tvalid_1's multi_logloss: 1.08833\n",
      "[110]\ttraining's multi_logloss: 0.968165\tvalid_1's multi_logloss: 1.08408\n",
      "[111]\ttraining's multi_logloss: 0.963465\tvalid_1's multi_logloss: 1.07991\n",
      "[112]\ttraining's multi_logloss: 0.95878\tvalid_1's multi_logloss: 1.07579\n",
      "[113]\ttraining's multi_logloss: 0.954218\tvalid_1's multi_logloss: 1.0718\n",
      "[114]\ttraining's multi_logloss: 0.949698\tvalid_1's multi_logloss: 1.06785\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[115]\ttraining's multi_logloss: 0.945275\tvalid_1's multi_logloss: 1.06397\n",
      "[116]\ttraining's multi_logloss: 0.940863\tvalid_1's multi_logloss: 1.06011\n",
      "[117]\ttraining's multi_logloss: 0.936589\tvalid_1's multi_logloss: 1.05631\n",
      "[118]\ttraining's multi_logloss: 0.932323\tvalid_1's multi_logloss: 1.05258\n",
      "[119]\ttraining's multi_logloss: 0.92816\tvalid_1's multi_logloss: 1.04894\n",
      "[120]\ttraining's multi_logloss: 0.923983\tvalid_1's multi_logloss: 1.04531\n",
      "[121]\ttraining's multi_logloss: 0.919909\tvalid_1's multi_logloss: 1.04181\n",
      "[122]\ttraining's multi_logloss: 0.915917\tvalid_1's multi_logloss: 1.03834\n",
      "[123]\ttraining's multi_logloss: 0.91197\tvalid_1's multi_logloss: 1.03496\n",
      "[124]\ttraining's multi_logloss: 0.908037\tvalid_1's multi_logloss: 1.03156\n",
      "[125]\ttraining's multi_logloss: 0.90418\tvalid_1's multi_logloss: 1.02822\n",
      "[126]\ttraining's multi_logloss: 0.900388\tvalid_1's multi_logloss: 1.02496\n",
      "[127]\ttraining's multi_logloss: 0.89664\tvalid_1's multi_logloss: 1.02173\n",
      "[128]\ttraining's multi_logloss: 0.892916\tvalid_1's multi_logloss: 1.01854\n",
      "[129]\ttraining's multi_logloss: 0.88928\tvalid_1's multi_logloss: 1.01545\n",
      "[130]\ttraining's multi_logloss: 0.885675\tvalid_1's multi_logloss: 1.01236\n",
      "[131]\ttraining's multi_logloss: 0.882106\tvalid_1's multi_logloss: 1.00928\n",
      "[132]\ttraining's multi_logloss: 0.878585\tvalid_1's multi_logloss: 1.00627\n",
      "[133]\ttraining's multi_logloss: 0.875098\tvalid_1's multi_logloss: 1.00329\n",
      "[134]\ttraining's multi_logloss: 0.871682\tvalid_1's multi_logloss: 1.00038\n",
      "[135]\ttraining's multi_logloss: 0.868262\tvalid_1's multi_logloss: 0.997489\n",
      "[136]\ttraining's multi_logloss: 0.864934\tvalid_1's multi_logloss: 0.994676\n",
      "[137]\ttraining's multi_logloss: 0.861591\tvalid_1's multi_logloss: 0.991853\n",
      "[138]\ttraining's multi_logloss: 0.858304\tvalid_1's multi_logloss: 0.989083\n",
      "[139]\ttraining's multi_logloss: 0.855049\tvalid_1's multi_logloss: 0.986341\n",
      "[140]\ttraining's multi_logloss: 0.851862\tvalid_1's multi_logloss: 0.983671\n",
      "[141]\ttraining's multi_logloss: 0.848691\tvalid_1's multi_logloss: 0.981038\n",
      "[142]\ttraining's multi_logloss: 0.845574\tvalid_1's multi_logloss: 0.978476\n",
      "[143]\ttraining's multi_logloss: 0.842503\tvalid_1's multi_logloss: 0.975897\n",
      "[144]\ttraining's multi_logloss: 0.839463\tvalid_1's multi_logloss: 0.973384\n",
      "[145]\ttraining's multi_logloss: 0.836452\tvalid_1's multi_logloss: 0.970891\n",
      "[146]\ttraining's multi_logloss: 0.833515\tvalid_1's multi_logloss: 0.968508\n",
      "[147]\ttraining's multi_logloss: 0.830602\tvalid_1's multi_logloss: 0.966117\n",
      "[148]\ttraining's multi_logloss: 0.827718\tvalid_1's multi_logloss: 0.963744\n",
      "[149]\ttraining's multi_logloss: 0.824886\tvalid_1's multi_logloss: 0.961446\n",
      "[150]\ttraining's multi_logloss: 0.82205\tvalid_1's multi_logloss: 0.959101\n",
      "[151]\ttraining's multi_logloss: 0.819274\tvalid_1's multi_logloss: 0.95684\n",
      "[152]\ttraining's multi_logloss: 0.816532\tvalid_1's multi_logloss: 0.954603\n",
      "[153]\ttraining's multi_logloss: 0.813841\tvalid_1's multi_logloss: 0.952374\n",
      "[154]\ttraining's multi_logloss: 0.811185\tvalid_1's multi_logloss: 0.950204\n",
      "[155]\ttraining's multi_logloss: 0.808569\tvalid_1's multi_logloss: 0.948069\n",
      "[156]\ttraining's multi_logloss: 0.805977\tvalid_1's multi_logloss: 0.945988\n",
      "[157]\ttraining's multi_logloss: 0.803406\tvalid_1's multi_logloss: 0.943886\n",
      "[158]\ttraining's multi_logloss: 0.800856\tvalid_1's multi_logloss: 0.941803\n",
      "[159]\ttraining's multi_logloss: 0.798318\tvalid_1's multi_logloss: 0.939776\n",
      "[160]\ttraining's multi_logloss: 0.795843\tvalid_1's multi_logloss: 0.937755\n",
      "[161]\ttraining's multi_logloss: 0.793402\tvalid_1's multi_logloss: 0.935786\n",
      "[162]\ttraining's multi_logloss: 0.790967\tvalid_1's multi_logloss: 0.933848\n",
      "[163]\ttraining's multi_logloss: 0.78857\tvalid_1's multi_logloss: 0.931935\n",
      "[164]\ttraining's multi_logloss: 0.786199\tvalid_1's multi_logloss: 0.930024\n",
      "[165]\ttraining's multi_logloss: 0.783836\tvalid_1's multi_logloss: 0.928145\n",
      "[166]\ttraining's multi_logloss: 0.781515\tvalid_1's multi_logloss: 0.926297\n",
      "[167]\ttraining's multi_logloss: 0.779194\tvalid_1's multi_logloss: 0.924466\n",
      "[168]\ttraining's multi_logloss: 0.776886\tvalid_1's multi_logloss: 0.922631\n",
      "[169]\ttraining's multi_logloss: 0.774622\tvalid_1's multi_logloss: 0.92082\n",
      "[170]\ttraining's multi_logloss: 0.772418\tvalid_1's multi_logloss: 0.919055\n",
      "[171]\ttraining's multi_logloss: 0.770225\tvalid_1's multi_logloss: 0.917328\n",
      "[172]\ttraining's multi_logloss: 0.768046\tvalid_1's multi_logloss: 0.915634\n",
      "[173]\ttraining's multi_logloss: 0.765901\tvalid_1's multi_logloss: 0.913964\n",
      "[174]\ttraining's multi_logloss: 0.763737\tvalid_1's multi_logloss: 0.91227\n",
      "[175]\ttraining's multi_logloss: 0.761607\tvalid_1's multi_logloss: 0.910606\n",
      "[176]\ttraining's multi_logloss: 0.759529\tvalid_1's multi_logloss: 0.90899\n",
      "[177]\ttraining's multi_logloss: 0.757453\tvalid_1's multi_logloss: 0.907373\n",
      "[178]\ttraining's multi_logloss: 0.755407\tvalid_1's multi_logloss: 0.905795\n",
      "[179]\ttraining's multi_logloss: 0.753383\tvalid_1's multi_logloss: 0.904234\n",
      "[180]\ttraining's multi_logloss: 0.751384\tvalid_1's multi_logloss: 0.902682\n",
      "[181]\ttraining's multi_logloss: 0.749361\tvalid_1's multi_logloss: 0.901082\n",
      "[182]\ttraining's multi_logloss: 0.7474\tvalid_1's multi_logloss: 0.89957\n",
      "[183]\ttraining's multi_logloss: 0.745473\tvalid_1's multi_logloss: 0.89807\n",
      "[184]\ttraining's multi_logloss: 0.743558\tvalid_1's multi_logloss: 0.89664\n",
      "[185]\ttraining's multi_logloss: 0.741633\tvalid_1's multi_logloss: 0.895186\n",
      "[186]\ttraining's multi_logloss: 0.739705\tvalid_1's multi_logloss: 0.893715\n",
      "[187]\ttraining's multi_logloss: 0.737839\tvalid_1's multi_logloss: 0.892283\n",
      "[188]\ttraining's multi_logloss: 0.736\tvalid_1's multi_logloss: 0.890904\n",
      "[189]\ttraining's multi_logloss: 0.73418\tvalid_1's multi_logloss: 0.889543\n",
      "[190]\ttraining's multi_logloss: 0.732356\tvalid_1's multi_logloss: 0.888196\n",
      "[191]\ttraining's multi_logloss: 0.730568\tvalid_1's multi_logloss: 0.886881\n",
      "[192]\ttraining's multi_logloss: 0.72876\tvalid_1's multi_logloss: 0.885542\n",
      "[193]\ttraining's multi_logloss: 0.726985\tvalid_1's multi_logloss: 0.884179\n",
      "[194]\ttraining's multi_logloss: 0.725225\tvalid_1's multi_logloss: 0.882921\n",
      "[195]\ttraining's multi_logloss: 0.723485\tvalid_1's multi_logloss: 0.881686\n",
      "[196]\ttraining's multi_logloss: 0.721763\tvalid_1's multi_logloss: 0.880382\n",
      "[197]\ttraining's multi_logloss: 0.720078\tvalid_1's multi_logloss: 0.879152\n",
      "[198]\ttraining's multi_logloss: 0.718414\tvalid_1's multi_logloss: 0.877941\n",
      "[199]\ttraining's multi_logloss: 0.716745\tvalid_1's multi_logloss: 0.876712\n",
      "[200]\ttraining's multi_logloss: 0.715101\tvalid_1's multi_logloss: 0.875561\n",
      "[201]\ttraining's multi_logloss: 0.713433\tvalid_1's multi_logloss: 0.874368\n",
      "[202]\ttraining's multi_logloss: 0.71178\tvalid_1's multi_logloss: 0.873223\n",
      "[203]\ttraining's multi_logloss: 0.710193\tvalid_1's multi_logloss: 0.872048\n",
      "[204]\ttraining's multi_logloss: 0.708598\tvalid_1's multi_logloss: 0.870921\n",
      "[205]\ttraining's multi_logloss: 0.706975\tvalid_1's multi_logloss: 0.869761\n",
      "[206]\ttraining's multi_logloss: 0.705433\tvalid_1's multi_logloss: 0.868686\n",
      "[207]\ttraining's multi_logloss: 0.703855\tvalid_1's multi_logloss: 0.867561\n",
      "[208]\ttraining's multi_logloss: 0.702284\tvalid_1's multi_logloss: 0.866437\n",
      "[209]\ttraining's multi_logloss: 0.700722\tvalid_1's multi_logloss: 0.865336\n",
      "[210]\ttraining's multi_logloss: 0.699209\tvalid_1's multi_logloss: 0.864287\n",
      "[211]\ttraining's multi_logloss: 0.697707\tvalid_1's multi_logloss: 0.863205\n",
      "[212]\ttraining's multi_logloss: 0.6962\tvalid_1's multi_logloss: 0.862142\n",
      "[213]\ttraining's multi_logloss: 0.694708\tvalid_1's multi_logloss: 0.861105\n",
      "[214]\ttraining's multi_logloss: 0.693235\tvalid_1's multi_logloss: 0.860113\n",
      "[215]\ttraining's multi_logloss: 0.691777\tvalid_1's multi_logloss: 0.859094\n",
      "[216]\ttraining's multi_logloss: 0.690325\tvalid_1's multi_logloss: 0.858063\n",
      "[217]\ttraining's multi_logloss: 0.688865\tvalid_1's multi_logloss: 0.857029\n",
      "[218]\ttraining's multi_logloss: 0.687449\tvalid_1's multi_logloss: 0.856081\n",
      "[219]\ttraining's multi_logloss: 0.686054\tvalid_1's multi_logloss: 0.855164\n",
      "[220]\ttraining's multi_logloss: 0.684667\tvalid_1's multi_logloss: 0.854214\n",
      "[221]\ttraining's multi_logloss: 0.683302\tvalid_1's multi_logloss: 0.853271\n",
      "[222]\ttraining's multi_logloss: 0.68195\tvalid_1's multi_logloss: 0.852343\n",
      "[223]\ttraining's multi_logloss: 0.680595\tvalid_1's multi_logloss: 0.851408\n",
      "[224]\ttraining's multi_logloss: 0.679229\tvalid_1's multi_logloss: 0.850489\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[225]\ttraining's multi_logloss: 0.677872\tvalid_1's multi_logloss: 0.849628\n",
      "[226]\ttraining's multi_logloss: 0.676547\tvalid_1's multi_logloss: 0.848757\n",
      "[227]\ttraining's multi_logloss: 0.67522\tvalid_1's multi_logloss: 0.847889\n",
      "[228]\ttraining's multi_logloss: 0.673903\tvalid_1's multi_logloss: 0.847028\n",
      "[229]\ttraining's multi_logloss: 0.672611\tvalid_1's multi_logloss: 0.846188\n",
      "[230]\ttraining's multi_logloss: 0.671313\tvalid_1's multi_logloss: 0.845368\n",
      "[231]\ttraining's multi_logloss: 0.670042\tvalid_1's multi_logloss: 0.84453\n",
      "[232]\ttraining's multi_logloss: 0.668757\tvalid_1's multi_logloss: 0.843701\n",
      "[233]\ttraining's multi_logloss: 0.667476\tvalid_1's multi_logloss: 0.842888\n",
      "[234]\ttraining's multi_logloss: 0.666222\tvalid_1's multi_logloss: 0.842076\n",
      "[235]\ttraining's multi_logloss: 0.664975\tvalid_1's multi_logloss: 0.841283\n",
      "[236]\ttraining's multi_logloss: 0.663723\tvalid_1's multi_logloss: 0.840474\n",
      "[237]\ttraining's multi_logloss: 0.662497\tvalid_1's multi_logloss: 0.839683\n",
      "[238]\ttraining's multi_logloss: 0.661306\tvalid_1's multi_logloss: 0.838962\n",
      "[239]\ttraining's multi_logloss: 0.660083\tvalid_1's multi_logloss: 0.838197\n",
      "[240]\ttraining's multi_logloss: 0.658883\tvalid_1's multi_logloss: 0.837441\n",
      "[241]\ttraining's multi_logloss: 0.657692\tvalid_1's multi_logloss: 0.836712\n",
      "[242]\ttraining's multi_logloss: 0.65651\tvalid_1's multi_logloss: 0.83596\n",
      "[243]\ttraining's multi_logloss: 0.655331\tvalid_1's multi_logloss: 0.835243\n",
      "[244]\ttraining's multi_logloss: 0.654152\tvalid_1's multi_logloss: 0.834479\n",
      "[245]\ttraining's multi_logloss: 0.653007\tvalid_1's multi_logloss: 0.833794\n",
      "[246]\ttraining's multi_logloss: 0.65184\tvalid_1's multi_logloss: 0.833075\n",
      "[247]\ttraining's multi_logloss: 0.650704\tvalid_1's multi_logloss: 0.832384\n",
      "[248]\ttraining's multi_logloss: 0.649578\tvalid_1's multi_logloss: 0.83171\n",
      "[249]\ttraining's multi_logloss: 0.648452\tvalid_1's multi_logloss: 0.831058\n",
      "[250]\ttraining's multi_logloss: 0.64734\tvalid_1's multi_logloss: 0.830402\n",
      "[251]\ttraining's multi_logloss: 0.646238\tvalid_1's multi_logloss: 0.829755\n",
      "[252]\ttraining's multi_logloss: 0.645132\tvalid_1's multi_logloss: 0.829109\n",
      "[253]\ttraining's multi_logloss: 0.644045\tvalid_1's multi_logloss: 0.828437\n",
      "[254]\ttraining's multi_logloss: 0.642953\tvalid_1's multi_logloss: 0.827795\n",
      "[255]\ttraining's multi_logloss: 0.641843\tvalid_1's multi_logloss: 0.827161\n",
      "[256]\ttraining's multi_logloss: 0.640785\tvalid_1's multi_logloss: 0.826563\n",
      "[257]\ttraining's multi_logloss: 0.63973\tvalid_1's multi_logloss: 0.825979\n",
      "[258]\ttraining's multi_logloss: 0.638634\tvalid_1's multi_logloss: 0.825349\n",
      "[259]\ttraining's multi_logloss: 0.637573\tvalid_1's multi_logloss: 0.824694\n",
      "[260]\ttraining's multi_logloss: 0.636535\tvalid_1's multi_logloss: 0.824081\n",
      "[261]\ttraining's multi_logloss: 0.635493\tvalid_1's multi_logloss: 0.823444\n",
      "[262]\ttraining's multi_logloss: 0.634455\tvalid_1's multi_logloss: 0.82286\n",
      "[263]\ttraining's multi_logloss: 0.633438\tvalid_1's multi_logloss: 0.822252\n",
      "[264]\ttraining's multi_logloss: 0.632405\tvalid_1's multi_logloss: 0.821696\n",
      "[265]\ttraining's multi_logloss: 0.631397\tvalid_1's multi_logloss: 0.821078\n",
      "[266]\ttraining's multi_logloss: 0.630383\tvalid_1's multi_logloss: 0.820544\n",
      "[267]\ttraining's multi_logloss: 0.629396\tvalid_1's multi_logloss: 0.819997\n",
      "[268]\ttraining's multi_logloss: 0.628404\tvalid_1's multi_logloss: 0.819446\n",
      "[269]\ttraining's multi_logloss: 0.627433\tvalid_1's multi_logloss: 0.818933\n",
      "[270]\ttraining's multi_logloss: 0.62644\tvalid_1's multi_logloss: 0.818412\n",
      "[271]\ttraining's multi_logloss: 0.625475\tvalid_1's multi_logloss: 0.817872\n",
      "[272]\ttraining's multi_logloss: 0.624493\tvalid_1's multi_logloss: 0.817329\n",
      "[273]\ttraining's multi_logloss: 0.623553\tvalid_1's multi_logloss: 0.816847\n",
      "[274]\ttraining's multi_logloss: 0.622597\tvalid_1's multi_logloss: 0.816296\n",
      "[275]\ttraining's multi_logloss: 0.621626\tvalid_1's multi_logloss: 0.815798\n",
      "[276]\ttraining's multi_logloss: 0.620698\tvalid_1's multi_logloss: 0.8153\n",
      "[277]\ttraining's multi_logloss: 0.619758\tvalid_1's multi_logloss: 0.814787\n",
      "[278]\ttraining's multi_logloss: 0.618836\tvalid_1's multi_logloss: 0.814322\n",
      "[279]\ttraining's multi_logloss: 0.617915\tvalid_1's multi_logloss: 0.813839\n",
      "[280]\ttraining's multi_logloss: 0.616984\tvalid_1's multi_logloss: 0.813348\n",
      "[281]\ttraining's multi_logloss: 0.616081\tvalid_1's multi_logloss: 0.812867\n",
      "[282]\ttraining's multi_logloss: 0.615171\tvalid_1's multi_logloss: 0.812384\n",
      "[283]\ttraining's multi_logloss: 0.614263\tvalid_1's multi_logloss: 0.811927\n",
      "[284]\ttraining's multi_logloss: 0.613346\tvalid_1's multi_logloss: 0.811454\n",
      "[285]\ttraining's multi_logloss: 0.61245\tvalid_1's multi_logloss: 0.810978\n",
      "[286]\ttraining's multi_logloss: 0.611563\tvalid_1's multi_logloss: 0.810539\n",
      "[287]\ttraining's multi_logloss: 0.610648\tvalid_1's multi_logloss: 0.810045\n",
      "[288]\ttraining's multi_logloss: 0.609766\tvalid_1's multi_logloss: 0.809616\n",
      "[289]\ttraining's multi_logloss: 0.608896\tvalid_1's multi_logloss: 0.809197\n",
      "[290]\ttraining's multi_logloss: 0.608027\tvalid_1's multi_logloss: 0.808769\n",
      "[291]\ttraining's multi_logloss: 0.607154\tvalid_1's multi_logloss: 0.808306\n",
      "[292]\ttraining's multi_logloss: 0.606275\tvalid_1's multi_logloss: 0.807909\n",
      "[293]\ttraining's multi_logloss: 0.60543\tvalid_1's multi_logloss: 0.807501\n",
      "[294]\ttraining's multi_logloss: 0.604574\tvalid_1's multi_logloss: 0.80709\n",
      "[295]\ttraining's multi_logloss: 0.603723\tvalid_1's multi_logloss: 0.806672\n",
      "[296]\ttraining's multi_logloss: 0.602884\tvalid_1's multi_logloss: 0.806231\n",
      "[297]\ttraining's multi_logloss: 0.602052\tvalid_1's multi_logloss: 0.805809\n",
      "[298]\ttraining's multi_logloss: 0.601218\tvalid_1's multi_logloss: 0.805399\n",
      "[299]\ttraining's multi_logloss: 0.600384\tvalid_1's multi_logloss: 0.804956\n",
      "[300]\ttraining's multi_logloss: 0.599543\tvalid_1's multi_logloss: 0.804594\n",
      "[301]\ttraining's multi_logloss: 0.598735\tvalid_1's multi_logloss: 0.804154\n",
      "[302]\ttraining's multi_logloss: 0.597918\tvalid_1's multi_logloss: 0.803766\n",
      "[303]\ttraining's multi_logloss: 0.597103\tvalid_1's multi_logloss: 0.803369\n",
      "[304]\ttraining's multi_logloss: 0.596275\tvalid_1's multi_logloss: 0.802927\n",
      "[305]\ttraining's multi_logloss: 0.595464\tvalid_1's multi_logloss: 0.802546\n",
      "[306]\ttraining's multi_logloss: 0.594664\tvalid_1's multi_logloss: 0.802139\n",
      "[307]\ttraining's multi_logloss: 0.593871\tvalid_1's multi_logloss: 0.80178\n",
      "[308]\ttraining's multi_logloss: 0.593085\tvalid_1's multi_logloss: 0.801441\n",
      "[309]\ttraining's multi_logloss: 0.592295\tvalid_1's multi_logloss: 0.801044\n",
      "[310]\ttraining's multi_logloss: 0.591491\tvalid_1's multi_logloss: 0.800698\n",
      "[311]\ttraining's multi_logloss: 0.590689\tvalid_1's multi_logloss: 0.800316\n",
      "[312]\ttraining's multi_logloss: 0.5899\tvalid_1's multi_logloss: 0.799978\n",
      "[313]\ttraining's multi_logloss: 0.589123\tvalid_1's multi_logloss: 0.799634\n",
      "[314]\ttraining's multi_logloss: 0.58834\tvalid_1's multi_logloss: 0.799285\n",
      "[315]\ttraining's multi_logloss: 0.587585\tvalid_1's multi_logloss: 0.79898\n",
      "[316]\ttraining's multi_logloss: 0.586811\tvalid_1's multi_logloss: 0.798657\n",
      "[317]\ttraining's multi_logloss: 0.586045\tvalid_1's multi_logloss: 0.798287\n",
      "[318]\ttraining's multi_logloss: 0.585278\tvalid_1's multi_logloss: 0.797948\n",
      "[319]\ttraining's multi_logloss: 0.584536\tvalid_1's multi_logloss: 0.797665\n",
      "[320]\ttraining's multi_logloss: 0.583759\tvalid_1's multi_logloss: 0.797308\n",
      "[321]\ttraining's multi_logloss: 0.583032\tvalid_1's multi_logloss: 0.796981\n",
      "[322]\ttraining's multi_logloss: 0.582291\tvalid_1's multi_logloss: 0.796674\n",
      "[323]\ttraining's multi_logloss: 0.581562\tvalid_1's multi_logloss: 0.796353\n",
      "[324]\ttraining's multi_logloss: 0.580835\tvalid_1's multi_logloss: 0.796043\n",
      "[325]\ttraining's multi_logloss: 0.580104\tvalid_1's multi_logloss: 0.795713\n",
      "[326]\ttraining's multi_logloss: 0.579388\tvalid_1's multi_logloss: 0.795415\n",
      "[327]\ttraining's multi_logloss: 0.578672\tvalid_1's multi_logloss: 0.795128\n",
      "[328]\ttraining's multi_logloss: 0.577957\tvalid_1's multi_logloss: 0.794846\n",
      "[329]\ttraining's multi_logloss: 0.577239\tvalid_1's multi_logloss: 0.79455\n",
      "[330]\ttraining's multi_logloss: 0.57653\tvalid_1's multi_logloss: 0.794247\n",
      "[331]\ttraining's multi_logloss: 0.575826\tvalid_1's multi_logloss: 0.793962\n",
      "[332]\ttraining's multi_logloss: 0.575127\tvalid_1's multi_logloss: 0.793664\n",
      "[333]\ttraining's multi_logloss: 0.574423\tvalid_1's multi_logloss: 0.793399\n",
      "[334]\ttraining's multi_logloss: 0.573722\tvalid_1's multi_logloss: 0.793117\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[335]\ttraining's multi_logloss: 0.573016\tvalid_1's multi_logloss: 0.792797\n",
      "[336]\ttraining's multi_logloss: 0.572335\tvalid_1's multi_logloss: 0.792537\n",
      "[337]\ttraining's multi_logloss: 0.571635\tvalid_1's multi_logloss: 0.792248\n",
      "[338]\ttraining's multi_logloss: 0.57095\tvalid_1's multi_logloss: 0.791946\n",
      "[339]\ttraining's multi_logloss: 0.570275\tvalid_1's multi_logloss: 0.791672\n",
      "[340]\ttraining's multi_logloss: 0.569605\tvalid_1's multi_logloss: 0.791389\n",
      "[341]\ttraining's multi_logloss: 0.568919\tvalid_1's multi_logloss: 0.791107\n",
      "[342]\ttraining's multi_logloss: 0.568232\tvalid_1's multi_logloss: 0.790845\n",
      "[343]\ttraining's multi_logloss: 0.567577\tvalid_1's multi_logloss: 0.790563\n",
      "[344]\ttraining's multi_logloss: 0.5669\tvalid_1's multi_logloss: 0.790311\n",
      "[345]\ttraining's multi_logloss: 0.566224\tvalid_1's multi_logloss: 0.790045\n",
      "[346]\ttraining's multi_logloss: 0.565564\tvalid_1's multi_logloss: 0.789745\n",
      "[347]\ttraining's multi_logloss: 0.564909\tvalid_1's multi_logloss: 0.789496\n",
      "[348]\ttraining's multi_logloss: 0.564237\tvalid_1's multi_logloss: 0.789223\n",
      "[349]\ttraining's multi_logloss: 0.563598\tvalid_1's multi_logloss: 0.788974\n",
      "[350]\ttraining's multi_logloss: 0.562955\tvalid_1's multi_logloss: 0.788709\n",
      "[351]\ttraining's multi_logloss: 0.562309\tvalid_1's multi_logloss: 0.788451\n",
      "[352]\ttraining's multi_logloss: 0.561639\tvalid_1's multi_logloss: 0.788195\n",
      "[353]\ttraining's multi_logloss: 0.560995\tvalid_1's multi_logloss: 0.787944\n",
      "[354]\ttraining's multi_logloss: 0.560344\tvalid_1's multi_logloss: 0.787688\n",
      "[355]\ttraining's multi_logloss: 0.559695\tvalid_1's multi_logloss: 0.787469\n",
      "[356]\ttraining's multi_logloss: 0.559067\tvalid_1's multi_logloss: 0.787232\n",
      "[357]\ttraining's multi_logloss: 0.558435\tvalid_1's multi_logloss: 0.787024\n",
      "[358]\ttraining's multi_logloss: 0.557808\tvalid_1's multi_logloss: 0.786796\n",
      "[359]\ttraining's multi_logloss: 0.557156\tvalid_1's multi_logloss: 0.786556\n",
      "[360]\ttraining's multi_logloss: 0.556524\tvalid_1's multi_logloss: 0.78635\n",
      "[361]\ttraining's multi_logloss: 0.555879\tvalid_1's multi_logloss: 0.786146\n",
      "[362]\ttraining's multi_logloss: 0.555236\tvalid_1's multi_logloss: 0.785936\n",
      "[363]\ttraining's multi_logloss: 0.554612\tvalid_1's multi_logloss: 0.785707\n",
      "[364]\ttraining's multi_logloss: 0.553978\tvalid_1's multi_logloss: 0.7855\n",
      "[365]\ttraining's multi_logloss: 0.553353\tvalid_1's multi_logloss: 0.785294\n",
      "[366]\ttraining's multi_logloss: 0.552736\tvalid_1's multi_logloss: 0.785071\n",
      "[367]\ttraining's multi_logloss: 0.55214\tvalid_1's multi_logloss: 0.784844\n",
      "[368]\ttraining's multi_logloss: 0.551498\tvalid_1's multi_logloss: 0.784646\n",
      "[369]\ttraining's multi_logloss: 0.550864\tvalid_1's multi_logloss: 0.784426\n",
      "[370]\ttraining's multi_logloss: 0.550246\tvalid_1's multi_logloss: 0.784217\n",
      "[371]\ttraining's multi_logloss: 0.549637\tvalid_1's multi_logloss: 0.784031\n",
      "[372]\ttraining's multi_logloss: 0.549027\tvalid_1's multi_logloss: 0.783817\n",
      "[373]\ttraining's multi_logloss: 0.548412\tvalid_1's multi_logloss: 0.783598\n",
      "[374]\ttraining's multi_logloss: 0.547796\tvalid_1's multi_logloss: 0.783358\n",
      "[375]\ttraining's multi_logloss: 0.547188\tvalid_1's multi_logloss: 0.783163\n",
      "[376]\ttraining's multi_logloss: 0.546579\tvalid_1's multi_logloss: 0.782953\n",
      "[377]\ttraining's multi_logloss: 0.545961\tvalid_1's multi_logloss: 0.782736\n",
      "[378]\ttraining's multi_logloss: 0.545366\tvalid_1's multi_logloss: 0.782547\n",
      "[379]\ttraining's multi_logloss: 0.544774\tvalid_1's multi_logloss: 0.782355\n",
      "[380]\ttraining's multi_logloss: 0.544187\tvalid_1's multi_logloss: 0.782155\n",
      "[381]\ttraining's multi_logloss: 0.543605\tvalid_1's multi_logloss: 0.781961\n",
      "[382]\ttraining's multi_logloss: 0.543026\tvalid_1's multi_logloss: 0.781794\n",
      "[383]\ttraining's multi_logloss: 0.542443\tvalid_1's multi_logloss: 0.781611\n",
      "[384]\ttraining's multi_logloss: 0.541845\tvalid_1's multi_logloss: 0.781418\n",
      "[385]\ttraining's multi_logloss: 0.541276\tvalid_1's multi_logloss: 0.781259\n",
      "[386]\ttraining's multi_logloss: 0.540686\tvalid_1's multi_logloss: 0.781053\n",
      "[387]\ttraining's multi_logloss: 0.540118\tvalid_1's multi_logloss: 0.780862\n",
      "[388]\ttraining's multi_logloss: 0.539559\tvalid_1's multi_logloss: 0.780682\n",
      "[389]\ttraining's multi_logloss: 0.538968\tvalid_1's multi_logloss: 0.780495\n",
      "[390]\ttraining's multi_logloss: 0.538392\tvalid_1's multi_logloss: 0.780288\n",
      "[391]\ttraining's multi_logloss: 0.537828\tvalid_1's multi_logloss: 0.780108\n",
      "[392]\ttraining's multi_logloss: 0.53726\tvalid_1's multi_logloss: 0.779931\n",
      "[393]\ttraining's multi_logloss: 0.536697\tvalid_1's multi_logloss: 0.779731\n",
      "[394]\ttraining's multi_logloss: 0.536118\tvalid_1's multi_logloss: 0.779522\n",
      "[395]\ttraining's multi_logloss: 0.53555\tvalid_1's multi_logloss: 0.779354\n",
      "[396]\ttraining's multi_logloss: 0.534981\tvalid_1's multi_logloss: 0.77916\n",
      "[397]\ttraining's multi_logloss: 0.534418\tvalid_1's multi_logloss: 0.779021\n",
      "[398]\ttraining's multi_logloss: 0.533883\tvalid_1's multi_logloss: 0.778829\n",
      "[399]\ttraining's multi_logloss: 0.533321\tvalid_1's multi_logloss: 0.778658\n",
      "[400]\ttraining's multi_logloss: 0.532784\tvalid_1's multi_logloss: 0.778488\n",
      "[401]\ttraining's multi_logloss: 0.532227\tvalid_1's multi_logloss: 0.778339\n",
      "[402]\ttraining's multi_logloss: 0.531667\tvalid_1's multi_logloss: 0.778136\n",
      "[403]\ttraining's multi_logloss: 0.531125\tvalid_1's multi_logloss: 0.777974\n",
      "[404]\ttraining's multi_logloss: 0.530591\tvalid_1's multi_logloss: 0.777836\n",
      "[405]\ttraining's multi_logloss: 0.53004\tvalid_1's multi_logloss: 0.777647\n",
      "[406]\ttraining's multi_logloss: 0.529509\tvalid_1's multi_logloss: 0.777503\n",
      "[407]\ttraining's multi_logloss: 0.528972\tvalid_1's multi_logloss: 0.777349\n",
      "[408]\ttraining's multi_logloss: 0.528431\tvalid_1's multi_logloss: 0.777182\n",
      "[409]\ttraining's multi_logloss: 0.527895\tvalid_1's multi_logloss: 0.777029\n",
      "[410]\ttraining's multi_logloss: 0.527357\tvalid_1's multi_logloss: 0.776856\n",
      "[411]\ttraining's multi_logloss: 0.526812\tvalid_1's multi_logloss: 0.776703\n",
      "[412]\ttraining's multi_logloss: 0.526294\tvalid_1's multi_logloss: 0.776555\n",
      "[413]\ttraining's multi_logloss: 0.525761\tvalid_1's multi_logloss: 0.776413\n",
      "[414]\ttraining's multi_logloss: 0.525244\tvalid_1's multi_logloss: 0.776265\n",
      "[415]\ttraining's multi_logloss: 0.524723\tvalid_1's multi_logloss: 0.77611\n",
      "[416]\ttraining's multi_logloss: 0.524188\tvalid_1's multi_logloss: 0.775967\n",
      "[417]\ttraining's multi_logloss: 0.523671\tvalid_1's multi_logloss: 0.775835\n",
      "[418]\ttraining's multi_logloss: 0.523151\tvalid_1's multi_logloss: 0.775702\n",
      "[419]\ttraining's multi_logloss: 0.522636\tvalid_1's multi_logloss: 0.775565\n",
      "[420]\ttraining's multi_logloss: 0.522126\tvalid_1's multi_logloss: 0.775415\n",
      "[421]\ttraining's multi_logloss: 0.521619\tvalid_1's multi_logloss: 0.775258\n",
      "[422]\ttraining's multi_logloss: 0.521117\tvalid_1's multi_logloss: 0.775125\n",
      "[423]\ttraining's multi_logloss: 0.520602\tvalid_1's multi_logloss: 0.775009\n",
      "[424]\ttraining's multi_logloss: 0.520102\tvalid_1's multi_logloss: 0.774866\n",
      "[425]\ttraining's multi_logloss: 0.519586\tvalid_1's multi_logloss: 0.77473\n",
      "[426]\ttraining's multi_logloss: 0.519083\tvalid_1's multi_logloss: 0.774616\n",
      "[427]\ttraining's multi_logloss: 0.518584\tvalid_1's multi_logloss: 0.77449\n",
      "[428]\ttraining's multi_logloss: 0.518078\tvalid_1's multi_logloss: 0.774359\n",
      "[429]\ttraining's multi_logloss: 0.517589\tvalid_1's multi_logloss: 0.774213\n",
      "[430]\ttraining's multi_logloss: 0.51708\tvalid_1's multi_logloss: 0.774077\n",
      "[431]\ttraining's multi_logloss: 0.516561\tvalid_1's multi_logloss: 0.773971\n",
      "[432]\ttraining's multi_logloss: 0.516075\tvalid_1's multi_logloss: 0.773834\n",
      "[433]\ttraining's multi_logloss: 0.515589\tvalid_1's multi_logloss: 0.773721\n",
      "[434]\ttraining's multi_logloss: 0.51509\tvalid_1's multi_logloss: 0.773599\n",
      "[435]\ttraining's multi_logloss: 0.514594\tvalid_1's multi_logloss: 0.7735\n",
      "[436]\ttraining's multi_logloss: 0.514103\tvalid_1's multi_logloss: 0.7734\n",
      "[437]\ttraining's multi_logloss: 0.513621\tvalid_1's multi_logloss: 0.773284\n",
      "[438]\ttraining's multi_logloss: 0.513138\tvalid_1's multi_logloss: 0.773168\n",
      "[439]\ttraining's multi_logloss: 0.512639\tvalid_1's multi_logloss: 0.773041\n",
      "[440]\ttraining's multi_logloss: 0.512146\tvalid_1's multi_logloss: 0.772926\n",
      "[441]\ttraining's multi_logloss: 0.511665\tvalid_1's multi_logloss: 0.772821\n",
      "[442]\ttraining's multi_logloss: 0.511181\tvalid_1's multi_logloss: 0.772679\n",
      "[443]\ttraining's multi_logloss: 0.510705\tvalid_1's multi_logloss: 0.772557\n",
      "[444]\ttraining's multi_logloss: 0.510224\tvalid_1's multi_logloss: 0.772446\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[445]\ttraining's multi_logloss: 0.509746\tvalid_1's multi_logloss: 0.772335\n",
      "[446]\ttraining's multi_logloss: 0.509277\tvalid_1's multi_logloss: 0.772213\n",
      "[447]\ttraining's multi_logloss: 0.508802\tvalid_1's multi_logloss: 0.772103\n",
      "[448]\ttraining's multi_logloss: 0.508312\tvalid_1's multi_logloss: 0.771979\n",
      "[449]\ttraining's multi_logloss: 0.507844\tvalid_1's multi_logloss: 0.771883\n",
      "[450]\ttraining's multi_logloss: 0.507382\tvalid_1's multi_logloss: 0.771778\n",
      "[451]\ttraining's multi_logloss: 0.506915\tvalid_1's multi_logloss: 0.771682\n",
      "[452]\ttraining's multi_logloss: 0.506462\tvalid_1's multi_logloss: 0.771569\n",
      "[453]\ttraining's multi_logloss: 0.505998\tvalid_1's multi_logloss: 0.771457\n",
      "[454]\ttraining's multi_logloss: 0.505531\tvalid_1's multi_logloss: 0.771357\n",
      "[455]\ttraining's multi_logloss: 0.505072\tvalid_1's multi_logloss: 0.771231\n",
      "[456]\ttraining's multi_logloss: 0.504605\tvalid_1's multi_logloss: 0.771131\n",
      "[457]\ttraining's multi_logloss: 0.504157\tvalid_1's multi_logloss: 0.771055\n",
      "[458]\ttraining's multi_logloss: 0.503698\tvalid_1's multi_logloss: 0.770977\n",
      "[459]\ttraining's multi_logloss: 0.503235\tvalid_1's multi_logloss: 0.770875\n",
      "[460]\ttraining's multi_logloss: 0.502777\tvalid_1's multi_logloss: 0.770764\n",
      "[461]\ttraining's multi_logloss: 0.502329\tvalid_1's multi_logloss: 0.770681\n",
      "[462]\ttraining's multi_logloss: 0.501866\tvalid_1's multi_logloss: 0.770608\n",
      "[463]\ttraining's multi_logloss: 0.501411\tvalid_1's multi_logloss: 0.770518\n",
      "[464]\ttraining's multi_logloss: 0.50096\tvalid_1's multi_logloss: 0.770423\n",
      "[465]\ttraining's multi_logloss: 0.500516\tvalid_1's multi_logloss: 0.770345\n",
      "[466]\ttraining's multi_logloss: 0.500051\tvalid_1's multi_logloss: 0.770245\n",
      "[467]\ttraining's multi_logloss: 0.499608\tvalid_1's multi_logloss: 0.770161\n",
      "[468]\ttraining's multi_logloss: 0.499162\tvalid_1's multi_logloss: 0.770061\n",
      "[469]\ttraining's multi_logloss: 0.498706\tvalid_1's multi_logloss: 0.76995\n",
      "[470]\ttraining's multi_logloss: 0.498252\tvalid_1's multi_logloss: 0.769883\n",
      "[471]\ttraining's multi_logloss: 0.49779\tvalid_1's multi_logloss: 0.769796\n",
      "[472]\ttraining's multi_logloss: 0.497339\tvalid_1's multi_logloss: 0.769704\n",
      "[473]\ttraining's multi_logloss: 0.496907\tvalid_1's multi_logloss: 0.769624\n",
      "[474]\ttraining's multi_logloss: 0.496468\tvalid_1's multi_logloss: 0.76954\n",
      "[475]\ttraining's multi_logloss: 0.496022\tvalid_1's multi_logloss: 0.769438\n",
      "[476]\ttraining's multi_logloss: 0.49558\tvalid_1's multi_logloss: 0.76937\n",
      "[477]\ttraining's multi_logloss: 0.495142\tvalid_1's multi_logloss: 0.769296\n",
      "[478]\ttraining's multi_logloss: 0.494715\tvalid_1's multi_logloss: 0.769199\n",
      "[479]\ttraining's multi_logloss: 0.49427\tvalid_1's multi_logloss: 0.76911\n",
      "[480]\ttraining's multi_logloss: 0.493841\tvalid_1's multi_logloss: 0.76902\n",
      "[481]\ttraining's multi_logloss: 0.493406\tvalid_1's multi_logloss: 0.768927\n",
      "[482]\ttraining's multi_logloss: 0.492994\tvalid_1's multi_logloss: 0.768855\n",
      "[483]\ttraining's multi_logloss: 0.492569\tvalid_1's multi_logloss: 0.768777\n",
      "[484]\ttraining's multi_logloss: 0.492129\tvalid_1's multi_logloss: 0.768695\n",
      "[485]\ttraining's multi_logloss: 0.491702\tvalid_1's multi_logloss: 0.768626\n",
      "[486]\ttraining's multi_logloss: 0.491278\tvalid_1's multi_logloss: 0.768533\n",
      "[487]\ttraining's multi_logloss: 0.490856\tvalid_1's multi_logloss: 0.768443\n",
      "[488]\ttraining's multi_logloss: 0.490437\tvalid_1's multi_logloss: 0.768358\n",
      "[489]\ttraining's multi_logloss: 0.490017\tvalid_1's multi_logloss: 0.768284\n",
      "[490]\ttraining's multi_logloss: 0.489593\tvalid_1's multi_logloss: 0.768224\n",
      "[491]\ttraining's multi_logloss: 0.489175\tvalid_1's multi_logloss: 0.768158\n",
      "[492]\ttraining's multi_logloss: 0.488744\tvalid_1's multi_logloss: 0.768072\n",
      "[493]\ttraining's multi_logloss: 0.488333\tvalid_1's multi_logloss: 0.768005\n",
      "[494]\ttraining's multi_logloss: 0.487921\tvalid_1's multi_logloss: 0.76794\n",
      "[495]\ttraining's multi_logloss: 0.487497\tvalid_1's multi_logloss: 0.767858\n",
      "[496]\ttraining's multi_logloss: 0.487082\tvalid_1's multi_logloss: 0.767793\n",
      "[497]\ttraining's multi_logloss: 0.486659\tvalid_1's multi_logloss: 0.767729\n",
      "[498]\ttraining's multi_logloss: 0.486252\tvalid_1's multi_logloss: 0.767668\n",
      "[499]\ttraining's multi_logloss: 0.485847\tvalid_1's multi_logloss: 0.767608\n",
      "[500]\ttraining's multi_logloss: 0.485446\tvalid_1's multi_logloss: 0.767557\n",
      "[501]\ttraining's multi_logloss: 0.485038\tvalid_1's multi_logloss: 0.767473\n",
      "[502]\ttraining's multi_logloss: 0.484631\tvalid_1's multi_logloss: 0.767398\n",
      "[503]\ttraining's multi_logloss: 0.484225\tvalid_1's multi_logloss: 0.767337\n",
      "[504]\ttraining's multi_logloss: 0.483819\tvalid_1's multi_logloss: 0.767277\n",
      "[505]\ttraining's multi_logloss: 0.483412\tvalid_1's multi_logloss: 0.767237\n",
      "[506]\ttraining's multi_logloss: 0.483013\tvalid_1's multi_logloss: 0.767152\n",
      "[507]\ttraining's multi_logloss: 0.482619\tvalid_1's multi_logloss: 0.767078\n",
      "[508]\ttraining's multi_logloss: 0.482212\tvalid_1's multi_logloss: 0.767029\n",
      "[509]\ttraining's multi_logloss: 0.4818\tvalid_1's multi_logloss: 0.766972\n",
      "[510]\ttraining's multi_logloss: 0.481397\tvalid_1's multi_logloss: 0.766921\n",
      "[511]\ttraining's multi_logloss: 0.480997\tvalid_1's multi_logloss: 0.766844\n",
      "[512]\ttraining's multi_logloss: 0.480594\tvalid_1's multi_logloss: 0.766792\n",
      "[513]\ttraining's multi_logloss: 0.480193\tvalid_1's multi_logloss: 0.766746\n",
      "[514]\ttraining's multi_logloss: 0.479792\tvalid_1's multi_logloss: 0.766693\n",
      "[515]\ttraining's multi_logloss: 0.479403\tvalid_1's multi_logloss: 0.766625\n",
      "[516]\ttraining's multi_logloss: 0.479007\tvalid_1's multi_logloss: 0.766571\n",
      "[517]\ttraining's multi_logloss: 0.478621\tvalid_1's multi_logloss: 0.766514\n",
      "[518]\ttraining's multi_logloss: 0.478224\tvalid_1's multi_logloss: 0.766452\n",
      "[519]\ttraining's multi_logloss: 0.477828\tvalid_1's multi_logloss: 0.766388\n",
      "[520]\ttraining's multi_logloss: 0.477436\tvalid_1's multi_logloss: 0.766347\n",
      "[521]\ttraining's multi_logloss: 0.477042\tvalid_1's multi_logloss: 0.76627\n",
      "[522]\ttraining's multi_logloss: 0.476653\tvalid_1's multi_logloss: 0.766233\n",
      "[523]\ttraining's multi_logloss: 0.476265\tvalid_1's multi_logloss: 0.766156\n",
      "[524]\ttraining's multi_logloss: 0.475892\tvalid_1's multi_logloss: 0.766099\n",
      "[525]\ttraining's multi_logloss: 0.475507\tvalid_1's multi_logloss: 0.766058\n",
      "[526]\ttraining's multi_logloss: 0.475131\tvalid_1's multi_logloss: 0.765997\n",
      "[527]\ttraining's multi_logloss: 0.474753\tvalid_1's multi_logloss: 0.765959\n",
      "[528]\ttraining's multi_logloss: 0.474379\tvalid_1's multi_logloss: 0.765906\n",
      "[529]\ttraining's multi_logloss: 0.473999\tvalid_1's multi_logloss: 0.765864\n",
      "[530]\ttraining's multi_logloss: 0.473619\tvalid_1's multi_logloss: 0.765804\n",
      "[531]\ttraining's multi_logloss: 0.473239\tvalid_1's multi_logloss: 0.765756\n",
      "[532]\ttraining's multi_logloss: 0.472841\tvalid_1's multi_logloss: 0.765698\n",
      "[533]\ttraining's multi_logloss: 0.472464\tvalid_1's multi_logloss: 0.765671\n",
      "[534]\ttraining's multi_logloss: 0.472079\tvalid_1's multi_logloss: 0.765608\n",
      "[535]\ttraining's multi_logloss: 0.4717\tvalid_1's multi_logloss: 0.765578\n",
      "[536]\ttraining's multi_logloss: 0.471318\tvalid_1's multi_logloss: 0.765504\n",
      "[537]\ttraining's multi_logloss: 0.47095\tvalid_1's multi_logloss: 0.765458\n",
      "[538]\ttraining's multi_logloss: 0.470567\tvalid_1's multi_logloss: 0.765423\n",
      "[539]\ttraining's multi_logloss: 0.470198\tvalid_1's multi_logloss: 0.765388\n",
      "[540]\ttraining's multi_logloss: 0.469824\tvalid_1's multi_logloss: 0.765327\n",
      "[541]\ttraining's multi_logloss: 0.469455\tvalid_1's multi_logloss: 0.765286\n",
      "[542]\ttraining's multi_logloss: 0.469091\tvalid_1's multi_logloss: 0.765264\n",
      "[543]\ttraining's multi_logloss: 0.468705\tvalid_1's multi_logloss: 0.765235\n",
      "[544]\ttraining's multi_logloss: 0.468338\tvalid_1's multi_logloss: 0.765191\n",
      "[545]\ttraining's multi_logloss: 0.467973\tvalid_1's multi_logloss: 0.765184\n",
      "[546]\ttraining's multi_logloss: 0.467607\tvalid_1's multi_logloss: 0.765132\n",
      "[547]\ttraining's multi_logloss: 0.467248\tvalid_1's multi_logloss: 0.765091\n",
      "[548]\ttraining's multi_logloss: 0.466886\tvalid_1's multi_logloss: 0.765051\n",
      "[549]\ttraining's multi_logloss: 0.466511\tvalid_1's multi_logloss: 0.765014\n",
      "[550]\ttraining's multi_logloss: 0.466139\tvalid_1's multi_logloss: 0.764947\n",
      "[551]\ttraining's multi_logloss: 0.465778\tvalid_1's multi_logloss: 0.7649\n",
      "[552]\ttraining's multi_logloss: 0.465424\tvalid_1's multi_logloss: 0.76484\n",
      "[553]\ttraining's multi_logloss: 0.465055\tvalid_1's multi_logloss: 0.764826\n",
      "[554]\ttraining's multi_logloss: 0.464689\tvalid_1's multi_logloss: 0.764782\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[555]\ttraining's multi_logloss: 0.464337\tvalid_1's multi_logloss: 0.764746\n",
      "[556]\ttraining's multi_logloss: 0.463967\tvalid_1's multi_logloss: 0.764691\n",
      "[557]\ttraining's multi_logloss: 0.463588\tvalid_1's multi_logloss: 0.764656\n",
      "[558]\ttraining's multi_logloss: 0.46323\tvalid_1's multi_logloss: 0.764613\n",
      "[559]\ttraining's multi_logloss: 0.462874\tvalid_1's multi_logloss: 0.764583\n",
      "[560]\ttraining's multi_logloss: 0.462517\tvalid_1's multi_logloss: 0.76452\n",
      "[561]\ttraining's multi_logloss: 0.462163\tvalid_1's multi_logloss: 0.764478\n",
      "[562]\ttraining's multi_logloss: 0.46181\tvalid_1's multi_logloss: 0.764459\n",
      "[563]\ttraining's multi_logloss: 0.46146\tvalid_1's multi_logloss: 0.764397\n",
      "[564]\ttraining's multi_logloss: 0.461113\tvalid_1's multi_logloss: 0.764333\n",
      "[565]\ttraining's multi_logloss: 0.460761\tvalid_1's multi_logloss: 0.764302\n",
      "[566]\ttraining's multi_logloss: 0.460414\tvalid_1's multi_logloss: 0.76428\n",
      "[567]\ttraining's multi_logloss: 0.460055\tvalid_1's multi_logloss: 0.764222\n",
      "[568]\ttraining's multi_logloss: 0.459704\tvalid_1's multi_logloss: 0.764167\n",
      "[569]\ttraining's multi_logloss: 0.459352\tvalid_1's multi_logloss: 0.764119\n",
      "[570]\ttraining's multi_logloss: 0.459003\tvalid_1's multi_logloss: 0.764098\n",
      "[571]\ttraining's multi_logloss: 0.458651\tvalid_1's multi_logloss: 0.764043\n",
      "[572]\ttraining's multi_logloss: 0.458297\tvalid_1's multi_logloss: 0.764002\n",
      "[573]\ttraining's multi_logloss: 0.457952\tvalid_1's multi_logloss: 0.763968\n",
      "[574]\ttraining's multi_logloss: 0.457611\tvalid_1's multi_logloss: 0.763924\n",
      "[575]\ttraining's multi_logloss: 0.457259\tvalid_1's multi_logloss: 0.763896\n",
      "[576]\ttraining's multi_logloss: 0.456919\tvalid_1's multi_logloss: 0.76387\n",
      "[577]\ttraining's multi_logloss: 0.456582\tvalid_1's multi_logloss: 0.763848\n",
      "[578]\ttraining's multi_logloss: 0.456244\tvalid_1's multi_logloss: 0.763814\n",
      "[579]\ttraining's multi_logloss: 0.455897\tvalid_1's multi_logloss: 0.763762\n",
      "[580]\ttraining's multi_logloss: 0.45555\tvalid_1's multi_logloss: 0.763717\n",
      "[581]\ttraining's multi_logloss: 0.455207\tvalid_1's multi_logloss: 0.76371\n",
      "[582]\ttraining's multi_logloss: 0.454883\tvalid_1's multi_logloss: 0.763655\n",
      "[583]\ttraining's multi_logloss: 0.454555\tvalid_1's multi_logloss: 0.763605\n",
      "[584]\ttraining's multi_logloss: 0.454208\tvalid_1's multi_logloss: 0.763579\n",
      "[585]\ttraining's multi_logloss: 0.453867\tvalid_1's multi_logloss: 0.763528\n",
      "[586]\ttraining's multi_logloss: 0.453522\tvalid_1's multi_logloss: 0.763503\n",
      "[587]\ttraining's multi_logloss: 0.453191\tvalid_1's multi_logloss: 0.763443\n",
      "[588]\ttraining's multi_logloss: 0.452867\tvalid_1's multi_logloss: 0.763393\n",
      "[589]\ttraining's multi_logloss: 0.452524\tvalid_1's multi_logloss: 0.763364\n",
      "[590]\ttraining's multi_logloss: 0.452183\tvalid_1's multi_logloss: 0.763315\n",
      "[591]\ttraining's multi_logloss: 0.451847\tvalid_1's multi_logloss: 0.763267\n",
      "[592]\ttraining's multi_logloss: 0.451507\tvalid_1's multi_logloss: 0.763223\n",
      "[593]\ttraining's multi_logloss: 0.451164\tvalid_1's multi_logloss: 0.763174\n",
      "[594]\ttraining's multi_logloss: 0.450819\tvalid_1's multi_logloss: 0.763145\n",
      "[595]\ttraining's multi_logloss: 0.450474\tvalid_1's multi_logloss: 0.763133\n",
      "[596]\ttraining's multi_logloss: 0.45013\tvalid_1's multi_logloss: 0.763092\n",
      "[597]\ttraining's multi_logloss: 0.449807\tvalid_1's multi_logloss: 0.763083\n",
      "[598]\ttraining's multi_logloss: 0.449456\tvalid_1's multi_logloss: 0.763055\n",
      "[599]\ttraining's multi_logloss: 0.449124\tvalid_1's multi_logloss: 0.763005\n",
      "[600]\ttraining's multi_logloss: 0.448786\tvalid_1's multi_logloss: 0.762973\n",
      "[601]\ttraining's multi_logloss: 0.448453\tvalid_1's multi_logloss: 0.762938\n",
      "[602]\ttraining's multi_logloss: 0.448118\tvalid_1's multi_logloss: 0.762896\n",
      "[603]\ttraining's multi_logloss: 0.44778\tvalid_1's multi_logloss: 0.76286\n",
      "[604]\ttraining's multi_logloss: 0.447463\tvalid_1's multi_logloss: 0.76284\n",
      "[605]\ttraining's multi_logloss: 0.447137\tvalid_1's multi_logloss: 0.762827\n",
      "[606]\ttraining's multi_logloss: 0.446796\tvalid_1's multi_logloss: 0.762794\n",
      "[607]\ttraining's multi_logloss: 0.446468\tvalid_1's multi_logloss: 0.762744\n",
      "[608]\ttraining's multi_logloss: 0.446143\tvalid_1's multi_logloss: 0.762708\n",
      "[609]\ttraining's multi_logloss: 0.445812\tvalid_1's multi_logloss: 0.762681\n",
      "[610]\ttraining's multi_logloss: 0.445498\tvalid_1's multi_logloss: 0.762648\n",
      "[611]\ttraining's multi_logloss: 0.445171\tvalid_1's multi_logloss: 0.762615\n",
      "[612]\ttraining's multi_logloss: 0.444847\tvalid_1's multi_logloss: 0.762576\n",
      "[613]\ttraining's multi_logloss: 0.444529\tvalid_1's multi_logloss: 0.762541\n",
      "[614]\ttraining's multi_logloss: 0.444211\tvalid_1's multi_logloss: 0.762536\n",
      "[615]\ttraining's multi_logloss: 0.443892\tvalid_1's multi_logloss: 0.76251\n",
      "[616]\ttraining's multi_logloss: 0.443564\tvalid_1's multi_logloss: 0.762458\n",
      "[617]\ttraining's multi_logloss: 0.443243\tvalid_1's multi_logloss: 0.762453\n",
      "[618]\ttraining's multi_logloss: 0.44293\tvalid_1's multi_logloss: 0.762429\n",
      "[619]\ttraining's multi_logloss: 0.442607\tvalid_1's multi_logloss: 0.762376\n",
      "[620]\ttraining's multi_logloss: 0.442296\tvalid_1's multi_logloss: 0.762356\n",
      "[621]\ttraining's multi_logloss: 0.44198\tvalid_1's multi_logloss: 0.762312\n",
      "[622]\ttraining's multi_logloss: 0.441656\tvalid_1's multi_logloss: 0.762287\n",
      "[623]\ttraining's multi_logloss: 0.441336\tvalid_1's multi_logloss: 0.762266\n",
      "[624]\ttraining's multi_logloss: 0.441013\tvalid_1's multi_logloss: 0.762237\n",
      "[625]\ttraining's multi_logloss: 0.440701\tvalid_1's multi_logloss: 0.762192\n",
      "[626]\ttraining's multi_logloss: 0.440391\tvalid_1's multi_logloss: 0.762161\n",
      "[627]\ttraining's multi_logloss: 0.440071\tvalid_1's multi_logloss: 0.76214\n",
      "[628]\ttraining's multi_logloss: 0.439756\tvalid_1's multi_logloss: 0.762116\n",
      "[629]\ttraining's multi_logloss: 0.439441\tvalid_1's multi_logloss: 0.76209\n",
      "[630]\ttraining's multi_logloss: 0.439129\tvalid_1's multi_logloss: 0.762059\n",
      "[631]\ttraining's multi_logloss: 0.438812\tvalid_1's multi_logloss: 0.762024\n",
      "[632]\ttraining's multi_logloss: 0.438512\tvalid_1's multi_logloss: 0.761992\n",
      "[633]\ttraining's multi_logloss: 0.438204\tvalid_1's multi_logloss: 0.761932\n",
      "[634]\ttraining's multi_logloss: 0.437881\tvalid_1's multi_logloss: 0.761887\n",
      "[635]\ttraining's multi_logloss: 0.437569\tvalid_1's multi_logloss: 0.761863\n",
      "[636]\ttraining's multi_logloss: 0.437267\tvalid_1's multi_logloss: 0.761829\n",
      "[637]\ttraining's multi_logloss: 0.436957\tvalid_1's multi_logloss: 0.76182\n",
      "[638]\ttraining's multi_logloss: 0.436644\tvalid_1's multi_logloss: 0.761802\n",
      "[639]\ttraining's multi_logloss: 0.436345\tvalid_1's multi_logloss: 0.761812\n",
      "[640]\ttraining's multi_logloss: 0.436038\tvalid_1's multi_logloss: 0.761806\n",
      "[641]\ttraining's multi_logloss: 0.435733\tvalid_1's multi_logloss: 0.761805\n",
      "[642]\ttraining's multi_logloss: 0.435428\tvalid_1's multi_logloss: 0.761779\n",
      "[643]\ttraining's multi_logloss: 0.435123\tvalid_1's multi_logloss: 0.761771\n",
      "[644]\ttraining's multi_logloss: 0.434812\tvalid_1's multi_logloss: 0.761751\n",
      "[645]\ttraining's multi_logloss: 0.434508\tvalid_1's multi_logloss: 0.761741\n",
      "[646]\ttraining's multi_logloss: 0.434205\tvalid_1's multi_logloss: 0.761723\n",
      "[647]\ttraining's multi_logloss: 0.433881\tvalid_1's multi_logloss: 0.761704\n",
      "[648]\ttraining's multi_logloss: 0.433586\tvalid_1's multi_logloss: 0.76168\n",
      "[649]\ttraining's multi_logloss: 0.433286\tvalid_1's multi_logloss: 0.761648\n",
      "[650]\ttraining's multi_logloss: 0.432976\tvalid_1's multi_logloss: 0.761612\n",
      "[651]\ttraining's multi_logloss: 0.432672\tvalid_1's multi_logloss: 0.761591\n",
      "[652]\ttraining's multi_logloss: 0.43238\tvalid_1's multi_logloss: 0.761569\n",
      "[653]\ttraining's multi_logloss: 0.432081\tvalid_1's multi_logloss: 0.761531\n",
      "[654]\ttraining's multi_logloss: 0.431797\tvalid_1's multi_logloss: 0.761497\n",
      "[655]\ttraining's multi_logloss: 0.431512\tvalid_1's multi_logloss: 0.761488\n",
      "[656]\ttraining's multi_logloss: 0.431207\tvalid_1's multi_logloss: 0.761479\n",
      "[657]\ttraining's multi_logloss: 0.430917\tvalid_1's multi_logloss: 0.761461\n",
      "[658]\ttraining's multi_logloss: 0.430621\tvalid_1's multi_logloss: 0.761449\n",
      "[659]\ttraining's multi_logloss: 0.430318\tvalid_1's multi_logloss: 0.761423\n",
      "[660]\ttraining's multi_logloss: 0.430027\tvalid_1's multi_logloss: 0.761414\n",
      "[661]\ttraining's multi_logloss: 0.429722\tvalid_1's multi_logloss: 0.761374\n",
      "[662]\ttraining's multi_logloss: 0.429431\tvalid_1's multi_logloss: 0.761375\n",
      "[663]\ttraining's multi_logloss: 0.42913\tvalid_1's multi_logloss: 0.761352\n",
      "[664]\ttraining's multi_logloss: 0.428837\tvalid_1's multi_logloss: 0.76135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[665]\ttraining's multi_logloss: 0.428552\tvalid_1's multi_logloss: 0.761355\n",
      "[666]\ttraining's multi_logloss: 0.428262\tvalid_1's multi_logloss: 0.761324\n",
      "[667]\ttraining's multi_logloss: 0.427967\tvalid_1's multi_logloss: 0.761313\n",
      "[668]\ttraining's multi_logloss: 0.427677\tvalid_1's multi_logloss: 0.761283\n",
      "[669]\ttraining's multi_logloss: 0.427378\tvalid_1's multi_logloss: 0.761269\n",
      "[670]\ttraining's multi_logloss: 0.427093\tvalid_1's multi_logloss: 0.761263\n",
      "[671]\ttraining's multi_logloss: 0.426812\tvalid_1's multi_logloss: 0.761254\n",
      "[672]\ttraining's multi_logloss: 0.426507\tvalid_1's multi_logloss: 0.761234\n",
      "[673]\ttraining's multi_logloss: 0.426223\tvalid_1's multi_logloss: 0.761237\n",
      "[674]\ttraining's multi_logloss: 0.42594\tvalid_1's multi_logloss: 0.761216\n",
      "[675]\ttraining's multi_logloss: 0.42565\tvalid_1's multi_logloss: 0.761208\n",
      "[676]\ttraining's multi_logloss: 0.425373\tvalid_1's multi_logloss: 0.761203\n",
      "[677]\ttraining's multi_logloss: 0.42508\tvalid_1's multi_logloss: 0.761195\n",
      "[678]\ttraining's multi_logloss: 0.424787\tvalid_1's multi_logloss: 0.761183\n",
      "[679]\ttraining's multi_logloss: 0.424499\tvalid_1's multi_logloss: 0.761156\n",
      "[680]\ttraining's multi_logloss: 0.424215\tvalid_1's multi_logloss: 0.761143\n",
      "[681]\ttraining's multi_logloss: 0.423928\tvalid_1's multi_logloss: 0.761132\n",
      "[682]\ttraining's multi_logloss: 0.423642\tvalid_1's multi_logloss: 0.76112\n",
      "[683]\ttraining's multi_logloss: 0.423351\tvalid_1's multi_logloss: 0.761099\n",
      "[684]\ttraining's multi_logloss: 0.42307\tvalid_1's multi_logloss: 0.761081\n",
      "[685]\ttraining's multi_logloss: 0.422791\tvalid_1's multi_logloss: 0.761064\n",
      "[686]\ttraining's multi_logloss: 0.4225\tvalid_1's multi_logloss: 0.76106\n",
      "[687]\ttraining's multi_logloss: 0.422218\tvalid_1's multi_logloss: 0.761057\n",
      "[688]\ttraining's multi_logloss: 0.421928\tvalid_1's multi_logloss: 0.761054\n",
      "[689]\ttraining's multi_logloss: 0.421655\tvalid_1's multi_logloss: 0.761037\n",
      "[690]\ttraining's multi_logloss: 0.421377\tvalid_1's multi_logloss: 0.761004\n",
      "[691]\ttraining's multi_logloss: 0.421103\tvalid_1's multi_logloss: 0.760999\n",
      "[692]\ttraining's multi_logloss: 0.420818\tvalid_1's multi_logloss: 0.760991\n",
      "[693]\ttraining's multi_logloss: 0.420538\tvalid_1's multi_logloss: 0.760962\n",
      "[694]\ttraining's multi_logloss: 0.420266\tvalid_1's multi_logloss: 0.760936\n",
      "[695]\ttraining's multi_logloss: 0.41999\tvalid_1's multi_logloss: 0.76091\n",
      "[696]\ttraining's multi_logloss: 0.419715\tvalid_1's multi_logloss: 0.760911\n",
      "[697]\ttraining's multi_logloss: 0.419436\tvalid_1's multi_logloss: 0.760903\n",
      "[698]\ttraining's multi_logloss: 0.419153\tvalid_1's multi_logloss: 0.760877\n",
      "[699]\ttraining's multi_logloss: 0.418875\tvalid_1's multi_logloss: 0.760864\n",
      "[700]\ttraining's multi_logloss: 0.418599\tvalid_1's multi_logloss: 0.760858\n",
      "[701]\ttraining's multi_logloss: 0.418325\tvalid_1's multi_logloss: 0.760864\n",
      "[702]\ttraining's multi_logloss: 0.41804\tvalid_1's multi_logloss: 0.760879\n",
      "[703]\ttraining's multi_logloss: 0.417755\tvalid_1's multi_logloss: 0.760852\n",
      "[704]\ttraining's multi_logloss: 0.417479\tvalid_1's multi_logloss: 0.760844\n",
      "[705]\ttraining's multi_logloss: 0.4172\tvalid_1's multi_logloss: 0.760854\n",
      "[706]\ttraining's multi_logloss: 0.41693\tvalid_1's multi_logloss: 0.760825\n",
      "[707]\ttraining's multi_logloss: 0.416663\tvalid_1's multi_logloss: 0.760816\n",
      "[708]\ttraining's multi_logloss: 0.416389\tvalid_1's multi_logloss: 0.760814\n",
      "[709]\ttraining's multi_logloss: 0.416105\tvalid_1's multi_logloss: 0.760797\n",
      "[710]\ttraining's multi_logloss: 0.415828\tvalid_1's multi_logloss: 0.760801\n",
      "[711]\ttraining's multi_logloss: 0.415569\tvalid_1's multi_logloss: 0.760814\n",
      "[712]\ttraining's multi_logloss: 0.415304\tvalid_1's multi_logloss: 0.76081\n",
      "[713]\ttraining's multi_logloss: 0.415037\tvalid_1's multi_logloss: 0.760823\n",
      "[714]\ttraining's multi_logloss: 0.414775\tvalid_1's multi_logloss: 0.76084\n",
      "[715]\ttraining's multi_logloss: 0.414506\tvalid_1's multi_logloss: 0.760835\n",
      "[716]\ttraining's multi_logloss: 0.414244\tvalid_1's multi_logloss: 0.760836\n",
      "[717]\ttraining's multi_logloss: 0.413976\tvalid_1's multi_logloss: 0.760842\n",
      "[718]\ttraining's multi_logloss: 0.413707\tvalid_1's multi_logloss: 0.760845\n",
      "[719]\ttraining's multi_logloss: 0.413434\tvalid_1's multi_logloss: 0.760836\n",
      "Early stopping, best iteration is:\n",
      "[709]\ttraining's multi_logloss: 0.416105\tvalid_1's multi_logloss: 0.760797\n"
     ]
    }
   ],
   "source": [
    "num_boost_round = 4000\n",
    "max_delta_step=0\n",
    "learning_rate=0.02\n",
    "\n",
    "params = {'objective':'multiclass',\n",
    "          'boosting_type': 'gbdt',\n",
    "          'max_depth' : -1,\n",
    "          'nthread': 4,\n",
    "          'metric': 'multi_logloss',\n",
    "          'max_delta_step': 3, \n",
    "          'num_class':38,\n",
    "          'learning_rate':learning_rate,\n",
    "          'max_delta_step':max_delta_step,\n",
    "          }\n",
    "\n",
    "# evals = [(dtrain, 'train'), (dtest, 'test')]\n",
    "\n",
    "# %%time\n",
    "# 4000, 0.008\n",
    "lightgbm_model = lightgbm.train(params = params,\n",
    "                                train_set = dtrain, \n",
    "                                valid_sets = [dtrain, dtest],\n",
    "                                num_boost_round = num_boost_round,\n",
    "                                early_stopping_rounds=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fl, company dummie들의 컬럼으로 Sum한 값을 확인해서 fl은 14(중앙값)이상, (company는) mean 값 이상으로 팔린 아이템만 남긴 feature로 돌렸다. 컬럼은 2236 점수는 0.760797"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "af.sendSlackDm(slack_url, \"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
