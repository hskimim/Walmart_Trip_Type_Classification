{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data :  (647054, 7)\n",
      "Test  data :  (653646, 6)\n",
      "submission  data :  (95674, 39)\n"
     ]
    }
   ],
   "source": [
    "# Import the functions used in this project\n",
    "import awesome_functions as af\n",
    "import decode_utils as du\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "# Pretty display for notebooks\n",
    "%matplotlib inline\n",
    "\n",
    "# Ignore the warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load the dataset\n",
    "train = pd.read_csv(\"../asset/train.csv\")\n",
    "test = pd.read_csv(\"../asset/test.csv\")\n",
    "submission = pd.read_csv(\"../asset/sample_submission.csv\")\n",
    "\n",
    "# Success - Display the first record\n",
    "print(\"Train data : \", train.shape)\n",
    "print(\"Test  data : \", test.shape)\n",
    "print(\"submission  data : \", submission.shape)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import pickle as pkl\n",
    "slack_url = pkl.load(open(\"Slack_url/send_url.pickle\", \"rb\"))\n",
    "\n",
    "import xgboost\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from scipy.sparse import csr_matrix\n",
    "def fitNaiveBayesModel(X, y):\n",
    "    return MultinomialNB(alpha=0.0).fit(X, y)\n",
    "\n",
    "# 원본을 유지하기 위해서 카피\n",
    "df_train = train.copy()\n",
    "df_test = test.copy()\n",
    "df_submission = submission.copy()\n",
    "\n",
    "df_train_dd = pd.read_csv(\"Feature_matrix/df_train_dd_201807291831.csv\")\n",
    "df_test_dd = pd.read_csv(\"Feature_matrix/df_test_dd_201807291855.csv\")\n",
    "df_train_fl = pd.read_csv(\"Feature_matrix/df_train_fl_201807291845.csv\")\n",
    "df_test_fl = pd.read_csv(\"Feature_matrix/df_test_fl_201807291908.csv\")\n",
    "# df_ratio = pd.read_csv(\"Feature_matrix/df_new_has_all_the_ratio_201808031807.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "vn_and_weekdays_cols = [\"VisitNumber\", \"TripType\", 'Return', 'Monday', 'Tuesday',\\\n",
    "                        'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "\n",
    "def get_pivor_df(df, col):\n",
    "    \"\"\"\n",
    "        example) \n",
    "            df_train_cp = get_pivor_df(df_decoded, \"Company\") 이후에,\n",
    "            df_train_cp = get_rid_of_zero_units(df_train_cp) 를 사용해서 음수를 없애줄것.\n",
    "    \"\"\"\n",
    "    \n",
    "    return pd.pivot_table(data= df, index=\"VisitNumber\", fill_value=0,\\\n",
    "                          values=\"ScanCount\", columns=col, aggfunc=np.sum)\n",
    "\n",
    "def get_rid_of_zero_units(df):\n",
    "    return pd.DataFrame(np.where(df < 0, 0, df), columns = df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSpecifiedVisitNumberData(df_train, vn):\n",
    "    display(df_train[df_train.VisitNumber == vn])\n",
    "#     display(df_train_dd[df_train_dd.VisitNumber == vn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_real_category_cnt(df_, col = \"DepartmentDescription\", threshold=1.0):\n",
    "    df = df_.copy()\n",
    "    df_count = df.groupby([\"VisitNumber\", col]).sum()[\"ScanCount\"].reset_index(name=\"Sc_sum\")\n",
    "    \n",
    "    # sc_count가 음수인 아이템은 같은 날 산 아이템이라 볼 수 없다.\n",
    "    # 리턴하기위해 가져온 것들이므로 월마트를 나갈 때 들고가는 아이템이라 보지않아도된다. \n",
    "    # 그런 아이템은 모두 nan으로 바꾸고 drop한다.\n",
    "    df_count[\"Sc_sum\"] = np.where(df_count[\"Sc_sum\"] <= 0, np.nan, df_count[\"Sc_sum\"])\n",
    "    df_count = df_count.dropna()\n",
    "    \n",
    "    # 남은 아이템들만 더해주면 위에서 지정해준 컬럼의 유니크한 개수만 남는다.\n",
    "    df_count = df_count.groupby(\"VisitNumber\").sum()[\"Sc_sum\"].reset_index(name=\"Sc_sum\")\n",
    "    \n",
    "    return list(df_count[df_count.Sc_sum == threshold].VisitNumber.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_flat_type_user(df_, col = \"DepartmentDescription\"):\n",
    "    \"\"\"\n",
    "        예:) vn_dd_more_than_one, vn_dd_one = get_flat_type_user(df_decoded) 반드시 df는 decoding 함수로 decoded된 것을 넣을 것.\n",
    "    \"\"\"\n",
    "    df = df_.copy()\n",
    "    df_count = df.groupby([\"VisitNumber\", col]).sum()[\"ScanCount\"].reset_index(name=\"Sc_sum\")\n",
    "    df_count[\"Sc_sum\"] = np.where(df_count[\"Sc_sum\"] <= 0, np.nan, df_count[\"Sc_sum\"])\n",
    "    df_count = df_count.dropna()\n",
    "    df_count_total = df_count.groupby(\"VisitNumber\").sum()[\"Sc_sum\"].reset_index(name=\"Total\")\n",
    "    df_merged = pd.merge(df_count, df_count_total, on=\"VisitNumber\")\n",
    "    df_merged[\"P\"] = df_merged[\"Sc_sum\"].div(df_merged[\"Total\"])\n",
    "#     df_merged = df_merged[df_merged[\"Total\"] != 1.0]\n",
    "    \n",
    "    one_item_only_vn = []\n",
    "    more_than_one_vn_count = []\n",
    "    for i, vn in enumerate(df_merged.VisitNumber.unique()):\n",
    "        tmp_df = df_merged[df_merged[\"VisitNumber\"] == vn]\n",
    "        unique_p = list(tmp_df[\"P\"].unique())\n",
    "        length_unique_p = len(unique_p)\n",
    "        if length_unique_p == 1:\n",
    "            if unique_p[0] == 1:\n",
    "                one_item_only_vn.append(vn)\n",
    "            else:\n",
    "                more_than_one_vn_count.append(vn)\n",
    "        if i % 5000 == 0:\n",
    "            print(str(i) + \"까지 진행됨.\")\n",
    "    \n",
    "    return more_than_one_vn_count, one_item_only_vn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import decode_utils as du\n",
    "# import awesome_functions as af\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "def getAccuracy(y_true, y_pred, data_length, i):\n",
    "    \"\"\"\n",
    "        y_true : 원래 타겟 컬럼의 데이터를 넣어준다.\n",
    "        y_pred : 예측한 값을 넣어준다.\n",
    "        data_length : 예측한 데이터의 총 개수를 넣어준다.\n",
    "    \"\"\"\n",
    "    accuracy = round(np.trace(confusion_matrix(y_true, y_pred))/data_length, 4)\n",
    "    display(Markdown(\"##### Accuracy : \" + str(accuracy) + \", smoothing : \" + str(i)))\n",
    "    return accuracy\n",
    "\n",
    "def fitNaiveBayesModel_smoothing(X, y, a = 1.0):\n",
    "    return MultinomialNB(alpha=a).fit(X, y)\n",
    "\n",
    "def __combine_dd_fl(df_dd, df_fl):\n",
    "    col_we_dont_need = [\"VisitNumber\", \"TripType\", 'Return', 'Monday',\\\n",
    "                        'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "    cols_we_need = [col for col in df_dd.columns if col not in col_we_dont_need]\n",
    "    cols = [col for col in cols_we_need if col != \"VisitNumber\"]\n",
    "    return du.concatDf(df_dd[cols], df_fl)\n",
    "    \n",
    "def get_concat_df_for_test_df(df_dd, df_fl):\n",
    "    return __combine_dd_fl(df_dd, df_fl)\n",
    "    \n",
    "def get_df_has_specified_vn_list(vn_list, df=None, df_dd=None, df_fl=None, is_in=True,\n",
    "                                 is_need_to_make_df = False):\n",
    "    if is_need_to_make_df:\n",
    "        df = __combine_dd_fl(df_dd, df_fl)\n",
    "        print(\"Concat 완료.\")\n",
    "    if is_in:\n",
    "        return df[df.VisitNumber.isin(vn_list)]\n",
    "    return df[~df.VisitNumber.isin(vn_list)]\n",
    "\n",
    "def test_multinomial(df, early_stop = 5):\n",
    "    X, y = af.get_df_to_fit(df)\n",
    "    a = np.arange(0, 0.16, 0.01)\n",
    "    accuracy_ = 0\n",
    "    count = 0\n",
    "    result = []\n",
    "    alpha = []\n",
    "    for i in a:\n",
    "        if count >= early_stop:\n",
    "            best_score = np.array(result).max()\n",
    "            idx = result.index(best_score)\n",
    "            display(Markdown(\"## Best_score : \" + str(best_score) + \", Alpha : \" + str(alpha[idx])))\n",
    "            return\n",
    "        model_nb = fitNaiveBayesModel_smoothing(X, y, i)\n",
    "        y_pred = model_nb.predict(X)\n",
    "        accuracy = getAccuracy(y, y_pred, len(X), i)\n",
    "        if accuracy_ > accuracy:\n",
    "            count += 1\n",
    "        accuracy_ = accuracy\n",
    "        result.append(accuracy)\n",
    "        alpha.append(i)\n",
    "    best_score = np.array(result).max()\n",
    "    idx = result.index(best_score)\n",
    "    display(Markdown(\"## Best_score : \" + str(best_score) + \", Alpha : \" + str(alpha[idx])))\n",
    "#     return best_score, alpha[idx]\n",
    "\n",
    "def cal_average_of_accuracy(li1, li2, score_li):    \n",
    "    li3 = 96574 - len(li1 + li2)\n",
    "    weight = [len(li1), len(li2), li3]\n",
    "    result = 0\n",
    "    for i, score in enumerate(score_li):\n",
    "        result += weight[i] * score\n",
    "    result = result/96574\n",
    "    print(result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveModelObjectAsPickle(model, feature):\n",
    "    filename = \"feature_\"+ str(feature) + \"_xgb_trained_model.pkl\"\n",
    "    joblib.dump(model, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_decoded = du.decodeStuffNeedsToBeDecoded(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_decoded = du.decodeStuffNeedsToBeDecoded(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vn_dd_more_than_one, vn_dd_one = get_flat_type_user(df_decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0까지 진행됨.\n",
      "5000까지 진행됨.\n",
      "10000까지 진행됨.\n",
      "15000까지 진행됨.\n",
      "20000까지 진행됨.\n",
      "25000까지 진행됨.\n",
      "30000까지 진행됨.\n",
      "35000까지 진행됨.\n",
      "40000까지 진행됨.\n",
      "45000까지 진행됨.\n",
      "50000까지 진행됨.\n",
      "55000까지 진행됨.\n",
      "60000까지 진행됨.\n",
      "65000까지 진행됨.\n",
      "70000까지 진행됨.\n",
      "75000까지 진행됨.\n",
      "80000까지 진행됨.\n",
      "85000까지 진행됨.\n",
      "90000까지 진행됨.\n"
     ]
    }
   ],
   "source": [
    "vn_fl_more_than_one, vn_fl_one = get_flat_type_user(df_decoded, \"FinelineNumber\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0까지 진행됨.\n",
      "5000까지 진행됨.\n",
      "10000까지 진행됨.\n",
      "15000까지 진행됨.\n",
      "20000까지 진행됨.\n",
      "25000까지 진행됨.\n",
      "30000까지 진행됨.\n",
      "35000까지 진행됨.\n",
      "40000까지 진행됨.\n",
      "45000까지 진행됨.\n",
      "50000까지 진행됨.\n",
      "55000까지 진행됨.\n",
      "60000까지 진행됨.\n",
      "65000까지 진행됨.\n",
      "70000까지 진행됨.\n",
      "75000까지 진행됨.\n",
      "80000까지 진행됨.\n",
      "85000까지 진행됨.\n",
      "90000까지 진행됨.\n"
     ]
    }
   ],
   "source": [
    "vn_test_fl_more_than_one, vn_test_fl_one = get_flat_type_user(df_test_decoded, \"FinelineNumber\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vn_company_more_than_one, vn_company_one = get_flat_type_user(df_decoded, \"Company\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [col for col in df_train_dd.columns if col != \"TripType\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_test_dd = df_test_dd[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_fl = [col for col in df_train_fl.columns if col != \"TripType\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_test_fl = df_test_fl[cols_fl]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 현 최고모델 Classification report를 통해 Insight를 얻자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat 완료.\n"
     ]
    }
   ],
   "source": [
    "df_to_test = get_df_has_specified_vn_list(vn_test_fl_one, df_dd = df_test_dd, df_fl = df_test_fl, is_need_to_make_df = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_1_test = af.get_df_to_fit(df_to_test, is_test_df=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_1_test.drop(\"index\", axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat 완료.\n"
     ]
    }
   ],
   "source": [
    "df_to_test = get_df_has_specified_vn_list(vn_test_fl_more_than_one, df_dd = df_test_dd, df_fl = df_test_fl, is_need_to_make_df = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_2_test = af.get_df_to_fit(df_to_test, is_test_df=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True, ...,  True,  True,  True])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_2_test.columns == X_2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_2_test.drop(\"index\", axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "vn_test_fl_3 = vn_test_fl_one + vn_test_fl_more_than_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat 완료.\n"
     ]
    }
   ],
   "source": [
    "df_to_test = get_df_has_specified_vn_list(vn_test_fl_3, is_in=False, df_dd = df_test_dd, df_fl = df_test_fl, is_need_to_make_df = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_3_test = af.get_df_to_fit(df_to_test, is_test_df=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_3_test.drop(\"index\", axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19313, 31216, 45145)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_1_test), len(X_2_test), len(X_3_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95674"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_1_test) + len(X_2_test) + len(X_3_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## feature 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat 완료.\n"
     ]
    }
   ],
   "source": [
    "df_to_test = get_df_has_specified_vn_list(vn_fl_one, df_dd = df_train_dd, df_fl = df_train_fl, is_need_to_make_df = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_1, y_1 = af.get_df_to_fit(df_to_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_enc = LabelEncoder().fit(y_1)\n",
    "y_labeled = label_enc.transform(y_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X, train_y, test_y = train_test_split(X_1, y_labeled, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "csr_train = csr_matrix(train_X.values)\n",
    "csr_test = csr_matrix(test_X.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mlogloss:1.66166\teval-mlogloss:1.66334\n",
      "Multiple eval metrics have been passed: 'eval-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until eval-mlogloss hasn't improved in 10 rounds.\n",
      "[1]\ttrain-mlogloss:1.31602\teval-mlogloss:1.3258\n",
      "[2]\ttrain-mlogloss:1.1202\teval-mlogloss:1.13234\n",
      "[3]\ttrain-mlogloss:0.992876\teval-mlogloss:1.00779\n",
      "[4]\ttrain-mlogloss:0.903931\teval-mlogloss:0.922093\n",
      "[5]\ttrain-mlogloss:0.832281\teval-mlogloss:0.852689\n",
      "[6]\ttrain-mlogloss:0.775618\teval-mlogloss:0.798166\n",
      "[7]\ttrain-mlogloss:0.728232\teval-mlogloss:0.752298\n",
      "[8]\ttrain-mlogloss:0.689028\teval-mlogloss:0.715336\n",
      "[9]\ttrain-mlogloss:0.656369\teval-mlogloss:0.683298\n",
      "[10]\ttrain-mlogloss:0.62861\teval-mlogloss:0.656622\n",
      "[11]\ttrain-mlogloss:0.604012\teval-mlogloss:0.633159\n",
      "[12]\ttrain-mlogloss:0.583449\teval-mlogloss:0.613185\n",
      "[13]\ttrain-mlogloss:0.564949\teval-mlogloss:0.594838\n",
      "[14]\ttrain-mlogloss:0.548756\teval-mlogloss:0.579191\n",
      "[15]\ttrain-mlogloss:0.534407\teval-mlogloss:0.565584\n",
      "[16]\ttrain-mlogloss:0.521388\teval-mlogloss:0.55395\n",
      "[17]\ttrain-mlogloss:0.510153\teval-mlogloss:0.543194\n",
      "[18]\ttrain-mlogloss:0.499876\teval-mlogloss:0.53362\n",
      "[19]\ttrain-mlogloss:0.490876\teval-mlogloss:0.525671\n",
      "[20]\ttrain-mlogloss:0.482811\teval-mlogloss:0.518738\n",
      "[21]\ttrain-mlogloss:0.475509\teval-mlogloss:0.512539\n",
      "[22]\ttrain-mlogloss:0.468935\teval-mlogloss:0.507073\n",
      "[23]\ttrain-mlogloss:0.462691\teval-mlogloss:0.501066\n",
      "[24]\ttrain-mlogloss:0.456794\teval-mlogloss:0.496354\n",
      "[25]\ttrain-mlogloss:0.451597\teval-mlogloss:0.491637\n",
      "[26]\ttrain-mlogloss:0.446592\teval-mlogloss:0.487553\n",
      "[27]\ttrain-mlogloss:0.441963\teval-mlogloss:0.483518\n",
      "[28]\ttrain-mlogloss:0.437733\teval-mlogloss:0.479861\n",
      "[29]\ttrain-mlogloss:0.433778\teval-mlogloss:0.476375\n",
      "[30]\ttrain-mlogloss:0.430175\teval-mlogloss:0.473526\n",
      "[31]\ttrain-mlogloss:0.426512\teval-mlogloss:0.47017\n",
      "[32]\ttrain-mlogloss:0.423204\teval-mlogloss:0.467962\n",
      "[33]\ttrain-mlogloss:0.419572\teval-mlogloss:0.465203\n",
      "[34]\ttrain-mlogloss:0.416411\teval-mlogloss:0.462766\n",
      "[35]\ttrain-mlogloss:0.41343\teval-mlogloss:0.460558\n",
      "[36]\ttrain-mlogloss:0.410655\teval-mlogloss:0.458647\n",
      "[37]\ttrain-mlogloss:0.407983\teval-mlogloss:0.456654\n",
      "[38]\ttrain-mlogloss:0.405426\teval-mlogloss:0.454793\n",
      "[39]\ttrain-mlogloss:0.402938\teval-mlogloss:0.453072\n",
      "[40]\ttrain-mlogloss:0.400335\teval-mlogloss:0.45081\n",
      "[41]\ttrain-mlogloss:0.398105\teval-mlogloss:0.449039\n",
      "[42]\ttrain-mlogloss:0.395873\teval-mlogloss:0.447502\n",
      "[43]\ttrain-mlogloss:0.393557\teval-mlogloss:0.446314\n",
      "[44]\ttrain-mlogloss:0.391458\teval-mlogloss:0.444527\n",
      "[45]\ttrain-mlogloss:0.389532\teval-mlogloss:0.443196\n",
      "[46]\ttrain-mlogloss:0.387283\teval-mlogloss:0.441614\n",
      "[47]\ttrain-mlogloss:0.384947\teval-mlogloss:0.440483\n",
      "[48]\ttrain-mlogloss:0.38302\teval-mlogloss:0.439063\n",
      "[49]\ttrain-mlogloss:0.381284\teval-mlogloss:0.437686\n",
      "[50]\ttrain-mlogloss:0.379466\teval-mlogloss:0.436834\n",
      "[51]\ttrain-mlogloss:0.377609\teval-mlogloss:0.435465\n",
      "[52]\ttrain-mlogloss:0.375881\teval-mlogloss:0.434508\n",
      "[53]\ttrain-mlogloss:0.37427\teval-mlogloss:0.433394\n",
      "[54]\ttrain-mlogloss:0.372545\teval-mlogloss:0.432274\n",
      "[55]\ttrain-mlogloss:0.370902\teval-mlogloss:0.431079\n",
      "[56]\ttrain-mlogloss:0.369384\teval-mlogloss:0.430075\n",
      "[57]\ttrain-mlogloss:0.367716\teval-mlogloss:0.429063\n",
      "[58]\ttrain-mlogloss:0.366209\teval-mlogloss:0.427898\n",
      "[59]\ttrain-mlogloss:0.36473\teval-mlogloss:0.427007\n",
      "[60]\ttrain-mlogloss:0.3633\teval-mlogloss:0.426117\n",
      "[61]\ttrain-mlogloss:0.361716\teval-mlogloss:0.424792\n",
      "[62]\ttrain-mlogloss:0.360268\teval-mlogloss:0.423898\n",
      "[63]\ttrain-mlogloss:0.358945\teval-mlogloss:0.423092\n",
      "[64]\ttrain-mlogloss:0.357597\teval-mlogloss:0.422141\n",
      "[65]\ttrain-mlogloss:0.356305\teval-mlogloss:0.421126\n",
      "[66]\ttrain-mlogloss:0.355027\teval-mlogloss:0.420053\n",
      "[67]\ttrain-mlogloss:0.353868\teval-mlogloss:0.419279\n",
      "[68]\ttrain-mlogloss:0.352465\teval-mlogloss:0.418733\n",
      "[69]\ttrain-mlogloss:0.351281\teval-mlogloss:0.417967\n",
      "[70]\ttrain-mlogloss:0.350042\teval-mlogloss:0.417329\n",
      "[71]\ttrain-mlogloss:0.348926\teval-mlogloss:0.416699\n",
      "[72]\ttrain-mlogloss:0.347825\teval-mlogloss:0.41577\n",
      "[73]\ttrain-mlogloss:0.346622\teval-mlogloss:0.414987\n",
      "[74]\ttrain-mlogloss:0.345566\teval-mlogloss:0.413961\n",
      "[75]\ttrain-mlogloss:0.344458\teval-mlogloss:0.41337\n",
      "[76]\ttrain-mlogloss:0.34341\teval-mlogloss:0.412571\n",
      "[77]\ttrain-mlogloss:0.342344\teval-mlogloss:0.411949\n",
      "[78]\ttrain-mlogloss:0.341334\teval-mlogloss:0.411336\n",
      "[79]\ttrain-mlogloss:0.340404\teval-mlogloss:0.410769\n",
      "[80]\ttrain-mlogloss:0.33939\teval-mlogloss:0.410302\n",
      "[81]\ttrain-mlogloss:0.338274\teval-mlogloss:0.409516\n",
      "[82]\ttrain-mlogloss:0.337277\teval-mlogloss:0.40903\n",
      "[83]\ttrain-mlogloss:0.336242\teval-mlogloss:0.408142\n",
      "[84]\ttrain-mlogloss:0.335141\teval-mlogloss:0.407282\n",
      "[85]\ttrain-mlogloss:0.334128\teval-mlogloss:0.406462\n",
      "[86]\ttrain-mlogloss:0.333123\teval-mlogloss:0.4058\n",
      "[87]\ttrain-mlogloss:0.332191\teval-mlogloss:0.405125\n",
      "[88]\ttrain-mlogloss:0.33131\teval-mlogloss:0.404373\n",
      "[89]\ttrain-mlogloss:0.330436\teval-mlogloss:0.403933\n",
      "[90]\ttrain-mlogloss:0.329585\teval-mlogloss:0.403461\n",
      "[91]\ttrain-mlogloss:0.328669\teval-mlogloss:0.402843\n",
      "[92]\ttrain-mlogloss:0.327793\teval-mlogloss:0.402474\n",
      "[93]\ttrain-mlogloss:0.326834\teval-mlogloss:0.402018\n",
      "[94]\ttrain-mlogloss:0.325975\teval-mlogloss:0.401437\n",
      "[95]\ttrain-mlogloss:0.325124\teval-mlogloss:0.401037\n",
      "[96]\ttrain-mlogloss:0.324203\teval-mlogloss:0.400361\n",
      "[97]\ttrain-mlogloss:0.321782\teval-mlogloss:0.39806\n",
      "[98]\ttrain-mlogloss:0.320364\teval-mlogloss:0.396619\n",
      "[99]\ttrain-mlogloss:0.319234\teval-mlogloss:0.39586\n",
      "[100]\ttrain-mlogloss:0.31819\teval-mlogloss:0.394944\n",
      "[101]\ttrain-mlogloss:0.317152\teval-mlogloss:0.39403\n",
      "[102]\ttrain-mlogloss:0.316154\teval-mlogloss:0.393325\n",
      "[103]\ttrain-mlogloss:0.315229\teval-mlogloss:0.392712\n",
      "[104]\ttrain-mlogloss:0.313444\teval-mlogloss:0.391452\n",
      "[105]\ttrain-mlogloss:0.312259\teval-mlogloss:0.390607\n",
      "[106]\ttrain-mlogloss:0.311233\teval-mlogloss:0.389911\n",
      "[107]\ttrain-mlogloss:0.310311\teval-mlogloss:0.389398\n",
      "[108]\ttrain-mlogloss:0.309407\teval-mlogloss:0.388899\n",
      "[109]\ttrain-mlogloss:0.30856\teval-mlogloss:0.388356\n",
      "[110]\ttrain-mlogloss:0.307777\teval-mlogloss:0.387923\n",
      "[111]\ttrain-mlogloss:0.307053\teval-mlogloss:0.387492\n",
      "[112]\ttrain-mlogloss:0.306339\teval-mlogloss:0.387199\n",
      "[113]\ttrain-mlogloss:0.305633\teval-mlogloss:0.386784\n",
      "[114]\ttrain-mlogloss:0.30491\teval-mlogloss:0.386364\n",
      "[115]\ttrain-mlogloss:0.304233\teval-mlogloss:0.386155\n",
      "[116]\ttrain-mlogloss:0.303631\teval-mlogloss:0.385713\n",
      "[117]\ttrain-mlogloss:0.303013\teval-mlogloss:0.38517\n",
      "[118]\ttrain-mlogloss:0.302444\teval-mlogloss:0.384758\n",
      "[119]\ttrain-mlogloss:0.301837\teval-mlogloss:0.384503\n",
      "[120]\ttrain-mlogloss:0.301142\teval-mlogloss:0.384236\n",
      "[121]\ttrain-mlogloss:0.300495\teval-mlogloss:0.384099\n",
      "[122]\ttrain-mlogloss:0.299888\teval-mlogloss:0.383731\n",
      "[123]\ttrain-mlogloss:0.299318\teval-mlogloss:0.383503\n",
      "[124]\ttrain-mlogloss:0.298691\teval-mlogloss:0.383395\n",
      "[125]\ttrain-mlogloss:0.29811\teval-mlogloss:0.3831\n",
      "[126]\ttrain-mlogloss:0.297561\teval-mlogloss:0.382639\n",
      "[127]\ttrain-mlogloss:0.297056\teval-mlogloss:0.382435\n",
      "[128]\ttrain-mlogloss:0.296547\teval-mlogloss:0.382209\n",
      "[129]\ttrain-mlogloss:0.295963\teval-mlogloss:0.382015\n",
      "[130]\ttrain-mlogloss:0.295355\teval-mlogloss:0.381615\n",
      "[131]\ttrain-mlogloss:0.294783\teval-mlogloss:0.381431\n",
      "[132]\ttrain-mlogloss:0.29419\teval-mlogloss:0.381254\n",
      "[133]\ttrain-mlogloss:0.293608\teval-mlogloss:0.380988\n",
      "[134]\ttrain-mlogloss:0.293039\teval-mlogloss:0.380874\n",
      "[135]\ttrain-mlogloss:0.292531\teval-mlogloss:0.380725\n",
      "[136]\ttrain-mlogloss:0.292023\teval-mlogloss:0.380527\n",
      "[137]\ttrain-mlogloss:0.291427\teval-mlogloss:0.380165\n",
      "[138]\ttrain-mlogloss:0.290945\teval-mlogloss:0.380005\n",
      "[139]\ttrain-mlogloss:0.290455\teval-mlogloss:0.379764\n",
      "[140]\ttrain-mlogloss:0.289926\teval-mlogloss:0.379538\n",
      "[141]\ttrain-mlogloss:0.289454\teval-mlogloss:0.379332\n",
      "[142]\ttrain-mlogloss:0.288892\teval-mlogloss:0.379049\n",
      "[143]\ttrain-mlogloss:0.288342\teval-mlogloss:0.378708\n",
      "[144]\ttrain-mlogloss:0.28786\teval-mlogloss:0.378308\n",
      "[145]\ttrain-mlogloss:0.287293\teval-mlogloss:0.377994\n",
      "[146]\ttrain-mlogloss:0.286736\teval-mlogloss:0.377842\n",
      "[147]\ttrain-mlogloss:0.286264\teval-mlogloss:0.377571\n",
      "[148]\ttrain-mlogloss:0.285767\teval-mlogloss:0.377469\n",
      "[149]\ttrain-mlogloss:0.285276\teval-mlogloss:0.377264\n",
      "[150]\ttrain-mlogloss:0.284834\teval-mlogloss:0.377114\n",
      "[151]\ttrain-mlogloss:0.284375\teval-mlogloss:0.376915\n",
      "[152]\ttrain-mlogloss:0.283961\teval-mlogloss:0.376758\n",
      "[153]\ttrain-mlogloss:0.28349\teval-mlogloss:0.376414\n",
      "[154]\ttrain-mlogloss:0.282973\teval-mlogloss:0.37636\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[155]\ttrain-mlogloss:0.282513\teval-mlogloss:0.376065\n",
      "[156]\ttrain-mlogloss:0.282089\teval-mlogloss:0.375853\n",
      "[157]\ttrain-mlogloss:0.281656\teval-mlogloss:0.375643\n",
      "[158]\ttrain-mlogloss:0.281234\teval-mlogloss:0.375468\n",
      "[159]\ttrain-mlogloss:0.280796\teval-mlogloss:0.375314\n",
      "[160]\ttrain-mlogloss:0.280375\teval-mlogloss:0.375131\n",
      "[161]\ttrain-mlogloss:0.279923\teval-mlogloss:0.374978\n",
      "[162]\ttrain-mlogloss:0.279325\teval-mlogloss:0.374806\n",
      "[163]\ttrain-mlogloss:0.278959\teval-mlogloss:0.374763\n",
      "[164]\ttrain-mlogloss:0.278579\teval-mlogloss:0.374669\n",
      "[165]\ttrain-mlogloss:0.278211\teval-mlogloss:0.374417\n",
      "[166]\ttrain-mlogloss:0.277872\teval-mlogloss:0.374307\n",
      "[167]\ttrain-mlogloss:0.277529\teval-mlogloss:0.374098\n",
      "[168]\ttrain-mlogloss:0.27718\teval-mlogloss:0.374027\n",
      "[169]\ttrain-mlogloss:0.2768\teval-mlogloss:0.373897\n",
      "[170]\ttrain-mlogloss:0.276393\teval-mlogloss:0.373721\n",
      "[171]\ttrain-mlogloss:0.276012\teval-mlogloss:0.37376\n",
      "[172]\ttrain-mlogloss:0.275659\teval-mlogloss:0.373514\n",
      "[173]\ttrain-mlogloss:0.27524\teval-mlogloss:0.373389\n",
      "[174]\ttrain-mlogloss:0.274855\teval-mlogloss:0.373177\n",
      "[175]\ttrain-mlogloss:0.274463\teval-mlogloss:0.372894\n",
      "[176]\ttrain-mlogloss:0.274145\teval-mlogloss:0.372737\n",
      "[177]\ttrain-mlogloss:0.273822\teval-mlogloss:0.37258\n",
      "[178]\ttrain-mlogloss:0.273511\teval-mlogloss:0.372355\n",
      "[179]\ttrain-mlogloss:0.273214\teval-mlogloss:0.37224\n",
      "[180]\ttrain-mlogloss:0.272902\teval-mlogloss:0.372079\n",
      "[181]\ttrain-mlogloss:0.27257\teval-mlogloss:0.37191\n",
      "[182]\ttrain-mlogloss:0.272204\teval-mlogloss:0.371735\n",
      "[183]\ttrain-mlogloss:0.271832\teval-mlogloss:0.371722\n",
      "[184]\ttrain-mlogloss:0.271474\teval-mlogloss:0.371513\n",
      "[185]\ttrain-mlogloss:0.271215\teval-mlogloss:0.371404\n",
      "[186]\ttrain-mlogloss:0.270941\teval-mlogloss:0.371331\n",
      "[187]\ttrain-mlogloss:0.270609\teval-mlogloss:0.371199\n",
      "[188]\ttrain-mlogloss:0.270187\teval-mlogloss:0.371068\n",
      "[189]\ttrain-mlogloss:0.269789\teval-mlogloss:0.370849\n",
      "[190]\ttrain-mlogloss:0.26947\teval-mlogloss:0.370793\n",
      "[191]\ttrain-mlogloss:0.269176\teval-mlogloss:0.370665\n",
      "[192]\ttrain-mlogloss:0.268861\teval-mlogloss:0.370586\n",
      "[193]\ttrain-mlogloss:0.268554\teval-mlogloss:0.370499\n",
      "[194]\ttrain-mlogloss:0.268216\teval-mlogloss:0.370416\n",
      "[195]\ttrain-mlogloss:0.267843\teval-mlogloss:0.370353\n",
      "[196]\ttrain-mlogloss:0.267514\teval-mlogloss:0.370335\n",
      "[197]\ttrain-mlogloss:0.267203\teval-mlogloss:0.370294\n",
      "[198]\ttrain-mlogloss:0.266884\teval-mlogloss:0.370155\n",
      "[199]\ttrain-mlogloss:0.266587\teval-mlogloss:0.370149\n",
      "[200]\ttrain-mlogloss:0.266299\teval-mlogloss:0.370061\n",
      "[201]\ttrain-mlogloss:0.266013\teval-mlogloss:0.370021\n",
      "[202]\ttrain-mlogloss:0.265694\teval-mlogloss:0.369804\n",
      "[203]\ttrain-mlogloss:0.265336\teval-mlogloss:0.369761\n",
      "[204]\ttrain-mlogloss:0.265104\teval-mlogloss:0.369856\n",
      "[205]\ttrain-mlogloss:0.264856\teval-mlogloss:0.369848\n",
      "[206]\ttrain-mlogloss:0.264602\teval-mlogloss:0.369686\n",
      "[207]\ttrain-mlogloss:0.264347\teval-mlogloss:0.369754\n",
      "[208]\ttrain-mlogloss:0.264127\teval-mlogloss:0.369724\n",
      "[209]\ttrain-mlogloss:0.263884\teval-mlogloss:0.369492\n",
      "[210]\ttrain-mlogloss:0.263641\teval-mlogloss:0.369361\n",
      "[211]\ttrain-mlogloss:0.263383\teval-mlogloss:0.369255\n",
      "[212]\ttrain-mlogloss:0.263109\teval-mlogloss:0.369449\n",
      "[213]\ttrain-mlogloss:0.262882\teval-mlogloss:0.369373\n",
      "[214]\ttrain-mlogloss:0.262649\teval-mlogloss:0.369311\n",
      "[215]\ttrain-mlogloss:0.262398\teval-mlogloss:0.369212\n",
      "[216]\ttrain-mlogloss:0.262142\teval-mlogloss:0.369254\n",
      "[217]\ttrain-mlogloss:0.261901\teval-mlogloss:0.369243\n",
      "[218]\ttrain-mlogloss:0.261668\teval-mlogloss:0.369108\n",
      "[219]\ttrain-mlogloss:0.261435\teval-mlogloss:0.369077\n",
      "[220]\ttrain-mlogloss:0.261231\teval-mlogloss:0.369084\n",
      "[221]\ttrain-mlogloss:0.260979\teval-mlogloss:0.368943\n",
      "[222]\ttrain-mlogloss:0.260764\teval-mlogloss:0.3689\n",
      "[223]\ttrain-mlogloss:0.260494\teval-mlogloss:0.368907\n",
      "[224]\ttrain-mlogloss:0.26019\teval-mlogloss:0.368788\n",
      "[225]\ttrain-mlogloss:0.259884\teval-mlogloss:0.368769\n",
      "[226]\ttrain-mlogloss:0.25963\teval-mlogloss:0.368632\n",
      "[227]\ttrain-mlogloss:0.259378\teval-mlogloss:0.368591\n",
      "[228]\ttrain-mlogloss:0.259132\teval-mlogloss:0.368562\n",
      "[229]\ttrain-mlogloss:0.25886\teval-mlogloss:0.368405\n",
      "[230]\ttrain-mlogloss:0.258625\teval-mlogloss:0.368466\n",
      "[231]\ttrain-mlogloss:0.258368\teval-mlogloss:0.368446\n",
      "[232]\ttrain-mlogloss:0.258148\teval-mlogloss:0.368481\n",
      "[233]\ttrain-mlogloss:0.257934\teval-mlogloss:0.368409\n",
      "[234]\ttrain-mlogloss:0.257617\teval-mlogloss:0.368364\n",
      "[235]\ttrain-mlogloss:0.257422\teval-mlogloss:0.368404\n",
      "[236]\ttrain-mlogloss:0.257221\teval-mlogloss:0.368344\n",
      "[237]\ttrain-mlogloss:0.257005\teval-mlogloss:0.368194\n",
      "[238]\ttrain-mlogloss:0.25682\teval-mlogloss:0.368219\n",
      "[239]\ttrain-mlogloss:0.256637\teval-mlogloss:0.368144\n",
      "[240]\ttrain-mlogloss:0.256449\teval-mlogloss:0.368061\n",
      "[241]\ttrain-mlogloss:0.256221\teval-mlogloss:0.368068\n",
      "[242]\ttrain-mlogloss:0.256025\teval-mlogloss:0.367976\n",
      "[243]\ttrain-mlogloss:0.255824\teval-mlogloss:0.367982\n",
      "[244]\ttrain-mlogloss:0.25565\teval-mlogloss:0.367942\n",
      "[245]\ttrain-mlogloss:0.255445\teval-mlogloss:0.367871\n",
      "[246]\ttrain-mlogloss:0.255228\teval-mlogloss:0.367809\n",
      "[247]\ttrain-mlogloss:0.255052\teval-mlogloss:0.367792\n",
      "[248]\ttrain-mlogloss:0.254845\teval-mlogloss:0.367711\n",
      "[249]\ttrain-mlogloss:0.254645\teval-mlogloss:0.367697\n",
      "[250]\ttrain-mlogloss:0.254467\teval-mlogloss:0.367643\n",
      "[251]\ttrain-mlogloss:0.254294\teval-mlogloss:0.36767\n",
      "[252]\ttrain-mlogloss:0.254099\teval-mlogloss:0.367634\n",
      "[253]\ttrain-mlogloss:0.253917\teval-mlogloss:0.3677\n",
      "[254]\ttrain-mlogloss:0.253741\teval-mlogloss:0.367719\n",
      "[255]\ttrain-mlogloss:0.25356\teval-mlogloss:0.3677\n",
      "[256]\ttrain-mlogloss:0.253361\teval-mlogloss:0.367805\n",
      "[257]\ttrain-mlogloss:0.253163\teval-mlogloss:0.367705\n",
      "[258]\ttrain-mlogloss:0.252996\teval-mlogloss:0.367675\n",
      "[259]\ttrain-mlogloss:0.252833\teval-mlogloss:0.367645\n",
      "[260]\ttrain-mlogloss:0.252658\teval-mlogloss:0.367547\n",
      "[261]\ttrain-mlogloss:0.252456\teval-mlogloss:0.367511\n",
      "[262]\ttrain-mlogloss:0.252274\teval-mlogloss:0.367422\n",
      "[263]\ttrain-mlogloss:0.2521\teval-mlogloss:0.36755\n",
      "[264]\ttrain-mlogloss:0.251927\teval-mlogloss:0.367478\n",
      "[265]\ttrain-mlogloss:0.251762\teval-mlogloss:0.36751\n",
      "[266]\ttrain-mlogloss:0.25158\teval-mlogloss:0.36751\n",
      "[267]\ttrain-mlogloss:0.25142\teval-mlogloss:0.367478\n",
      "[268]\ttrain-mlogloss:0.251253\teval-mlogloss:0.367464\n",
      "[269]\ttrain-mlogloss:0.251069\teval-mlogloss:0.367405\n",
      "[270]\ttrain-mlogloss:0.250894\teval-mlogloss:0.36735\n",
      "[271]\ttrain-mlogloss:0.250727\teval-mlogloss:0.367298\n",
      "[272]\ttrain-mlogloss:0.250559\teval-mlogloss:0.367414\n",
      "[273]\ttrain-mlogloss:0.250387\teval-mlogloss:0.36734\n",
      "[274]\ttrain-mlogloss:0.250232\teval-mlogloss:0.367379\n",
      "[275]\ttrain-mlogloss:0.250056\teval-mlogloss:0.367332\n",
      "[276]\ttrain-mlogloss:0.249889\teval-mlogloss:0.367383\n",
      "[277]\ttrain-mlogloss:0.249713\teval-mlogloss:0.367374\n",
      "[278]\ttrain-mlogloss:0.249454\teval-mlogloss:0.367353\n",
      "[279]\ttrain-mlogloss:0.249249\teval-mlogloss:0.367432\n",
      "[280]\ttrain-mlogloss:0.24904\teval-mlogloss:0.367475\n",
      "[281]\ttrain-mlogloss:0.248835\teval-mlogloss:0.367463\n",
      "Stopping. Best iteration:\n",
      "[271]\ttrain-mlogloss:0.250727\teval-mlogloss:0.367298\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if xgboost:\n",
    "    dtrain = xgb.DMatrix(csr_train, label=train_y, feature_names = train_X.columns)\n",
    "    dtest = xgb.DMatrix(csr_test, label=test_y, feature_names = train_X.columns)\n",
    "    num_boost_round = 500\n",
    "    params = {'objective': 'multi:softprob', \n",
    "              'eval_metric': 'mlogloss',\n",
    "              'num_class':38,\n",
    "              'max_depth':4,\n",
    "              'eta': 0.25}\n",
    "\n",
    "    evals = [(dtrain, 'train'), (dtest, 'eval')]\n",
    "\n",
    "    bst = xgb.train(params=params,  \n",
    "                    dtrain=dtrain, \n",
    "                    num_boost_round=num_boost_round, \n",
    "                    evals=evals,\n",
    "                    early_stopping_rounds=10,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feature 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat 완료.\n"
     ]
    }
   ],
   "source": [
    "df_to_test = get_df_has_specified_vn_list(vn_fl_more_than_one, df_dd = df_train_dd, df_fl = df_train_fl, is_need_to_make_df=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_2, y_2 = af.get_df_to_fit(df_to_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_enc = LabelEncoder().fit(y_2)\n",
    "y_labeled = label_enc.transform(y_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X, train_y, test_y = train_test_split(X_2, y_labeled, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "csr_train = csr_matrix(train_X.values)\n",
    "csr_test = csr_matrix(test_X.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mlogloss:2.45352\teval-mlogloss:2.463\n",
      "Multiple eval metrics have been passed: 'eval-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until eval-mlogloss hasn't improved in 10 rounds.\n",
      "[1]\ttrain-mlogloss:2.20739\teval-mlogloss:2.22532\n",
      "[2]\ttrain-mlogloss:2.03683\teval-mlogloss:2.06199\n",
      "[3]\ttrain-mlogloss:1.90914\teval-mlogloss:1.94012\n",
      "[4]\ttrain-mlogloss:1.8097\teval-mlogloss:1.84626\n",
      "[5]\ttrain-mlogloss:1.7268\teval-mlogloss:1.76735\n",
      "[6]\ttrain-mlogloss:1.65856\teval-mlogloss:1.70286\n",
      "[7]\ttrain-mlogloss:1.60111\teval-mlogloss:1.64874\n",
      "[8]\ttrain-mlogloss:1.55113\teval-mlogloss:1.60206\n",
      "[9]\ttrain-mlogloss:1.50773\teval-mlogloss:1.56201\n",
      "[10]\ttrain-mlogloss:1.46929\teval-mlogloss:1.52746\n",
      "[11]\ttrain-mlogloss:1.43496\teval-mlogloss:1.49665\n",
      "[12]\ttrain-mlogloss:1.40467\teval-mlogloss:1.46952\n",
      "[13]\ttrain-mlogloss:1.37719\teval-mlogloss:1.44449\n",
      "[14]\ttrain-mlogloss:1.35302\teval-mlogloss:1.42287\n",
      "[15]\ttrain-mlogloss:1.33069\teval-mlogloss:1.40363\n",
      "[16]\ttrain-mlogloss:1.31038\teval-mlogloss:1.38645\n",
      "[17]\ttrain-mlogloss:1.29191\teval-mlogloss:1.37067\n",
      "[18]\ttrain-mlogloss:1.2738\teval-mlogloss:1.35529\n",
      "[19]\ttrain-mlogloss:1.25787\teval-mlogloss:1.34265\n",
      "[20]\ttrain-mlogloss:1.24252\teval-mlogloss:1.33028\n",
      "[21]\ttrain-mlogloss:1.22863\teval-mlogloss:1.31888\n",
      "[22]\ttrain-mlogloss:1.2154\teval-mlogloss:1.30848\n",
      "[23]\ttrain-mlogloss:1.203\teval-mlogloss:1.29843\n",
      "[24]\ttrain-mlogloss:1.19119\teval-mlogloss:1.28972\n",
      "[25]\ttrain-mlogloss:1.18002\teval-mlogloss:1.28134\n",
      "[26]\ttrain-mlogloss:1.17\teval-mlogloss:1.27372\n",
      "[27]\ttrain-mlogloss:1.16031\teval-mlogloss:1.26671\n",
      "[28]\ttrain-mlogloss:1.15059\teval-mlogloss:1.25962\n",
      "[29]\ttrain-mlogloss:1.14147\teval-mlogloss:1.25308\n",
      "[30]\ttrain-mlogloss:1.13275\teval-mlogloss:1.24711\n",
      "[31]\ttrain-mlogloss:1.1243\teval-mlogloss:1.24137\n",
      "[32]\ttrain-mlogloss:1.11594\teval-mlogloss:1.23519\n",
      "[33]\ttrain-mlogloss:1.10822\teval-mlogloss:1.23016\n",
      "[34]\ttrain-mlogloss:1.10079\teval-mlogloss:1.22465\n",
      "[35]\ttrain-mlogloss:1.09381\teval-mlogloss:1.21983\n",
      "[36]\ttrain-mlogloss:1.08673\teval-mlogloss:1.2154\n",
      "[37]\ttrain-mlogloss:1.07996\teval-mlogloss:1.2109\n",
      "[38]\ttrain-mlogloss:1.07334\teval-mlogloss:1.20663\n",
      "[39]\ttrain-mlogloss:1.06674\teval-mlogloss:1.20185\n",
      "[40]\ttrain-mlogloss:1.06076\teval-mlogloss:1.19769\n",
      "[41]\ttrain-mlogloss:1.05464\teval-mlogloss:1.19366\n",
      "[42]\ttrain-mlogloss:1.04846\teval-mlogloss:1.18987\n",
      "[43]\ttrain-mlogloss:1.04277\teval-mlogloss:1.1862\n",
      "[44]\ttrain-mlogloss:1.03703\teval-mlogloss:1.18302\n",
      "[45]\ttrain-mlogloss:1.03189\teval-mlogloss:1.17969\n",
      "[46]\ttrain-mlogloss:1.02639\teval-mlogloss:1.17633\n",
      "[47]\ttrain-mlogloss:1.02101\teval-mlogloss:1.17336\n",
      "[48]\ttrain-mlogloss:1.01581\teval-mlogloss:1.17017\n",
      "[49]\ttrain-mlogloss:1.01045\teval-mlogloss:1.16729\n",
      "[50]\ttrain-mlogloss:1.00523\teval-mlogloss:1.164\n",
      "[51]\ttrain-mlogloss:1.00032\teval-mlogloss:1.16086\n",
      "[52]\ttrain-mlogloss:0.995859\teval-mlogloss:1.15757\n",
      "[53]\ttrain-mlogloss:0.991284\teval-mlogloss:1.1545\n",
      "[54]\ttrain-mlogloss:0.986682\teval-mlogloss:1.15191\n",
      "[55]\ttrain-mlogloss:0.981904\teval-mlogloss:1.14919\n",
      "[56]\ttrain-mlogloss:0.977453\teval-mlogloss:1.1462\n",
      "[57]\ttrain-mlogloss:0.973246\teval-mlogloss:1.14397\n",
      "[58]\ttrain-mlogloss:0.968806\teval-mlogloss:1.14095\n",
      "[59]\ttrain-mlogloss:0.964619\teval-mlogloss:1.13868\n",
      "[60]\ttrain-mlogloss:0.960341\teval-mlogloss:1.13623\n",
      "[61]\ttrain-mlogloss:0.956289\teval-mlogloss:1.13388\n",
      "[62]\ttrain-mlogloss:0.952517\teval-mlogloss:1.13177\n",
      "[63]\ttrain-mlogloss:0.948735\teval-mlogloss:1.12971\n",
      "[64]\ttrain-mlogloss:0.944625\teval-mlogloss:1.12731\n",
      "[65]\ttrain-mlogloss:0.94098\teval-mlogloss:1.1253\n",
      "[66]\ttrain-mlogloss:0.937036\teval-mlogloss:1.12319\n",
      "[67]\ttrain-mlogloss:0.933686\teval-mlogloss:1.12132\n",
      "[68]\ttrain-mlogloss:0.930133\teval-mlogloss:1.11916\n",
      "[69]\ttrain-mlogloss:0.926397\teval-mlogloss:1.11677\n",
      "[70]\ttrain-mlogloss:0.92283\teval-mlogloss:1.11507\n",
      "[71]\ttrain-mlogloss:0.919304\teval-mlogloss:1.11332\n",
      "[72]\ttrain-mlogloss:0.915915\teval-mlogloss:1.11157\n",
      "[73]\ttrain-mlogloss:0.912627\teval-mlogloss:1.10963\n",
      "[74]\ttrain-mlogloss:0.909255\teval-mlogloss:1.10787\n",
      "[75]\ttrain-mlogloss:0.906137\teval-mlogloss:1.10621\n",
      "[76]\ttrain-mlogloss:0.902999\teval-mlogloss:1.10451\n",
      "[77]\ttrain-mlogloss:0.899738\teval-mlogloss:1.10268\n",
      "[78]\ttrain-mlogloss:0.896605\teval-mlogloss:1.10134\n",
      "[79]\ttrain-mlogloss:0.893393\teval-mlogloss:1.09943\n",
      "[80]\ttrain-mlogloss:0.890453\teval-mlogloss:1.098\n",
      "[81]\ttrain-mlogloss:0.887308\teval-mlogloss:1.09624\n",
      "[82]\ttrain-mlogloss:0.884329\teval-mlogloss:1.09427\n",
      "[83]\ttrain-mlogloss:0.88141\teval-mlogloss:1.09278\n",
      "[84]\ttrain-mlogloss:0.878779\teval-mlogloss:1.09138\n",
      "[85]\ttrain-mlogloss:0.876117\teval-mlogloss:1.09015\n",
      "[86]\ttrain-mlogloss:0.873365\teval-mlogloss:1.08873\n",
      "[87]\ttrain-mlogloss:0.870446\teval-mlogloss:1.08757\n",
      "[88]\ttrain-mlogloss:0.867719\teval-mlogloss:1.08614\n",
      "[89]\ttrain-mlogloss:0.864961\teval-mlogloss:1.08478\n",
      "[90]\ttrain-mlogloss:0.862113\teval-mlogloss:1.08329\n",
      "[91]\ttrain-mlogloss:0.85951\teval-mlogloss:1.08166\n",
      "[92]\ttrain-mlogloss:0.856819\teval-mlogloss:1.08002\n",
      "[93]\ttrain-mlogloss:0.853847\teval-mlogloss:1.07857\n",
      "[94]\ttrain-mlogloss:0.85125\teval-mlogloss:1.07713\n",
      "[95]\ttrain-mlogloss:0.848675\teval-mlogloss:1.07586\n",
      "[96]\ttrain-mlogloss:0.846217\teval-mlogloss:1.07491\n",
      "[97]\ttrain-mlogloss:0.843711\teval-mlogloss:1.07382\n",
      "[98]\ttrain-mlogloss:0.84109\teval-mlogloss:1.07212\n",
      "[99]\ttrain-mlogloss:0.83867\teval-mlogloss:1.07094\n",
      "[100]\ttrain-mlogloss:0.835983\teval-mlogloss:1.0699\n",
      "[101]\ttrain-mlogloss:0.83347\teval-mlogloss:1.06879\n",
      "[102]\ttrain-mlogloss:0.831014\teval-mlogloss:1.06758\n",
      "[103]\ttrain-mlogloss:0.828611\teval-mlogloss:1.06681\n",
      "[104]\ttrain-mlogloss:0.826251\teval-mlogloss:1.06574\n",
      "[105]\ttrain-mlogloss:0.824094\teval-mlogloss:1.06462\n",
      "[106]\ttrain-mlogloss:0.821713\teval-mlogloss:1.06364\n",
      "[107]\ttrain-mlogloss:0.819454\teval-mlogloss:1.0629\n",
      "[108]\ttrain-mlogloss:0.817081\teval-mlogloss:1.06197\n",
      "[109]\ttrain-mlogloss:0.814804\teval-mlogloss:1.06106\n",
      "[110]\ttrain-mlogloss:0.812513\teval-mlogloss:1.06011\n",
      "[111]\ttrain-mlogloss:0.810449\teval-mlogloss:1.05914\n",
      "[112]\ttrain-mlogloss:0.808282\teval-mlogloss:1.05839\n",
      "[113]\ttrain-mlogloss:0.805913\teval-mlogloss:1.05771\n",
      "[114]\ttrain-mlogloss:0.803802\teval-mlogloss:1.05671\n",
      "[115]\ttrain-mlogloss:0.80166\teval-mlogloss:1.05567\n",
      "[116]\ttrain-mlogloss:0.79952\teval-mlogloss:1.0549\n",
      "[117]\ttrain-mlogloss:0.797306\teval-mlogloss:1.05416\n",
      "[118]\ttrain-mlogloss:0.795228\teval-mlogloss:1.05317\n",
      "[119]\ttrain-mlogloss:0.79309\teval-mlogloss:1.05219\n",
      "[120]\ttrain-mlogloss:0.79118\teval-mlogloss:1.05134\n",
      "[121]\ttrain-mlogloss:0.788924\teval-mlogloss:1.05024\n",
      "[122]\ttrain-mlogloss:0.78674\teval-mlogloss:1.04956\n",
      "[123]\ttrain-mlogloss:0.784539\teval-mlogloss:1.04882\n",
      "[124]\ttrain-mlogloss:0.782524\teval-mlogloss:1.04814\n",
      "[125]\ttrain-mlogloss:0.780578\teval-mlogloss:1.04707\n",
      "[126]\ttrain-mlogloss:0.778646\teval-mlogloss:1.04645\n",
      "[127]\ttrain-mlogloss:0.776641\teval-mlogloss:1.04584\n",
      "[128]\ttrain-mlogloss:0.774751\teval-mlogloss:1.04494\n",
      "[129]\ttrain-mlogloss:0.77291\teval-mlogloss:1.04395\n",
      "[130]\ttrain-mlogloss:0.770858\teval-mlogloss:1.04315\n",
      "[131]\ttrain-mlogloss:0.768965\teval-mlogloss:1.04224\n",
      "[132]\ttrain-mlogloss:0.76705\teval-mlogloss:1.04137\n",
      "[133]\ttrain-mlogloss:0.765176\teval-mlogloss:1.04013\n",
      "[134]\ttrain-mlogloss:0.763266\teval-mlogloss:1.03934\n",
      "[135]\ttrain-mlogloss:0.761152\teval-mlogloss:1.03855\n",
      "[136]\ttrain-mlogloss:0.759303\teval-mlogloss:1.03798\n",
      "[137]\ttrain-mlogloss:0.757551\teval-mlogloss:1.03753\n",
      "[138]\ttrain-mlogloss:0.755792\teval-mlogloss:1.03698\n",
      "[139]\ttrain-mlogloss:0.753908\teval-mlogloss:1.03634\n",
      "[140]\ttrain-mlogloss:0.752241\teval-mlogloss:1.03557\n",
      "[141]\ttrain-mlogloss:0.750435\teval-mlogloss:1.03505\n",
      "[142]\ttrain-mlogloss:0.748699\teval-mlogloss:1.03409\n",
      "[143]\ttrain-mlogloss:0.746933\teval-mlogloss:1.03351\n",
      "[144]\ttrain-mlogloss:0.745061\teval-mlogloss:1.03267\n",
      "[145]\ttrain-mlogloss:0.743243\teval-mlogloss:1.03204\n",
      "[146]\ttrain-mlogloss:0.741487\teval-mlogloss:1.03141\n",
      "[147]\ttrain-mlogloss:0.73969\teval-mlogloss:1.03063\n",
      "[148]\ttrain-mlogloss:0.738065\teval-mlogloss:1.02994\n",
      "[149]\ttrain-mlogloss:0.736449\teval-mlogloss:1.02909\n",
      "[150]\ttrain-mlogloss:0.734768\teval-mlogloss:1.02854\n",
      "[151]\ttrain-mlogloss:0.733134\teval-mlogloss:1.02815\n",
      "[152]\ttrain-mlogloss:0.731439\teval-mlogloss:1.02753\n",
      "[153]\ttrain-mlogloss:0.729745\teval-mlogloss:1.02685\n",
      "[154]\ttrain-mlogloss:0.728137\teval-mlogloss:1.02647\n",
      "[155]\ttrain-mlogloss:0.726564\teval-mlogloss:1.02561\n",
      "[156]\ttrain-mlogloss:0.724902\teval-mlogloss:1.02504\n",
      "[157]\ttrain-mlogloss:0.723178\teval-mlogloss:1.02424\n",
      "[158]\ttrain-mlogloss:0.721649\teval-mlogloss:1.02358\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[159]\ttrain-mlogloss:0.720036\teval-mlogloss:1.02329\n",
      "[160]\ttrain-mlogloss:0.718476\teval-mlogloss:1.02314\n",
      "[161]\ttrain-mlogloss:0.716973\teval-mlogloss:1.02233\n",
      "[162]\ttrain-mlogloss:0.715489\teval-mlogloss:1.02192\n",
      "[163]\ttrain-mlogloss:0.714032\teval-mlogloss:1.02137\n",
      "[164]\ttrain-mlogloss:0.712611\teval-mlogloss:1.02083\n",
      "[165]\ttrain-mlogloss:0.711085\teval-mlogloss:1.02029\n",
      "[166]\ttrain-mlogloss:0.709592\teval-mlogloss:1.02002\n",
      "[167]\ttrain-mlogloss:0.708009\teval-mlogloss:1.01939\n",
      "[168]\ttrain-mlogloss:0.706513\teval-mlogloss:1.01866\n",
      "[169]\ttrain-mlogloss:0.705125\teval-mlogloss:1.01844\n",
      "[170]\ttrain-mlogloss:0.703778\teval-mlogloss:1.01801\n",
      "[171]\ttrain-mlogloss:0.702231\teval-mlogloss:1.0175\n",
      "[172]\ttrain-mlogloss:0.700849\teval-mlogloss:1.01701\n",
      "[173]\ttrain-mlogloss:0.699455\teval-mlogloss:1.0167\n",
      "[174]\ttrain-mlogloss:0.698064\teval-mlogloss:1.01604\n",
      "[175]\ttrain-mlogloss:0.696649\teval-mlogloss:1.01545\n",
      "[176]\ttrain-mlogloss:0.695186\teval-mlogloss:1.01499\n",
      "[177]\ttrain-mlogloss:0.693628\teval-mlogloss:1.0144\n",
      "[178]\ttrain-mlogloss:0.692248\teval-mlogloss:1.01413\n",
      "[179]\ttrain-mlogloss:0.690778\teval-mlogloss:1.01393\n",
      "[180]\ttrain-mlogloss:0.689452\teval-mlogloss:1.0134\n",
      "[181]\ttrain-mlogloss:0.688035\teval-mlogloss:1.01303\n",
      "[182]\ttrain-mlogloss:0.686528\teval-mlogloss:1.01247\n",
      "[183]\ttrain-mlogloss:0.685064\teval-mlogloss:1.01174\n",
      "[184]\ttrain-mlogloss:0.683893\teval-mlogloss:1.01142\n",
      "[185]\ttrain-mlogloss:0.682444\teval-mlogloss:1.01092\n",
      "[186]\ttrain-mlogloss:0.681059\teval-mlogloss:1.01039\n",
      "[187]\ttrain-mlogloss:0.679787\teval-mlogloss:1.00985\n",
      "[188]\ttrain-mlogloss:0.678461\teval-mlogloss:1.00942\n",
      "[189]\ttrain-mlogloss:0.677171\teval-mlogloss:1.00901\n",
      "[190]\ttrain-mlogloss:0.675868\teval-mlogloss:1.00878\n",
      "[191]\ttrain-mlogloss:0.674605\teval-mlogloss:1.00835\n",
      "[192]\ttrain-mlogloss:0.673323\teval-mlogloss:1.00769\n",
      "[193]\ttrain-mlogloss:0.672141\teval-mlogloss:1.00745\n",
      "[194]\ttrain-mlogloss:0.670665\teval-mlogloss:1.0071\n",
      "[195]\ttrain-mlogloss:0.669314\teval-mlogloss:1.00678\n",
      "[196]\ttrain-mlogloss:0.668085\teval-mlogloss:1.00664\n",
      "[197]\ttrain-mlogloss:0.666807\teval-mlogloss:1.00634\n",
      "[198]\ttrain-mlogloss:0.665546\teval-mlogloss:1.00605\n",
      "[199]\ttrain-mlogloss:0.664175\teval-mlogloss:1.00567\n",
      "[200]\ttrain-mlogloss:0.662848\teval-mlogloss:1.00539\n",
      "[201]\ttrain-mlogloss:0.661594\teval-mlogloss:1.00531\n",
      "[202]\ttrain-mlogloss:0.660359\teval-mlogloss:1.0049\n",
      "[203]\ttrain-mlogloss:0.65922\teval-mlogloss:1.00455\n",
      "[204]\ttrain-mlogloss:0.657902\teval-mlogloss:1.00404\n",
      "[205]\ttrain-mlogloss:0.656457\teval-mlogloss:1.00363\n",
      "[206]\ttrain-mlogloss:0.655056\teval-mlogloss:1.00298\n",
      "[207]\ttrain-mlogloss:0.653903\teval-mlogloss:1.00279\n",
      "[208]\ttrain-mlogloss:0.65276\teval-mlogloss:1.00242\n",
      "[209]\ttrain-mlogloss:0.651627\teval-mlogloss:1.00182\n",
      "[210]\ttrain-mlogloss:0.650347\teval-mlogloss:1.00139\n",
      "[211]\ttrain-mlogloss:0.649135\teval-mlogloss:1.00105\n",
      "[212]\ttrain-mlogloss:0.647954\teval-mlogloss:1.00062\n",
      "[213]\ttrain-mlogloss:0.646898\teval-mlogloss:1.00057\n",
      "[214]\ttrain-mlogloss:0.645798\teval-mlogloss:1.0003\n",
      "[215]\ttrain-mlogloss:0.644768\teval-mlogloss:1.00013\n",
      "[216]\ttrain-mlogloss:0.643618\teval-mlogloss:0.999973\n",
      "[217]\ttrain-mlogloss:0.642392\teval-mlogloss:0.999629\n",
      "[218]\ttrain-mlogloss:0.641322\teval-mlogloss:0.999436\n",
      "[219]\ttrain-mlogloss:0.640157\teval-mlogloss:0.998903\n",
      "[220]\ttrain-mlogloss:0.639118\teval-mlogloss:0.998779\n",
      "[221]\ttrain-mlogloss:0.637998\teval-mlogloss:0.998553\n",
      "[222]\ttrain-mlogloss:0.636909\teval-mlogloss:0.998261\n",
      "[223]\ttrain-mlogloss:0.635779\teval-mlogloss:0.997789\n",
      "[224]\ttrain-mlogloss:0.63464\teval-mlogloss:0.997432\n",
      "[225]\ttrain-mlogloss:0.633523\teval-mlogloss:0.997254\n",
      "[226]\ttrain-mlogloss:0.632458\teval-mlogloss:0.996939\n",
      "[227]\ttrain-mlogloss:0.631423\teval-mlogloss:0.996864\n",
      "[228]\ttrain-mlogloss:0.630248\teval-mlogloss:0.996525\n",
      "[229]\ttrain-mlogloss:0.629158\teval-mlogloss:0.996252\n",
      "[230]\ttrain-mlogloss:0.627986\teval-mlogloss:0.996058\n",
      "[231]\ttrain-mlogloss:0.62682\teval-mlogloss:0.9956\n",
      "[232]\ttrain-mlogloss:0.625775\teval-mlogloss:0.995201\n",
      "[233]\ttrain-mlogloss:0.624712\teval-mlogloss:0.994959\n",
      "[234]\ttrain-mlogloss:0.623658\teval-mlogloss:0.994799\n",
      "[235]\ttrain-mlogloss:0.62255\teval-mlogloss:0.99454\n",
      "[236]\ttrain-mlogloss:0.621489\teval-mlogloss:0.994461\n",
      "[237]\ttrain-mlogloss:0.620452\teval-mlogloss:0.994112\n",
      "[238]\ttrain-mlogloss:0.619307\teval-mlogloss:0.993747\n",
      "[239]\ttrain-mlogloss:0.618129\teval-mlogloss:0.993412\n",
      "[240]\ttrain-mlogloss:0.616995\teval-mlogloss:0.993138\n",
      "[241]\ttrain-mlogloss:0.61608\teval-mlogloss:0.992832\n",
      "[242]\ttrain-mlogloss:0.615091\teval-mlogloss:0.992682\n",
      "[243]\ttrain-mlogloss:0.613924\teval-mlogloss:0.992377\n",
      "[244]\ttrain-mlogloss:0.612888\teval-mlogloss:0.992077\n",
      "[245]\ttrain-mlogloss:0.611933\teval-mlogloss:0.991776\n",
      "[246]\ttrain-mlogloss:0.610844\teval-mlogloss:0.99153\n",
      "[247]\ttrain-mlogloss:0.609836\teval-mlogloss:0.9913\n",
      "[248]\ttrain-mlogloss:0.608802\teval-mlogloss:0.99131\n",
      "[249]\ttrain-mlogloss:0.607809\teval-mlogloss:0.991098\n",
      "[250]\ttrain-mlogloss:0.606673\teval-mlogloss:0.990825\n",
      "[251]\ttrain-mlogloss:0.605664\teval-mlogloss:0.990627\n",
      "[252]\ttrain-mlogloss:0.604639\teval-mlogloss:0.990386\n",
      "[253]\ttrain-mlogloss:0.603527\teval-mlogloss:0.990161\n",
      "[254]\ttrain-mlogloss:0.602338\teval-mlogloss:0.989865\n",
      "[255]\ttrain-mlogloss:0.601306\teval-mlogloss:0.989643\n",
      "[256]\ttrain-mlogloss:0.600273\teval-mlogloss:0.989441\n",
      "[257]\ttrain-mlogloss:0.599371\teval-mlogloss:0.989141\n",
      "[258]\ttrain-mlogloss:0.598351\teval-mlogloss:0.988645\n",
      "[259]\ttrain-mlogloss:0.597362\teval-mlogloss:0.988486\n",
      "[260]\ttrain-mlogloss:0.596374\teval-mlogloss:0.988203\n",
      "[261]\ttrain-mlogloss:0.595507\teval-mlogloss:0.987933\n",
      "[262]\ttrain-mlogloss:0.594547\teval-mlogloss:0.987802\n",
      "[263]\ttrain-mlogloss:0.593555\teval-mlogloss:0.987372\n",
      "[264]\ttrain-mlogloss:0.592602\teval-mlogloss:0.986986\n",
      "[265]\ttrain-mlogloss:0.591784\teval-mlogloss:0.986651\n",
      "[266]\ttrain-mlogloss:0.590889\teval-mlogloss:0.986601\n",
      "[267]\ttrain-mlogloss:0.589918\teval-mlogloss:0.986331\n",
      "[268]\ttrain-mlogloss:0.588975\teval-mlogloss:0.985914\n",
      "[269]\ttrain-mlogloss:0.588071\teval-mlogloss:0.985694\n",
      "[270]\ttrain-mlogloss:0.587131\teval-mlogloss:0.985511\n",
      "[271]\ttrain-mlogloss:0.586244\teval-mlogloss:0.985199\n",
      "[272]\ttrain-mlogloss:0.585294\teval-mlogloss:0.985025\n",
      "[273]\ttrain-mlogloss:0.584382\teval-mlogloss:0.984922\n",
      "[274]\ttrain-mlogloss:0.583487\teval-mlogloss:0.984751\n",
      "[275]\ttrain-mlogloss:0.582509\teval-mlogloss:0.984487\n",
      "[276]\ttrain-mlogloss:0.581522\teval-mlogloss:0.98432\n",
      "[277]\ttrain-mlogloss:0.580662\teval-mlogloss:0.98417\n",
      "[278]\ttrain-mlogloss:0.579698\teval-mlogloss:0.984044\n",
      "[279]\ttrain-mlogloss:0.578693\teval-mlogloss:0.983932\n",
      "[280]\ttrain-mlogloss:0.577794\teval-mlogloss:0.983682\n",
      "[281]\ttrain-mlogloss:0.576846\teval-mlogloss:0.983622\n",
      "[282]\ttrain-mlogloss:0.576002\teval-mlogloss:0.983525\n",
      "[283]\ttrain-mlogloss:0.575116\teval-mlogloss:0.983417\n",
      "[284]\ttrain-mlogloss:0.574255\teval-mlogloss:0.983325\n",
      "[285]\ttrain-mlogloss:0.573389\teval-mlogloss:0.983245\n",
      "[286]\ttrain-mlogloss:0.572489\teval-mlogloss:0.983095\n",
      "[287]\ttrain-mlogloss:0.571566\teval-mlogloss:0.983013\n",
      "[288]\ttrain-mlogloss:0.570646\teval-mlogloss:0.982733\n",
      "[289]\ttrain-mlogloss:0.569726\teval-mlogloss:0.98292\n",
      "[290]\ttrain-mlogloss:0.568845\teval-mlogloss:0.982749\n",
      "[291]\ttrain-mlogloss:0.56793\teval-mlogloss:0.982414\n",
      "[292]\ttrain-mlogloss:0.567021\teval-mlogloss:0.982287\n",
      "[293]\ttrain-mlogloss:0.566086\teval-mlogloss:0.982174\n",
      "[294]\ttrain-mlogloss:0.565144\teval-mlogloss:0.982011\n",
      "[295]\ttrain-mlogloss:0.564256\teval-mlogloss:0.981856\n",
      "[296]\ttrain-mlogloss:0.563333\teval-mlogloss:0.981739\n",
      "[297]\ttrain-mlogloss:0.562396\teval-mlogloss:0.9814\n",
      "[298]\ttrain-mlogloss:0.56161\teval-mlogloss:0.981288\n",
      "[299]\ttrain-mlogloss:0.560772\teval-mlogloss:0.981065\n",
      "[300]\ttrain-mlogloss:0.559951\teval-mlogloss:0.981069\n",
      "[301]\ttrain-mlogloss:0.559073\teval-mlogloss:0.980917\n",
      "[302]\ttrain-mlogloss:0.558253\teval-mlogloss:0.98085\n",
      "[303]\ttrain-mlogloss:0.557379\teval-mlogloss:0.980715\n",
      "[304]\ttrain-mlogloss:0.556538\teval-mlogloss:0.980464\n",
      "[305]\ttrain-mlogloss:0.555673\teval-mlogloss:0.980218\n",
      "[306]\ttrain-mlogloss:0.554798\teval-mlogloss:0.980074\n",
      "[307]\ttrain-mlogloss:0.554025\teval-mlogloss:0.97996\n",
      "[308]\ttrain-mlogloss:0.553142\teval-mlogloss:0.979937\n",
      "[309]\ttrain-mlogloss:0.552342\teval-mlogloss:0.979726\n",
      "[310]\ttrain-mlogloss:0.551471\teval-mlogloss:0.979568\n",
      "[311]\ttrain-mlogloss:0.55059\teval-mlogloss:0.979267\n",
      "[312]\ttrain-mlogloss:0.549798\teval-mlogloss:0.979203\n",
      "[313]\ttrain-mlogloss:0.549049\teval-mlogloss:0.979048\n",
      "[314]\ttrain-mlogloss:0.548321\teval-mlogloss:0.978798\n",
      "[315]\ttrain-mlogloss:0.547512\teval-mlogloss:0.978626\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316]\ttrain-mlogloss:0.546744\teval-mlogloss:0.978411\n",
      "[317]\ttrain-mlogloss:0.545926\teval-mlogloss:0.9784\n",
      "[318]\ttrain-mlogloss:0.545024\teval-mlogloss:0.978092\n",
      "[319]\ttrain-mlogloss:0.544104\teval-mlogloss:0.978042\n",
      "[320]\ttrain-mlogloss:0.543275\teval-mlogloss:0.97784\n",
      "[321]\ttrain-mlogloss:0.542359\teval-mlogloss:0.977507\n",
      "[322]\ttrain-mlogloss:0.541586\teval-mlogloss:0.977389\n",
      "[323]\ttrain-mlogloss:0.540821\teval-mlogloss:0.977353\n",
      "[324]\ttrain-mlogloss:0.540098\teval-mlogloss:0.97729\n",
      "[325]\ttrain-mlogloss:0.539389\teval-mlogloss:0.977312\n",
      "[326]\ttrain-mlogloss:0.538595\teval-mlogloss:0.977221\n",
      "[327]\ttrain-mlogloss:0.537725\teval-mlogloss:0.977097\n",
      "[328]\ttrain-mlogloss:0.53681\teval-mlogloss:0.97685\n",
      "[329]\ttrain-mlogloss:0.536061\teval-mlogloss:0.97659\n",
      "[330]\ttrain-mlogloss:0.53525\teval-mlogloss:0.97641\n",
      "[331]\ttrain-mlogloss:0.534455\teval-mlogloss:0.97629\n",
      "[332]\ttrain-mlogloss:0.533642\teval-mlogloss:0.976181\n",
      "[333]\ttrain-mlogloss:0.532823\teval-mlogloss:0.975977\n",
      "[334]\ttrain-mlogloss:0.532\teval-mlogloss:0.9759\n",
      "[335]\ttrain-mlogloss:0.531128\teval-mlogloss:0.975665\n",
      "[336]\ttrain-mlogloss:0.530369\teval-mlogloss:0.975551\n",
      "[337]\ttrain-mlogloss:0.529694\teval-mlogloss:0.9756\n",
      "[338]\ttrain-mlogloss:0.529009\teval-mlogloss:0.975548\n",
      "[339]\ttrain-mlogloss:0.528271\teval-mlogloss:0.975472\n",
      "[340]\ttrain-mlogloss:0.527462\teval-mlogloss:0.97534\n",
      "[341]\ttrain-mlogloss:0.52671\teval-mlogloss:0.975208\n",
      "[342]\ttrain-mlogloss:0.525998\teval-mlogloss:0.974994\n",
      "[343]\ttrain-mlogloss:0.525229\teval-mlogloss:0.974771\n",
      "[344]\ttrain-mlogloss:0.524529\teval-mlogloss:0.974791\n",
      "[345]\ttrain-mlogloss:0.523804\teval-mlogloss:0.974613\n",
      "[346]\ttrain-mlogloss:0.523131\teval-mlogloss:0.97459\n",
      "[347]\ttrain-mlogloss:0.522467\teval-mlogloss:0.974359\n",
      "[348]\ttrain-mlogloss:0.521754\teval-mlogloss:0.97412\n",
      "[349]\ttrain-mlogloss:0.52099\teval-mlogloss:0.974047\n",
      "[350]\ttrain-mlogloss:0.520208\teval-mlogloss:0.973952\n",
      "[351]\ttrain-mlogloss:0.519517\teval-mlogloss:0.973835\n",
      "[352]\ttrain-mlogloss:0.518767\teval-mlogloss:0.973647\n",
      "[353]\ttrain-mlogloss:0.518087\teval-mlogloss:0.973539\n",
      "[354]\ttrain-mlogloss:0.517424\teval-mlogloss:0.973564\n",
      "[355]\ttrain-mlogloss:0.516713\teval-mlogloss:0.973529\n",
      "[356]\ttrain-mlogloss:0.516082\teval-mlogloss:0.973428\n",
      "[357]\ttrain-mlogloss:0.5154\teval-mlogloss:0.973254\n",
      "[358]\ttrain-mlogloss:0.514727\teval-mlogloss:0.973256\n",
      "[359]\ttrain-mlogloss:0.513939\teval-mlogloss:0.973326\n",
      "[360]\ttrain-mlogloss:0.513235\teval-mlogloss:0.973248\n",
      "[361]\ttrain-mlogloss:0.512402\teval-mlogloss:0.973109\n",
      "[362]\ttrain-mlogloss:0.511645\teval-mlogloss:0.972891\n",
      "[363]\ttrain-mlogloss:0.510976\teval-mlogloss:0.972891\n",
      "[364]\ttrain-mlogloss:0.51028\teval-mlogloss:0.972924\n",
      "[365]\ttrain-mlogloss:0.509607\teval-mlogloss:0.972857\n",
      "[366]\ttrain-mlogloss:0.508867\teval-mlogloss:0.972823\n",
      "[367]\ttrain-mlogloss:0.508087\teval-mlogloss:0.972959\n",
      "[368]\ttrain-mlogloss:0.507388\teval-mlogloss:0.972798\n",
      "[369]\ttrain-mlogloss:0.506729\teval-mlogloss:0.972845\n",
      "[370]\ttrain-mlogloss:0.506074\teval-mlogloss:0.972714\n",
      "[371]\ttrain-mlogloss:0.505332\teval-mlogloss:0.972516\n",
      "[372]\ttrain-mlogloss:0.504644\teval-mlogloss:0.972552\n",
      "[373]\ttrain-mlogloss:0.503929\teval-mlogloss:0.972391\n",
      "[374]\ttrain-mlogloss:0.503235\teval-mlogloss:0.972317\n",
      "[375]\ttrain-mlogloss:0.502566\teval-mlogloss:0.972057\n",
      "[376]\ttrain-mlogloss:0.501872\teval-mlogloss:0.97202\n",
      "[377]\ttrain-mlogloss:0.501155\teval-mlogloss:0.97183\n",
      "[378]\ttrain-mlogloss:0.500424\teval-mlogloss:0.971591\n",
      "[379]\ttrain-mlogloss:0.499796\teval-mlogloss:0.971557\n",
      "[380]\ttrain-mlogloss:0.499097\teval-mlogloss:0.971467\n",
      "[381]\ttrain-mlogloss:0.498367\teval-mlogloss:0.971505\n",
      "[382]\ttrain-mlogloss:0.497569\teval-mlogloss:0.971285\n",
      "[383]\ttrain-mlogloss:0.496822\teval-mlogloss:0.971129\n",
      "[384]\ttrain-mlogloss:0.496123\teval-mlogloss:0.971126\n",
      "[385]\ttrain-mlogloss:0.495427\teval-mlogloss:0.970992\n",
      "[386]\ttrain-mlogloss:0.494789\teval-mlogloss:0.971058\n",
      "[387]\ttrain-mlogloss:0.494206\teval-mlogloss:0.970983\n",
      "[388]\ttrain-mlogloss:0.493555\teval-mlogloss:0.971015\n",
      "[389]\ttrain-mlogloss:0.492979\teval-mlogloss:0.970968\n",
      "[390]\ttrain-mlogloss:0.492352\teval-mlogloss:0.97094\n",
      "[391]\ttrain-mlogloss:0.491697\teval-mlogloss:0.970916\n",
      "[392]\ttrain-mlogloss:0.491081\teval-mlogloss:0.970808\n",
      "[393]\ttrain-mlogloss:0.49043\teval-mlogloss:0.970881\n",
      "[394]\ttrain-mlogloss:0.489744\teval-mlogloss:0.97066\n",
      "[395]\ttrain-mlogloss:0.489071\teval-mlogloss:0.97057\n",
      "[396]\ttrain-mlogloss:0.488418\teval-mlogloss:0.970515\n",
      "[397]\ttrain-mlogloss:0.487785\teval-mlogloss:0.970413\n",
      "[398]\ttrain-mlogloss:0.487131\teval-mlogloss:0.970334\n",
      "[399]\ttrain-mlogloss:0.48648\teval-mlogloss:0.970377\n",
      "[400]\ttrain-mlogloss:0.485815\teval-mlogloss:0.970233\n",
      "[401]\ttrain-mlogloss:0.485173\teval-mlogloss:0.970255\n",
      "[402]\ttrain-mlogloss:0.484571\teval-mlogloss:0.970245\n",
      "[403]\ttrain-mlogloss:0.483873\teval-mlogloss:0.969973\n",
      "[404]\ttrain-mlogloss:0.483283\teval-mlogloss:0.96981\n",
      "[405]\ttrain-mlogloss:0.482573\teval-mlogloss:0.969766\n",
      "[406]\ttrain-mlogloss:0.481892\teval-mlogloss:0.969598\n",
      "[407]\ttrain-mlogloss:0.481242\teval-mlogloss:0.969535\n",
      "[408]\ttrain-mlogloss:0.480622\teval-mlogloss:0.96935\n",
      "[409]\ttrain-mlogloss:0.480012\teval-mlogloss:0.969292\n",
      "[410]\ttrain-mlogloss:0.479397\teval-mlogloss:0.969121\n",
      "[411]\ttrain-mlogloss:0.478806\teval-mlogloss:0.96903\n",
      "[412]\ttrain-mlogloss:0.478237\teval-mlogloss:0.968822\n",
      "[413]\ttrain-mlogloss:0.477692\teval-mlogloss:0.968741\n",
      "[414]\ttrain-mlogloss:0.477163\teval-mlogloss:0.968649\n",
      "[415]\ttrain-mlogloss:0.476495\teval-mlogloss:0.968688\n",
      "[416]\ttrain-mlogloss:0.475849\teval-mlogloss:0.968375\n",
      "[417]\ttrain-mlogloss:0.475295\teval-mlogloss:0.968442\n",
      "[418]\ttrain-mlogloss:0.474708\teval-mlogloss:0.968292\n",
      "[419]\ttrain-mlogloss:0.474059\teval-mlogloss:0.968276\n",
      "[420]\ttrain-mlogloss:0.473426\teval-mlogloss:0.96835\n",
      "[421]\ttrain-mlogloss:0.472832\teval-mlogloss:0.968465\n",
      "[422]\ttrain-mlogloss:0.472262\teval-mlogloss:0.968591\n",
      "[423]\ttrain-mlogloss:0.471713\teval-mlogloss:0.968489\n",
      "[424]\ttrain-mlogloss:0.471125\teval-mlogloss:0.968491\n",
      "[425]\ttrain-mlogloss:0.470582\teval-mlogloss:0.968503\n",
      "[426]\ttrain-mlogloss:0.470007\teval-mlogloss:0.968437\n",
      "[427]\ttrain-mlogloss:0.469391\teval-mlogloss:0.968367\n",
      "[428]\ttrain-mlogloss:0.468799\teval-mlogloss:0.968259\n",
      "[429]\ttrain-mlogloss:0.468271\teval-mlogloss:0.968098\n",
      "[430]\ttrain-mlogloss:0.467633\teval-mlogloss:0.968122\n",
      "[431]\ttrain-mlogloss:0.467084\teval-mlogloss:0.968002\n",
      "[432]\ttrain-mlogloss:0.466461\teval-mlogloss:0.967946\n",
      "[433]\ttrain-mlogloss:0.465896\teval-mlogloss:0.967875\n",
      "[434]\ttrain-mlogloss:0.465354\teval-mlogloss:0.967707\n",
      "[435]\ttrain-mlogloss:0.46462\teval-mlogloss:0.967485\n",
      "[436]\ttrain-mlogloss:0.463934\teval-mlogloss:0.967348\n",
      "[437]\ttrain-mlogloss:0.46327\teval-mlogloss:0.967249\n",
      "[438]\ttrain-mlogloss:0.462662\teval-mlogloss:0.967231\n",
      "[439]\ttrain-mlogloss:0.462049\teval-mlogloss:0.966995\n",
      "[440]\ttrain-mlogloss:0.461496\teval-mlogloss:0.966986\n",
      "[441]\ttrain-mlogloss:0.460875\teval-mlogloss:0.966967\n",
      "[442]\ttrain-mlogloss:0.460229\teval-mlogloss:0.9669\n",
      "[443]\ttrain-mlogloss:0.459604\teval-mlogloss:0.966769\n",
      "[444]\ttrain-mlogloss:0.458961\teval-mlogloss:0.966814\n",
      "[445]\ttrain-mlogloss:0.458353\teval-mlogloss:0.966553\n",
      "[446]\ttrain-mlogloss:0.457813\teval-mlogloss:0.96641\n",
      "[447]\ttrain-mlogloss:0.457123\teval-mlogloss:0.966186\n",
      "[448]\ttrain-mlogloss:0.456513\teval-mlogloss:0.966132\n",
      "[449]\ttrain-mlogloss:0.455979\teval-mlogloss:0.966076\n",
      "[450]\ttrain-mlogloss:0.455442\teval-mlogloss:0.966086\n",
      "[451]\ttrain-mlogloss:0.454901\teval-mlogloss:0.966102\n",
      "[452]\ttrain-mlogloss:0.454364\teval-mlogloss:0.966103\n",
      "[453]\ttrain-mlogloss:0.453809\teval-mlogloss:0.966\n",
      "[454]\ttrain-mlogloss:0.453203\teval-mlogloss:0.965974\n",
      "[455]\ttrain-mlogloss:0.452619\teval-mlogloss:0.965961\n",
      "[456]\ttrain-mlogloss:0.452029\teval-mlogloss:0.966064\n",
      "[457]\ttrain-mlogloss:0.451527\teval-mlogloss:0.96592\n",
      "[458]\ttrain-mlogloss:0.450967\teval-mlogloss:0.965928\n",
      "[459]\ttrain-mlogloss:0.450451\teval-mlogloss:0.965876\n",
      "[460]\ttrain-mlogloss:0.449882\teval-mlogloss:0.965786\n",
      "[461]\ttrain-mlogloss:0.449311\teval-mlogloss:0.965858\n",
      "[462]\ttrain-mlogloss:0.448802\teval-mlogloss:0.965872\n",
      "[463]\ttrain-mlogloss:0.448302\teval-mlogloss:0.965815\n",
      "[464]\ttrain-mlogloss:0.447763\teval-mlogloss:0.965826\n",
      "[465]\ttrain-mlogloss:0.447236\teval-mlogloss:0.965732\n",
      "[466]\ttrain-mlogloss:0.446719\teval-mlogloss:0.965672\n",
      "[467]\ttrain-mlogloss:0.446157\teval-mlogloss:0.965651\n",
      "[468]\ttrain-mlogloss:0.445588\teval-mlogloss:0.965602\n",
      "[469]\ttrain-mlogloss:0.44497\teval-mlogloss:0.965561\n",
      "[470]\ttrain-mlogloss:0.444364\teval-mlogloss:0.965518\n",
      "[471]\ttrain-mlogloss:0.443814\teval-mlogloss:0.96548\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[472]\ttrain-mlogloss:0.443312\teval-mlogloss:0.965553\n",
      "[473]\ttrain-mlogloss:0.442726\teval-mlogloss:0.965726\n",
      "[474]\ttrain-mlogloss:0.44223\teval-mlogloss:0.96577\n",
      "[475]\ttrain-mlogloss:0.441622\teval-mlogloss:0.965784\n",
      "[476]\ttrain-mlogloss:0.441104\teval-mlogloss:0.965815\n",
      "[477]\ttrain-mlogloss:0.44047\teval-mlogloss:0.965792\n",
      "[478]\ttrain-mlogloss:0.439805\teval-mlogloss:0.96562\n",
      "[479]\ttrain-mlogloss:0.439234\teval-mlogloss:0.965539\n",
      "[480]\ttrain-mlogloss:0.438567\teval-mlogloss:0.965515\n",
      "[481]\ttrain-mlogloss:0.437979\teval-mlogloss:0.965495\n",
      "Stopping. Best iteration:\n",
      "[471]\ttrain-mlogloss:0.443814\teval-mlogloss:0.96548\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if xgboost:\n",
    "    dtrain = xgb.DMatrix(csr_train, label=train_y, feature_names = train_X.columns)\n",
    "    dtest = xgb.DMatrix(csr_test, label=test_y, feature_names = train_X.columns)\n",
    "    num_boost_round = 500\n",
    "    params = {'objective': 'multi:softprob', \n",
    "              'eval_metric': 'mlogloss',\n",
    "              'num_class':38,\n",
    "              'max_depth':3,\n",
    "              'eta': 0.25}\n",
    "\n",
    "    evals = [(dtrain, 'train'), (dtest, 'eval')]\n",
    "\n",
    "    bst_2 = xgb.train(params=params,  \n",
    "                    dtrain=dtrain, \n",
    "                    num_boost_round=num_boost_round, \n",
    "                    evals=evals,\n",
    "                    early_stopping_rounds=10,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feature 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "vn_fl_3 = vn_fl_one + vn_fl_more_than_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat 완료.\n"
     ]
    }
   ],
   "source": [
    "df_to_test = get_df_has_specified_vn_list(vn_fl_3, is_in=False, df_dd = df_train_dd, df_fl = df_train_fl, is_need_to_make_df = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_3, y_3 = af.get_df_to_fit(df_to_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_enc = LabelEncoder().fit(y_3)\n",
    "y_labeled = label_enc.transform(y_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X, train_y, test_y = train_test_split(X_3, y_labeled, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "csr_train = csr_matrix(train_X.values)\n",
    "csr_test = csr_matrix(test_X.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mlogloss:2.45352\teval-mlogloss:2.463\n",
      "Multiple eval metrics have been passed: 'eval-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until eval-mlogloss hasn't improved in 10 rounds.\n",
      "[1]\ttrain-mlogloss:2.20739\teval-mlogloss:2.22532\n",
      "[2]\ttrain-mlogloss:2.03683\teval-mlogloss:2.06199\n",
      "[3]\ttrain-mlogloss:1.90914\teval-mlogloss:1.94012\n",
      "[4]\ttrain-mlogloss:1.8097\teval-mlogloss:1.84626\n",
      "[5]\ttrain-mlogloss:1.7268\teval-mlogloss:1.76735\n",
      "[6]\ttrain-mlogloss:1.65856\teval-mlogloss:1.70286\n",
      "[7]\ttrain-mlogloss:1.60111\teval-mlogloss:1.64874\n",
      "[8]\ttrain-mlogloss:1.55113\teval-mlogloss:1.60206\n",
      "[9]\ttrain-mlogloss:1.50773\teval-mlogloss:1.56201\n",
      "[10]\ttrain-mlogloss:1.46929\teval-mlogloss:1.52746\n",
      "[11]\ttrain-mlogloss:1.43496\teval-mlogloss:1.49665\n",
      "[12]\ttrain-mlogloss:1.40467\teval-mlogloss:1.46952\n",
      "[13]\ttrain-mlogloss:1.37719\teval-mlogloss:1.44449\n",
      "[14]\ttrain-mlogloss:1.35302\teval-mlogloss:1.42287\n",
      "[15]\ttrain-mlogloss:1.33069\teval-mlogloss:1.40363\n",
      "[16]\ttrain-mlogloss:1.31038\teval-mlogloss:1.38645\n",
      "[17]\ttrain-mlogloss:1.29191\teval-mlogloss:1.37067\n",
      "[18]\ttrain-mlogloss:1.2738\teval-mlogloss:1.35529\n",
      "[19]\ttrain-mlogloss:1.25787\teval-mlogloss:1.34265\n",
      "[20]\ttrain-mlogloss:1.24252\teval-mlogloss:1.33028\n",
      "[21]\ttrain-mlogloss:1.22863\teval-mlogloss:1.31888\n",
      "[22]\ttrain-mlogloss:1.2154\teval-mlogloss:1.30848\n",
      "[23]\ttrain-mlogloss:1.203\teval-mlogloss:1.29843\n",
      "[24]\ttrain-mlogloss:1.19119\teval-mlogloss:1.28972\n",
      "[25]\ttrain-mlogloss:1.18002\teval-mlogloss:1.28134\n",
      "[26]\ttrain-mlogloss:1.17\teval-mlogloss:1.27372\n",
      "[27]\ttrain-mlogloss:1.16031\teval-mlogloss:1.26671\n",
      "[28]\ttrain-mlogloss:1.15059\teval-mlogloss:1.25962\n",
      "[29]\ttrain-mlogloss:1.14147\teval-mlogloss:1.25308\n",
      "[30]\ttrain-mlogloss:1.13275\teval-mlogloss:1.24711\n",
      "[31]\ttrain-mlogloss:1.1243\teval-mlogloss:1.24137\n",
      "[32]\ttrain-mlogloss:1.11594\teval-mlogloss:1.23519\n",
      "[33]\ttrain-mlogloss:1.10822\teval-mlogloss:1.23016\n",
      "[34]\ttrain-mlogloss:1.10079\teval-mlogloss:1.22465\n",
      "[35]\ttrain-mlogloss:1.09381\teval-mlogloss:1.21983\n",
      "[36]\ttrain-mlogloss:1.08673\teval-mlogloss:1.2154\n",
      "[37]\ttrain-mlogloss:1.07996\teval-mlogloss:1.2109\n",
      "[38]\ttrain-mlogloss:1.07334\teval-mlogloss:1.20663\n",
      "[39]\ttrain-mlogloss:1.06674\teval-mlogloss:1.20185\n",
      "[40]\ttrain-mlogloss:1.06076\teval-mlogloss:1.19769\n",
      "[41]\ttrain-mlogloss:1.05464\teval-mlogloss:1.19366\n",
      "[42]\ttrain-mlogloss:1.04846\teval-mlogloss:1.18987\n",
      "[43]\ttrain-mlogloss:1.04277\teval-mlogloss:1.1862\n",
      "[44]\ttrain-mlogloss:1.03703\teval-mlogloss:1.18302\n",
      "[45]\ttrain-mlogloss:1.03189\teval-mlogloss:1.17969\n",
      "[46]\ttrain-mlogloss:1.02639\teval-mlogloss:1.17633\n",
      "[47]\ttrain-mlogloss:1.02101\teval-mlogloss:1.17336\n",
      "[48]\ttrain-mlogloss:1.01581\teval-mlogloss:1.17017\n",
      "[49]\ttrain-mlogloss:1.01045\teval-mlogloss:1.16729\n",
      "[50]\ttrain-mlogloss:1.00523\teval-mlogloss:1.164\n",
      "[51]\ttrain-mlogloss:1.00032\teval-mlogloss:1.16086\n",
      "[52]\ttrain-mlogloss:0.995859\teval-mlogloss:1.15757\n",
      "[53]\ttrain-mlogloss:0.991284\teval-mlogloss:1.1545\n",
      "[54]\ttrain-mlogloss:0.986682\teval-mlogloss:1.15191\n",
      "[55]\ttrain-mlogloss:0.981904\teval-mlogloss:1.14919\n",
      "[56]\ttrain-mlogloss:0.977453\teval-mlogloss:1.1462\n",
      "[57]\ttrain-mlogloss:0.973246\teval-mlogloss:1.14397\n",
      "[58]\ttrain-mlogloss:0.968806\teval-mlogloss:1.14095\n",
      "[59]\ttrain-mlogloss:0.964619\teval-mlogloss:1.13868\n",
      "[60]\ttrain-mlogloss:0.960341\teval-mlogloss:1.13623\n",
      "[61]\ttrain-mlogloss:0.956289\teval-mlogloss:1.13388\n",
      "[62]\ttrain-mlogloss:0.952517\teval-mlogloss:1.13177\n",
      "[63]\ttrain-mlogloss:0.948735\teval-mlogloss:1.12971\n",
      "[64]\ttrain-mlogloss:0.944625\teval-mlogloss:1.12731\n",
      "[65]\ttrain-mlogloss:0.94098\teval-mlogloss:1.1253\n",
      "[66]\ttrain-mlogloss:0.937036\teval-mlogloss:1.12319\n",
      "[67]\ttrain-mlogloss:0.933686\teval-mlogloss:1.12132\n",
      "[68]\ttrain-mlogloss:0.930133\teval-mlogloss:1.11916\n",
      "[69]\ttrain-mlogloss:0.926397\teval-mlogloss:1.11677\n",
      "[70]\ttrain-mlogloss:0.92283\teval-mlogloss:1.11507\n",
      "[71]\ttrain-mlogloss:0.919304\teval-mlogloss:1.11332\n",
      "[72]\ttrain-mlogloss:0.915915\teval-mlogloss:1.11157\n",
      "[73]\ttrain-mlogloss:0.912627\teval-mlogloss:1.10963\n",
      "[74]\ttrain-mlogloss:0.909255\teval-mlogloss:1.10787\n",
      "[75]\ttrain-mlogloss:0.906137\teval-mlogloss:1.10621\n",
      "[76]\ttrain-mlogloss:0.902999\teval-mlogloss:1.10451\n",
      "[77]\ttrain-mlogloss:0.899738\teval-mlogloss:1.10268\n",
      "[78]\ttrain-mlogloss:0.896605\teval-mlogloss:1.10134\n",
      "[79]\ttrain-mlogloss:0.893393\teval-mlogloss:1.09943\n",
      "[80]\ttrain-mlogloss:0.890453\teval-mlogloss:1.098\n",
      "[81]\ttrain-mlogloss:0.887308\teval-mlogloss:1.09624\n",
      "[82]\ttrain-mlogloss:0.884329\teval-mlogloss:1.09427\n",
      "[83]\ttrain-mlogloss:0.88141\teval-mlogloss:1.09278\n",
      "[84]\ttrain-mlogloss:0.878779\teval-mlogloss:1.09138\n",
      "[85]\ttrain-mlogloss:0.876117\teval-mlogloss:1.09015\n",
      "[86]\ttrain-mlogloss:0.873365\teval-mlogloss:1.08873\n",
      "[87]\ttrain-mlogloss:0.870446\teval-mlogloss:1.08757\n",
      "[88]\ttrain-mlogloss:0.867719\teval-mlogloss:1.08614\n",
      "[89]\ttrain-mlogloss:0.864961\teval-mlogloss:1.08478\n",
      "[90]\ttrain-mlogloss:0.862113\teval-mlogloss:1.08329\n",
      "[91]\ttrain-mlogloss:0.85951\teval-mlogloss:1.08166\n",
      "[92]\ttrain-mlogloss:0.856819\teval-mlogloss:1.08002\n",
      "[93]\ttrain-mlogloss:0.853847\teval-mlogloss:1.07857\n",
      "[94]\ttrain-mlogloss:0.85125\teval-mlogloss:1.07713\n",
      "[95]\ttrain-mlogloss:0.848675\teval-mlogloss:1.07586\n",
      "[96]\ttrain-mlogloss:0.846217\teval-mlogloss:1.07491\n",
      "[97]\ttrain-mlogloss:0.843711\teval-mlogloss:1.07382\n",
      "[98]\ttrain-mlogloss:0.84109\teval-mlogloss:1.07212\n",
      "[99]\ttrain-mlogloss:0.83867\teval-mlogloss:1.07094\n",
      "[100]\ttrain-mlogloss:0.835983\teval-mlogloss:1.0699\n",
      "[101]\ttrain-mlogloss:0.83347\teval-mlogloss:1.06879\n",
      "[102]\ttrain-mlogloss:0.831014\teval-mlogloss:1.06758\n",
      "[103]\ttrain-mlogloss:0.828611\teval-mlogloss:1.06681\n",
      "[104]\ttrain-mlogloss:0.826251\teval-mlogloss:1.06574\n",
      "[105]\ttrain-mlogloss:0.824094\teval-mlogloss:1.06462\n",
      "[106]\ttrain-mlogloss:0.821713\teval-mlogloss:1.06364\n",
      "[107]\ttrain-mlogloss:0.819454\teval-mlogloss:1.0629\n",
      "[108]\ttrain-mlogloss:0.817081\teval-mlogloss:1.06197\n",
      "[109]\ttrain-mlogloss:0.814804\teval-mlogloss:1.06106\n",
      "[110]\ttrain-mlogloss:0.812513\teval-mlogloss:1.06011\n",
      "[111]\ttrain-mlogloss:0.810449\teval-mlogloss:1.05914\n",
      "[112]\ttrain-mlogloss:0.808282\teval-mlogloss:1.05839\n",
      "[113]\ttrain-mlogloss:0.805913\teval-mlogloss:1.05771\n",
      "[114]\ttrain-mlogloss:0.803802\teval-mlogloss:1.05671\n",
      "[115]\ttrain-mlogloss:0.80166\teval-mlogloss:1.05567\n",
      "[116]\ttrain-mlogloss:0.79952\teval-mlogloss:1.0549\n",
      "[117]\ttrain-mlogloss:0.797306\teval-mlogloss:1.05416\n",
      "[118]\ttrain-mlogloss:0.795228\teval-mlogloss:1.05317\n",
      "[119]\ttrain-mlogloss:0.79309\teval-mlogloss:1.05219\n",
      "[120]\ttrain-mlogloss:0.79118\teval-mlogloss:1.05134\n",
      "[121]\ttrain-mlogloss:0.788924\teval-mlogloss:1.05024\n",
      "[122]\ttrain-mlogloss:0.78674\teval-mlogloss:1.04956\n",
      "[123]\ttrain-mlogloss:0.784539\teval-mlogloss:1.04882\n",
      "[124]\ttrain-mlogloss:0.782524\teval-mlogloss:1.04814\n",
      "[125]\ttrain-mlogloss:0.780578\teval-mlogloss:1.04707\n",
      "[126]\ttrain-mlogloss:0.778646\teval-mlogloss:1.04645\n",
      "[127]\ttrain-mlogloss:0.776641\teval-mlogloss:1.04584\n",
      "[128]\ttrain-mlogloss:0.774751\teval-mlogloss:1.04494\n",
      "[129]\ttrain-mlogloss:0.77291\teval-mlogloss:1.04395\n",
      "[130]\ttrain-mlogloss:0.770858\teval-mlogloss:1.04315\n",
      "[131]\ttrain-mlogloss:0.768965\teval-mlogloss:1.04224\n",
      "[132]\ttrain-mlogloss:0.76705\teval-mlogloss:1.04137\n",
      "[133]\ttrain-mlogloss:0.765176\teval-mlogloss:1.04013\n",
      "[134]\ttrain-mlogloss:0.763266\teval-mlogloss:1.03934\n",
      "[135]\ttrain-mlogloss:0.761152\teval-mlogloss:1.03855\n",
      "[136]\ttrain-mlogloss:0.759303\teval-mlogloss:1.03798\n",
      "[137]\ttrain-mlogloss:0.757551\teval-mlogloss:1.03753\n",
      "[138]\ttrain-mlogloss:0.755792\teval-mlogloss:1.03698\n",
      "[139]\ttrain-mlogloss:0.753908\teval-mlogloss:1.03634\n",
      "[140]\ttrain-mlogloss:0.752241\teval-mlogloss:1.03557\n",
      "[141]\ttrain-mlogloss:0.750435\teval-mlogloss:1.03505\n",
      "[142]\ttrain-mlogloss:0.748699\teval-mlogloss:1.03409\n",
      "[143]\ttrain-mlogloss:0.746933\teval-mlogloss:1.03351\n",
      "[144]\ttrain-mlogloss:0.745061\teval-mlogloss:1.03267\n",
      "[145]\ttrain-mlogloss:0.743243\teval-mlogloss:1.03204\n",
      "[146]\ttrain-mlogloss:0.741487\teval-mlogloss:1.03141\n",
      "[147]\ttrain-mlogloss:0.73969\teval-mlogloss:1.03063\n",
      "[148]\ttrain-mlogloss:0.738065\teval-mlogloss:1.02994\n",
      "[149]\ttrain-mlogloss:0.736449\teval-mlogloss:1.02909\n",
      "[150]\ttrain-mlogloss:0.734768\teval-mlogloss:1.02854\n",
      "[151]\ttrain-mlogloss:0.733134\teval-mlogloss:1.02815\n",
      "[152]\ttrain-mlogloss:0.731439\teval-mlogloss:1.02753\n",
      "[153]\ttrain-mlogloss:0.729745\teval-mlogloss:1.02685\n",
      "[154]\ttrain-mlogloss:0.728137\teval-mlogloss:1.02647\n",
      "[155]\ttrain-mlogloss:0.726564\teval-mlogloss:1.02561\n",
      "[156]\ttrain-mlogloss:0.724902\teval-mlogloss:1.02504\n",
      "[157]\ttrain-mlogloss:0.723178\teval-mlogloss:1.02424\n",
      "[158]\ttrain-mlogloss:0.721649\teval-mlogloss:1.02358\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[159]\ttrain-mlogloss:0.720036\teval-mlogloss:1.02329\n",
      "[160]\ttrain-mlogloss:0.718476\teval-mlogloss:1.02314\n",
      "[161]\ttrain-mlogloss:0.716973\teval-mlogloss:1.02233\n",
      "[162]\ttrain-mlogloss:0.715489\teval-mlogloss:1.02192\n",
      "[163]\ttrain-mlogloss:0.714032\teval-mlogloss:1.02137\n",
      "[164]\ttrain-mlogloss:0.712611\teval-mlogloss:1.02083\n",
      "[165]\ttrain-mlogloss:0.711085\teval-mlogloss:1.02029\n",
      "[166]\ttrain-mlogloss:0.709592\teval-mlogloss:1.02002\n",
      "[167]\ttrain-mlogloss:0.708009\teval-mlogloss:1.01939\n",
      "[168]\ttrain-mlogloss:0.706513\teval-mlogloss:1.01866\n",
      "[169]\ttrain-mlogloss:0.705125\teval-mlogloss:1.01844\n",
      "[170]\ttrain-mlogloss:0.703778\teval-mlogloss:1.01801\n",
      "[171]\ttrain-mlogloss:0.702231\teval-mlogloss:1.0175\n",
      "[172]\ttrain-mlogloss:0.700849\teval-mlogloss:1.01701\n",
      "[173]\ttrain-mlogloss:0.699455\teval-mlogloss:1.0167\n",
      "[174]\ttrain-mlogloss:0.698064\teval-mlogloss:1.01604\n",
      "[175]\ttrain-mlogloss:0.696649\teval-mlogloss:1.01545\n",
      "[176]\ttrain-mlogloss:0.695186\teval-mlogloss:1.01499\n",
      "[177]\ttrain-mlogloss:0.693628\teval-mlogloss:1.0144\n",
      "[178]\ttrain-mlogloss:0.692248\teval-mlogloss:1.01413\n",
      "[179]\ttrain-mlogloss:0.690778\teval-mlogloss:1.01393\n",
      "[180]\ttrain-mlogloss:0.689452\teval-mlogloss:1.0134\n",
      "[181]\ttrain-mlogloss:0.688035\teval-mlogloss:1.01303\n",
      "[182]\ttrain-mlogloss:0.686528\teval-mlogloss:1.01247\n",
      "[183]\ttrain-mlogloss:0.685064\teval-mlogloss:1.01174\n",
      "[184]\ttrain-mlogloss:0.683893\teval-mlogloss:1.01142\n",
      "[185]\ttrain-mlogloss:0.682444\teval-mlogloss:1.01092\n",
      "[186]\ttrain-mlogloss:0.681059\teval-mlogloss:1.01039\n",
      "[187]\ttrain-mlogloss:0.679787\teval-mlogloss:1.00985\n",
      "[188]\ttrain-mlogloss:0.678461\teval-mlogloss:1.00942\n",
      "[189]\ttrain-mlogloss:0.677171\teval-mlogloss:1.00901\n",
      "[190]\ttrain-mlogloss:0.675868\teval-mlogloss:1.00878\n",
      "[191]\ttrain-mlogloss:0.674605\teval-mlogloss:1.00835\n",
      "[192]\ttrain-mlogloss:0.673323\teval-mlogloss:1.00769\n",
      "[193]\ttrain-mlogloss:0.672141\teval-mlogloss:1.00745\n",
      "[194]\ttrain-mlogloss:0.670665\teval-mlogloss:1.0071\n",
      "[195]\ttrain-mlogloss:0.669314\teval-mlogloss:1.00678\n",
      "[196]\ttrain-mlogloss:0.668085\teval-mlogloss:1.00664\n",
      "[197]\ttrain-mlogloss:0.666807\teval-mlogloss:1.00634\n",
      "[198]\ttrain-mlogloss:0.665546\teval-mlogloss:1.00605\n",
      "[199]\ttrain-mlogloss:0.664175\teval-mlogloss:1.00567\n",
      "[200]\ttrain-mlogloss:0.662848\teval-mlogloss:1.00539\n",
      "[201]\ttrain-mlogloss:0.661594\teval-mlogloss:1.00531\n",
      "[202]\ttrain-mlogloss:0.660359\teval-mlogloss:1.0049\n",
      "[203]\ttrain-mlogloss:0.65922\teval-mlogloss:1.00455\n",
      "[204]\ttrain-mlogloss:0.657902\teval-mlogloss:1.00404\n",
      "[205]\ttrain-mlogloss:0.656457\teval-mlogloss:1.00363\n",
      "[206]\ttrain-mlogloss:0.655056\teval-mlogloss:1.00298\n",
      "[207]\ttrain-mlogloss:0.653903\teval-mlogloss:1.00279\n",
      "[208]\ttrain-mlogloss:0.65276\teval-mlogloss:1.00242\n",
      "[209]\ttrain-mlogloss:0.651627\teval-mlogloss:1.00182\n",
      "[210]\ttrain-mlogloss:0.650347\teval-mlogloss:1.00139\n",
      "[211]\ttrain-mlogloss:0.649135\teval-mlogloss:1.00105\n",
      "[212]\ttrain-mlogloss:0.647954\teval-mlogloss:1.00062\n",
      "[213]\ttrain-mlogloss:0.646898\teval-mlogloss:1.00057\n",
      "[214]\ttrain-mlogloss:0.645798\teval-mlogloss:1.0003\n",
      "[215]\ttrain-mlogloss:0.644768\teval-mlogloss:1.00013\n",
      "[216]\ttrain-mlogloss:0.643618\teval-mlogloss:0.999973\n",
      "[217]\ttrain-mlogloss:0.642392\teval-mlogloss:0.999629\n",
      "[218]\ttrain-mlogloss:0.641322\teval-mlogloss:0.999436\n",
      "[219]\ttrain-mlogloss:0.640157\teval-mlogloss:0.998903\n",
      "[220]\ttrain-mlogloss:0.639118\teval-mlogloss:0.998779\n",
      "[221]\ttrain-mlogloss:0.637998\teval-mlogloss:0.998553\n",
      "[222]\ttrain-mlogloss:0.636909\teval-mlogloss:0.998261\n",
      "[223]\ttrain-mlogloss:0.635779\teval-mlogloss:0.997789\n",
      "[224]\ttrain-mlogloss:0.63464\teval-mlogloss:0.997432\n",
      "[225]\ttrain-mlogloss:0.633523\teval-mlogloss:0.997254\n",
      "[226]\ttrain-mlogloss:0.632458\teval-mlogloss:0.996939\n",
      "[227]\ttrain-mlogloss:0.631423\teval-mlogloss:0.996864\n",
      "[228]\ttrain-mlogloss:0.630248\teval-mlogloss:0.996525\n",
      "[229]\ttrain-mlogloss:0.629158\teval-mlogloss:0.996252\n",
      "[230]\ttrain-mlogloss:0.627986\teval-mlogloss:0.996058\n",
      "[231]\ttrain-mlogloss:0.62682\teval-mlogloss:0.9956\n",
      "[232]\ttrain-mlogloss:0.625775\teval-mlogloss:0.995201\n",
      "[233]\ttrain-mlogloss:0.624712\teval-mlogloss:0.994959\n",
      "[234]\ttrain-mlogloss:0.623658\teval-mlogloss:0.994799\n",
      "[235]\ttrain-mlogloss:0.62255\teval-mlogloss:0.99454\n",
      "[236]\ttrain-mlogloss:0.621489\teval-mlogloss:0.994461\n",
      "[237]\ttrain-mlogloss:0.620452\teval-mlogloss:0.994112\n",
      "[238]\ttrain-mlogloss:0.619307\teval-mlogloss:0.993747\n",
      "[239]\ttrain-mlogloss:0.618129\teval-mlogloss:0.993412\n",
      "[240]\ttrain-mlogloss:0.616995\teval-mlogloss:0.993138\n",
      "[241]\ttrain-mlogloss:0.61608\teval-mlogloss:0.992832\n",
      "[242]\ttrain-mlogloss:0.615091\teval-mlogloss:0.992682\n",
      "[243]\ttrain-mlogloss:0.613924\teval-mlogloss:0.992377\n",
      "[244]\ttrain-mlogloss:0.612888\teval-mlogloss:0.992077\n",
      "[245]\ttrain-mlogloss:0.611933\teval-mlogloss:0.991776\n",
      "[246]\ttrain-mlogloss:0.610844\teval-mlogloss:0.99153\n",
      "[247]\ttrain-mlogloss:0.609836\teval-mlogloss:0.9913\n",
      "[248]\ttrain-mlogloss:0.608802\teval-mlogloss:0.99131\n",
      "[249]\ttrain-mlogloss:0.607809\teval-mlogloss:0.991098\n",
      "[250]\ttrain-mlogloss:0.606673\teval-mlogloss:0.990825\n",
      "[251]\ttrain-mlogloss:0.605664\teval-mlogloss:0.990627\n",
      "[252]\ttrain-mlogloss:0.604639\teval-mlogloss:0.990386\n",
      "[253]\ttrain-mlogloss:0.603527\teval-mlogloss:0.990161\n",
      "[254]\ttrain-mlogloss:0.602338\teval-mlogloss:0.989865\n",
      "[255]\ttrain-mlogloss:0.601306\teval-mlogloss:0.989643\n",
      "[256]\ttrain-mlogloss:0.600273\teval-mlogloss:0.989441\n",
      "[257]\ttrain-mlogloss:0.599371\teval-mlogloss:0.989141\n",
      "[258]\ttrain-mlogloss:0.598351\teval-mlogloss:0.988645\n",
      "[259]\ttrain-mlogloss:0.597362\teval-mlogloss:0.988486\n",
      "[260]\ttrain-mlogloss:0.596374\teval-mlogloss:0.988203\n",
      "[261]\ttrain-mlogloss:0.595507\teval-mlogloss:0.987933\n",
      "[262]\ttrain-mlogloss:0.594547\teval-mlogloss:0.987802\n",
      "[263]\ttrain-mlogloss:0.593555\teval-mlogloss:0.987372\n",
      "[264]\ttrain-mlogloss:0.592602\teval-mlogloss:0.986986\n",
      "[265]\ttrain-mlogloss:0.591784\teval-mlogloss:0.986651\n",
      "[266]\ttrain-mlogloss:0.590889\teval-mlogloss:0.986601\n",
      "[267]\ttrain-mlogloss:0.589918\teval-mlogloss:0.986331\n",
      "[268]\ttrain-mlogloss:0.588975\teval-mlogloss:0.985914\n",
      "[269]\ttrain-mlogloss:0.588071\teval-mlogloss:0.985694\n",
      "[270]\ttrain-mlogloss:0.587131\teval-mlogloss:0.985511\n",
      "[271]\ttrain-mlogloss:0.586244\teval-mlogloss:0.985199\n",
      "[272]\ttrain-mlogloss:0.585294\teval-mlogloss:0.985025\n",
      "[273]\ttrain-mlogloss:0.584382\teval-mlogloss:0.984922\n",
      "[274]\ttrain-mlogloss:0.583487\teval-mlogloss:0.984751\n",
      "[275]\ttrain-mlogloss:0.582509\teval-mlogloss:0.984487\n",
      "[276]\ttrain-mlogloss:0.581522\teval-mlogloss:0.98432\n",
      "[277]\ttrain-mlogloss:0.580662\teval-mlogloss:0.98417\n",
      "[278]\ttrain-mlogloss:0.579698\teval-mlogloss:0.984044\n",
      "[279]\ttrain-mlogloss:0.578693\teval-mlogloss:0.983932\n",
      "[280]\ttrain-mlogloss:0.577794\teval-mlogloss:0.983682\n",
      "[281]\ttrain-mlogloss:0.576846\teval-mlogloss:0.983622\n",
      "[282]\ttrain-mlogloss:0.576002\teval-mlogloss:0.983525\n",
      "[283]\ttrain-mlogloss:0.575116\teval-mlogloss:0.983417\n",
      "[284]\ttrain-mlogloss:0.574255\teval-mlogloss:0.983325\n",
      "[285]\ttrain-mlogloss:0.573389\teval-mlogloss:0.983245\n",
      "[286]\ttrain-mlogloss:0.572489\teval-mlogloss:0.983095\n",
      "[287]\ttrain-mlogloss:0.571566\teval-mlogloss:0.983013\n",
      "[288]\ttrain-mlogloss:0.570646\teval-mlogloss:0.982733\n",
      "[289]\ttrain-mlogloss:0.569726\teval-mlogloss:0.98292\n",
      "[290]\ttrain-mlogloss:0.568845\teval-mlogloss:0.982749\n",
      "[291]\ttrain-mlogloss:0.56793\teval-mlogloss:0.982414\n",
      "[292]\ttrain-mlogloss:0.567021\teval-mlogloss:0.982287\n",
      "[293]\ttrain-mlogloss:0.566086\teval-mlogloss:0.982174\n",
      "[294]\ttrain-mlogloss:0.565144\teval-mlogloss:0.982011\n",
      "[295]\ttrain-mlogloss:0.564256\teval-mlogloss:0.981856\n",
      "[296]\ttrain-mlogloss:0.563333\teval-mlogloss:0.981739\n",
      "[297]\ttrain-mlogloss:0.562396\teval-mlogloss:0.9814\n",
      "[298]\ttrain-mlogloss:0.56161\teval-mlogloss:0.981288\n",
      "[299]\ttrain-mlogloss:0.560772\teval-mlogloss:0.981065\n",
      "[300]\ttrain-mlogloss:0.559951\teval-mlogloss:0.981069\n",
      "[301]\ttrain-mlogloss:0.559073\teval-mlogloss:0.980917\n",
      "[302]\ttrain-mlogloss:0.558253\teval-mlogloss:0.98085\n",
      "[303]\ttrain-mlogloss:0.557379\teval-mlogloss:0.980715\n",
      "[304]\ttrain-mlogloss:0.556538\teval-mlogloss:0.980464\n",
      "[305]\ttrain-mlogloss:0.555673\teval-mlogloss:0.980218\n",
      "[306]\ttrain-mlogloss:0.554798\teval-mlogloss:0.980074\n",
      "[307]\ttrain-mlogloss:0.554025\teval-mlogloss:0.97996\n",
      "[308]\ttrain-mlogloss:0.553142\teval-mlogloss:0.979937\n",
      "[309]\ttrain-mlogloss:0.552342\teval-mlogloss:0.979726\n",
      "[310]\ttrain-mlogloss:0.551471\teval-mlogloss:0.979568\n",
      "[311]\ttrain-mlogloss:0.55059\teval-mlogloss:0.979267\n",
      "[312]\ttrain-mlogloss:0.549798\teval-mlogloss:0.979203\n",
      "[313]\ttrain-mlogloss:0.549049\teval-mlogloss:0.979048\n",
      "[314]\ttrain-mlogloss:0.548321\teval-mlogloss:0.978798\n",
      "[315]\ttrain-mlogloss:0.547512\teval-mlogloss:0.978626\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[316]\ttrain-mlogloss:0.546744\teval-mlogloss:0.978411\n",
      "[317]\ttrain-mlogloss:0.545926\teval-mlogloss:0.9784\n",
      "[318]\ttrain-mlogloss:0.545024\teval-mlogloss:0.978092\n",
      "[319]\ttrain-mlogloss:0.544104\teval-mlogloss:0.978042\n",
      "[320]\ttrain-mlogloss:0.543275\teval-mlogloss:0.97784\n",
      "[321]\ttrain-mlogloss:0.542359\teval-mlogloss:0.977507\n",
      "[322]\ttrain-mlogloss:0.541586\teval-mlogloss:0.977389\n",
      "[323]\ttrain-mlogloss:0.540821\teval-mlogloss:0.977353\n",
      "[324]\ttrain-mlogloss:0.540098\teval-mlogloss:0.97729\n",
      "[325]\ttrain-mlogloss:0.539389\teval-mlogloss:0.977312\n",
      "[326]\ttrain-mlogloss:0.538595\teval-mlogloss:0.977221\n",
      "[327]\ttrain-mlogloss:0.537725\teval-mlogloss:0.977097\n",
      "[328]\ttrain-mlogloss:0.53681\teval-mlogloss:0.97685\n",
      "[329]\ttrain-mlogloss:0.536061\teval-mlogloss:0.97659\n",
      "[330]\ttrain-mlogloss:0.53525\teval-mlogloss:0.97641\n",
      "[331]\ttrain-mlogloss:0.534455\teval-mlogloss:0.97629\n",
      "[332]\ttrain-mlogloss:0.533642\teval-mlogloss:0.976181\n",
      "[333]\ttrain-mlogloss:0.532823\teval-mlogloss:0.975977\n",
      "[334]\ttrain-mlogloss:0.532\teval-mlogloss:0.9759\n",
      "[335]\ttrain-mlogloss:0.531128\teval-mlogloss:0.975665\n",
      "[336]\ttrain-mlogloss:0.530369\teval-mlogloss:0.975551\n",
      "[337]\ttrain-mlogloss:0.529694\teval-mlogloss:0.9756\n",
      "[338]\ttrain-mlogloss:0.529009\teval-mlogloss:0.975548\n",
      "[339]\ttrain-mlogloss:0.528271\teval-mlogloss:0.975472\n",
      "[340]\ttrain-mlogloss:0.527462\teval-mlogloss:0.97534\n",
      "[341]\ttrain-mlogloss:0.52671\teval-mlogloss:0.975208\n",
      "[342]\ttrain-mlogloss:0.525998\teval-mlogloss:0.974994\n",
      "[343]\ttrain-mlogloss:0.525229\teval-mlogloss:0.974771\n",
      "[344]\ttrain-mlogloss:0.524529\teval-mlogloss:0.974791\n",
      "[345]\ttrain-mlogloss:0.523804\teval-mlogloss:0.974613\n",
      "[346]\ttrain-mlogloss:0.523131\teval-mlogloss:0.97459\n",
      "[347]\ttrain-mlogloss:0.522467\teval-mlogloss:0.974359\n",
      "[348]\ttrain-mlogloss:0.521754\teval-mlogloss:0.97412\n",
      "[349]\ttrain-mlogloss:0.52099\teval-mlogloss:0.974047\n",
      "[350]\ttrain-mlogloss:0.520208\teval-mlogloss:0.973952\n",
      "[351]\ttrain-mlogloss:0.519517\teval-mlogloss:0.973835\n",
      "[352]\ttrain-mlogloss:0.518767\teval-mlogloss:0.973647\n",
      "[353]\ttrain-mlogloss:0.518087\teval-mlogloss:0.973539\n",
      "[354]\ttrain-mlogloss:0.517424\teval-mlogloss:0.973564\n",
      "[355]\ttrain-mlogloss:0.516713\teval-mlogloss:0.973529\n",
      "[356]\ttrain-mlogloss:0.516082\teval-mlogloss:0.973428\n",
      "[357]\ttrain-mlogloss:0.5154\teval-mlogloss:0.973254\n",
      "[358]\ttrain-mlogloss:0.514727\teval-mlogloss:0.973256\n",
      "[359]\ttrain-mlogloss:0.513939\teval-mlogloss:0.973326\n",
      "[360]\ttrain-mlogloss:0.513235\teval-mlogloss:0.973248\n",
      "[361]\ttrain-mlogloss:0.512402\teval-mlogloss:0.973109\n",
      "[362]\ttrain-mlogloss:0.511645\teval-mlogloss:0.972891\n",
      "[363]\ttrain-mlogloss:0.510976\teval-mlogloss:0.972891\n",
      "[364]\ttrain-mlogloss:0.51028\teval-mlogloss:0.972924\n",
      "[365]\ttrain-mlogloss:0.509607\teval-mlogloss:0.972857\n",
      "[366]\ttrain-mlogloss:0.508867\teval-mlogloss:0.972823\n",
      "[367]\ttrain-mlogloss:0.508087\teval-mlogloss:0.972959\n",
      "[368]\ttrain-mlogloss:0.507388\teval-mlogloss:0.972798\n",
      "[369]\ttrain-mlogloss:0.506729\teval-mlogloss:0.972845\n",
      "[370]\ttrain-mlogloss:0.506074\teval-mlogloss:0.972714\n",
      "[371]\ttrain-mlogloss:0.505332\teval-mlogloss:0.972516\n",
      "[372]\ttrain-mlogloss:0.504644\teval-mlogloss:0.972552\n",
      "[373]\ttrain-mlogloss:0.503929\teval-mlogloss:0.972391\n",
      "[374]\ttrain-mlogloss:0.503235\teval-mlogloss:0.972317\n",
      "[375]\ttrain-mlogloss:0.502566\teval-mlogloss:0.972057\n",
      "[376]\ttrain-mlogloss:0.501872\teval-mlogloss:0.97202\n",
      "[377]\ttrain-mlogloss:0.501155\teval-mlogloss:0.97183\n",
      "[378]\ttrain-mlogloss:0.500424\teval-mlogloss:0.971591\n",
      "[379]\ttrain-mlogloss:0.499796\teval-mlogloss:0.971557\n",
      "[380]\ttrain-mlogloss:0.499097\teval-mlogloss:0.971467\n",
      "[381]\ttrain-mlogloss:0.498367\teval-mlogloss:0.971505\n",
      "[382]\ttrain-mlogloss:0.497569\teval-mlogloss:0.971285\n",
      "[383]\ttrain-mlogloss:0.496822\teval-mlogloss:0.971129\n",
      "[384]\ttrain-mlogloss:0.496123\teval-mlogloss:0.971126\n",
      "[385]\ttrain-mlogloss:0.495427\teval-mlogloss:0.970992\n",
      "[386]\ttrain-mlogloss:0.494789\teval-mlogloss:0.971058\n",
      "[387]\ttrain-mlogloss:0.494206\teval-mlogloss:0.970983\n",
      "[388]\ttrain-mlogloss:0.493555\teval-mlogloss:0.971015\n",
      "[389]\ttrain-mlogloss:0.492979\teval-mlogloss:0.970968\n",
      "[390]\ttrain-mlogloss:0.492352\teval-mlogloss:0.97094\n",
      "[391]\ttrain-mlogloss:0.491697\teval-mlogloss:0.970916\n",
      "[392]\ttrain-mlogloss:0.491081\teval-mlogloss:0.970808\n",
      "[393]\ttrain-mlogloss:0.49043\teval-mlogloss:0.970881\n",
      "[394]\ttrain-mlogloss:0.489744\teval-mlogloss:0.97066\n",
      "[395]\ttrain-mlogloss:0.489071\teval-mlogloss:0.97057\n",
      "[396]\ttrain-mlogloss:0.488418\teval-mlogloss:0.970515\n",
      "[397]\ttrain-mlogloss:0.487785\teval-mlogloss:0.970413\n",
      "[398]\ttrain-mlogloss:0.487131\teval-mlogloss:0.970334\n",
      "[399]\ttrain-mlogloss:0.48648\teval-mlogloss:0.970377\n",
      "[400]\ttrain-mlogloss:0.485815\teval-mlogloss:0.970233\n",
      "[401]\ttrain-mlogloss:0.485173\teval-mlogloss:0.970255\n",
      "[402]\ttrain-mlogloss:0.484571\teval-mlogloss:0.970245\n",
      "[403]\ttrain-mlogloss:0.483873\teval-mlogloss:0.969973\n",
      "[404]\ttrain-mlogloss:0.483283\teval-mlogloss:0.96981\n",
      "[405]\ttrain-mlogloss:0.482573\teval-mlogloss:0.969766\n",
      "[406]\ttrain-mlogloss:0.481892\teval-mlogloss:0.969598\n",
      "[407]\ttrain-mlogloss:0.481242\teval-mlogloss:0.969535\n",
      "[408]\ttrain-mlogloss:0.480622\teval-mlogloss:0.96935\n",
      "[409]\ttrain-mlogloss:0.480012\teval-mlogloss:0.969292\n",
      "[410]\ttrain-mlogloss:0.479397\teval-mlogloss:0.969121\n",
      "[411]\ttrain-mlogloss:0.478806\teval-mlogloss:0.96903\n",
      "[412]\ttrain-mlogloss:0.478237\teval-mlogloss:0.968822\n",
      "[413]\ttrain-mlogloss:0.477692\teval-mlogloss:0.968741\n",
      "[414]\ttrain-mlogloss:0.477163\teval-mlogloss:0.968649\n",
      "[415]\ttrain-mlogloss:0.476495\teval-mlogloss:0.968688\n",
      "[416]\ttrain-mlogloss:0.475849\teval-mlogloss:0.968375\n",
      "[417]\ttrain-mlogloss:0.475295\teval-mlogloss:0.968442\n",
      "[418]\ttrain-mlogloss:0.474708\teval-mlogloss:0.968292\n",
      "[419]\ttrain-mlogloss:0.474059\teval-mlogloss:0.968276\n",
      "[420]\ttrain-mlogloss:0.473426\teval-mlogloss:0.96835\n",
      "[421]\ttrain-mlogloss:0.472832\teval-mlogloss:0.968465\n",
      "[422]\ttrain-mlogloss:0.472262\teval-mlogloss:0.968591\n",
      "[423]\ttrain-mlogloss:0.471713\teval-mlogloss:0.968489\n",
      "[424]\ttrain-mlogloss:0.471125\teval-mlogloss:0.968491\n",
      "[425]\ttrain-mlogloss:0.470582\teval-mlogloss:0.968503\n",
      "[426]\ttrain-mlogloss:0.470007\teval-mlogloss:0.968437\n",
      "[427]\ttrain-mlogloss:0.469391\teval-mlogloss:0.968367\n",
      "[428]\ttrain-mlogloss:0.468799\teval-mlogloss:0.968259\n",
      "[429]\ttrain-mlogloss:0.468271\teval-mlogloss:0.968098\n",
      "[430]\ttrain-mlogloss:0.467633\teval-mlogloss:0.968122\n",
      "[431]\ttrain-mlogloss:0.467084\teval-mlogloss:0.968002\n",
      "[432]\ttrain-mlogloss:0.466461\teval-mlogloss:0.967946\n",
      "[433]\ttrain-mlogloss:0.465896\teval-mlogloss:0.967875\n",
      "[434]\ttrain-mlogloss:0.465354\teval-mlogloss:0.967707\n",
      "[435]\ttrain-mlogloss:0.46462\teval-mlogloss:0.967485\n",
      "[436]\ttrain-mlogloss:0.463934\teval-mlogloss:0.967348\n",
      "[437]\ttrain-mlogloss:0.46327\teval-mlogloss:0.967249\n",
      "[438]\ttrain-mlogloss:0.462662\teval-mlogloss:0.967231\n",
      "[439]\ttrain-mlogloss:0.462049\teval-mlogloss:0.966995\n",
      "[440]\ttrain-mlogloss:0.461496\teval-mlogloss:0.966986\n",
      "[441]\ttrain-mlogloss:0.460875\teval-mlogloss:0.966967\n",
      "[442]\ttrain-mlogloss:0.460229\teval-mlogloss:0.9669\n",
      "[443]\ttrain-mlogloss:0.459604\teval-mlogloss:0.966769\n",
      "[444]\ttrain-mlogloss:0.458961\teval-mlogloss:0.966814\n",
      "[445]\ttrain-mlogloss:0.458353\teval-mlogloss:0.966553\n",
      "[446]\ttrain-mlogloss:0.457813\teval-mlogloss:0.96641\n",
      "[447]\ttrain-mlogloss:0.457123\teval-mlogloss:0.966186\n",
      "[448]\ttrain-mlogloss:0.456513\teval-mlogloss:0.966132\n",
      "[449]\ttrain-mlogloss:0.455979\teval-mlogloss:0.966076\n",
      "[450]\ttrain-mlogloss:0.455442\teval-mlogloss:0.966086\n",
      "[451]\ttrain-mlogloss:0.454901\teval-mlogloss:0.966102\n",
      "[452]\ttrain-mlogloss:0.454364\teval-mlogloss:0.966103\n",
      "[453]\ttrain-mlogloss:0.453809\teval-mlogloss:0.966\n",
      "[454]\ttrain-mlogloss:0.453203\teval-mlogloss:0.965974\n",
      "[455]\ttrain-mlogloss:0.452619\teval-mlogloss:0.965961\n",
      "[456]\ttrain-mlogloss:0.452029\teval-mlogloss:0.966064\n",
      "[457]\ttrain-mlogloss:0.451527\teval-mlogloss:0.96592\n",
      "[458]\ttrain-mlogloss:0.450967\teval-mlogloss:0.965928\n",
      "[459]\ttrain-mlogloss:0.450451\teval-mlogloss:0.965876\n",
      "[460]\ttrain-mlogloss:0.449882\teval-mlogloss:0.965786\n",
      "[461]\ttrain-mlogloss:0.449311\teval-mlogloss:0.965858\n",
      "[462]\ttrain-mlogloss:0.448802\teval-mlogloss:0.965872\n",
      "[463]\ttrain-mlogloss:0.448302\teval-mlogloss:0.965815\n",
      "[464]\ttrain-mlogloss:0.447763\teval-mlogloss:0.965826\n",
      "[465]\ttrain-mlogloss:0.447236\teval-mlogloss:0.965732\n",
      "[466]\ttrain-mlogloss:0.446719\teval-mlogloss:0.965672\n",
      "[467]\ttrain-mlogloss:0.446157\teval-mlogloss:0.965651\n",
      "[468]\ttrain-mlogloss:0.445588\teval-mlogloss:0.965602\n",
      "[469]\ttrain-mlogloss:0.44497\teval-mlogloss:0.965561\n",
      "[470]\ttrain-mlogloss:0.444364\teval-mlogloss:0.965518\n",
      "[471]\ttrain-mlogloss:0.443814\teval-mlogloss:0.96548\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[472]\ttrain-mlogloss:0.443312\teval-mlogloss:0.965553\n",
      "[473]\ttrain-mlogloss:0.442726\teval-mlogloss:0.965726\n",
      "[474]\ttrain-mlogloss:0.44223\teval-mlogloss:0.96577\n",
      "[475]\ttrain-mlogloss:0.441622\teval-mlogloss:0.965784\n",
      "[476]\ttrain-mlogloss:0.441104\teval-mlogloss:0.965815\n",
      "[477]\ttrain-mlogloss:0.44047\teval-mlogloss:0.965792\n",
      "[478]\ttrain-mlogloss:0.439805\teval-mlogloss:0.96562\n",
      "[479]\ttrain-mlogloss:0.439234\teval-mlogloss:0.965539\n",
      "[480]\ttrain-mlogloss:0.438567\teval-mlogloss:0.965515\n",
      "[481]\ttrain-mlogloss:0.437979\teval-mlogloss:0.965495\n",
      "Stopping. Best iteration:\n",
      "[471]\ttrain-mlogloss:0.443814\teval-mlogloss:0.96548\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if xgboost:\n",
    "    dtrain = xgb.DMatrix(csr_train, label=train_y, feature_names = train_X.columns)\n",
    "    dtest = xgb.DMatrix(csr_test, label=test_y, feature_names = train_X.columns)\n",
    "    num_boost_round = 500\n",
    "    params = {'objective': 'multi:softprob', \n",
    "              'eval_metric': 'mlogloss',\n",
    "              'num_class': 38,\n",
    "              'max_depth': 3,\n",
    "              'eta': 0.25}\n",
    "\n",
    "    evals = [(dtrain, 'train'), (dtest, 'eval')]\n",
    "\n",
    "    bst_3 = xgb.train(params=params,  \n",
    "                    dtrain=dtrain, \n",
    "                    num_boost_round=num_boost_round, \n",
    "                    evals=evals,\n",
    "                    early_stopping_rounds=10,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8401327193447511\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8401327193447511"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cal_average_of_accuracy(vn_fl_one, vn_fl_more_than_one, [0.367298, 0.96, 0.96])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test_proba_1 = model_feature_1.predict_proba(X_1_test)\n",
    "y_pred_test_proba_2 = model_feature_2.predict_proba(X_2_test)\n",
    "y_pred_test_proba_3 = model_feature_3.predict_proba(X_3_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba_1 = model_feature_1.predict_proba(X_1)\n",
    "y_pred_proba_2 = model_feature_2.predict_proba(X_2)\n",
    "y_pred_proba_3 = model_feature_3.predict_proba(X_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_test.set_index(\"VisitNumber\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_proba_and_set_submission(models, features, targets, vns, submission):\n",
    "    sub = submission.copy()\n",
    "    sub.set_index(\"VisitNumber\", inplace=True)\n",
    "    for idx, model in enumerate(models):\n",
    "        y_pred = model.predict(features[idx])\n",
    "        y_proba = model.predict_proba(features[idx])\n",
    "        tt_li = []\n",
    "        vn_li = vns[idx]\n",
    "        y_pred_unique = targets[idx].unique()\n",
    "        for i in range(len(y_pred_unique)):\n",
    "            tmp = \"TripType_\" + str(sorted(y_pred_unique)[i])\n",
    "            tt_li.append(tmp)\n",
    "        sub.at[vn_li, tt_li] = y_proba\n",
    "        print(str(idx + 1) + \" feature 완료.\")\n",
    "    return sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_test.set_index(\"VisitNumber\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "vn_test_fl_dice = list(df_to_test.VisitNumber.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "vns_test = [vn_test_fl_one, vn_test_fl_more_than_one, vn_test_fl_dice]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 feature 완료.\n",
      "2 feature 완료.\n",
      "3 feature 완료.\n"
     ]
    }
   ],
   "source": [
    "sub_test = get_proba_and_set_submission(models, features, targets, vns, sub_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt_li = []\n",
    "for i in range(len(y_1_2.unique())):\n",
    "    tmp = \"TripType_\" + str(sorted(y_1_2.unique())[i])\n",
    "    tt_li.append(tmp)\n",
    "len(tt_li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = submission.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_1_test = pd.DataFrame(y_pred_test_proba_1, columns = tt_li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_1_test[\"VisitNumber\"] = vn_test_fl_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_1_test[\"TripType_14\"] = 0\n",
    "submit_1_test[\"TripType_43\"] = 0\n",
    "submit_1_test[\"TripType_44\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_1_test = submit_1_test[submit.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_1_2_test = pd.DataFrame(y_pred_test_proba_1_2, columns = tt_li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_1_2_test[\"TripType_14\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50529, 50529)"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vn_test_fl_1_2), len(submit_1_2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_1_2_test[\"VisitNumber\"] = vn_test_fl_1_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_1_2_test = submit_1_2_test[submit.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_2_3_test = pd.DataFrame(y_pred_test_proba_2_3, columns = tt_li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_2_3_test[\"VisitNumber\"] = vn_test_fl_2_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_2_3_test = submit_2_3_test[submit.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_test_all_2_3 = pd.concat([submit_1_test, submit_2_3_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_test_all_2_3 = submit_test_all_2_3.sort_values(\"VisitNumber\")\n",
    "submit_test_all_2_3.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "af.saveDataFrameToCsv(submit_test_all_2_3, \"last_try\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_test_all_1_2 = pd.concat([submit_1_2_test, submit_3_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_test_all_1_2 = submit_test_all_1_2.sort_values(\"VisitNumber\")\n",
    "submit_test_all_1_2.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "af.saveDataFrameToCsv(submit_test_all_1_2, \"get_insight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_test = get_concat_df_for_test_df(df_train_dd, df_train_fl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1-HR PHOTO</th>\n",
       "      <th>ACCESSORIES</th>\n",
       "      <th>AUTOMOTIVE</th>\n",
       "      <th>BAKERY</th>\n",
       "      <th>BATH AND SHOWER</th>\n",
       "      <th>BEAUTY</th>\n",
       "      <th>BEDDING</th>\n",
       "      <th>BOOKS AND MAGAZINES</th>\n",
       "      <th>BOYS WEAR</th>\n",
       "      <th>BRAS &amp; SHAPEWEAR</th>\n",
       "      <th>...</th>\n",
       "      <th>1627.0</th>\n",
       "      <th>-1</th>\n",
       "      <th>8191.0</th>\n",
       "      <th>Monday</th>\n",
       "      <th>Tuesday</th>\n",
       "      <th>Wednesday</th>\n",
       "      <th>Thursday</th>\n",
       "      <th>Friday</th>\n",
       "      <th>Saturday</th>\n",
       "      <th>Sunday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 5430 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    1-HR PHOTO  ACCESSORIES  AUTOMOTIVE  BAKERY  BATH AND SHOWER  BEAUTY  \\\n",
       "15           0            0           0       0                0       0   \n",
       "16           0            0           0       0                0       0   \n",
       "18           0            0           0       0                0       0   \n",
       "22           0            0           0       0                0       0   \n",
       "27           0            0           0       0                0       0   \n",
       "\n",
       "    BEDDING  BOOKS AND MAGAZINES  BOYS WEAR  BRAS & SHAPEWEAR   ...    1627.0  \\\n",
       "15        0                    0          0                 0   ...         0   \n",
       "16        0                    0          0                 0   ...         0   \n",
       "18        0                    0          0                 0   ...         0   \n",
       "22        0                    0          0                 0   ...         0   \n",
       "27        0                    0          0                 0   ...         0   \n",
       "\n",
       "    -1  8191.0  Monday  Tuesday  Wednesday  Thursday  Friday  Saturday  Sunday  \n",
       "15   0       0       0        0          0         0       1         0       0  \n",
       "16   0       0       0        0          0         0       1         0       0  \n",
       "18   0       0       0        0          0         0       1         0       0  \n",
       "22   0       0       0        0          0         0       1         0       0  \n",
       "27   0       0       0        0          0         0       1         0       0  \n",
       "\n",
       "[5 rows x 5430 columns]"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = af.get_df_to_fit(df_to_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1-HR PHOTO</th>\n",
       "      <th>ACCESSORIES</th>\n",
       "      <th>AUTOMOTIVE</th>\n",
       "      <th>BAKERY</th>\n",
       "      <th>BATH AND SHOWER</th>\n",
       "      <th>BEAUTY</th>\n",
       "      <th>BEDDING</th>\n",
       "      <th>BOOKS AND MAGAZINES</th>\n",
       "      <th>BOYS WEAR</th>\n",
       "      <th>BRAS &amp; SHAPEWEAR</th>\n",
       "      <th>...</th>\n",
       "      <th>1627.0</th>\n",
       "      <th>-1</th>\n",
       "      <th>8191.0</th>\n",
       "      <th>Monday</th>\n",
       "      <th>Tuesday</th>\n",
       "      <th>Wednesday</th>\n",
       "      <th>Thursday</th>\n",
       "      <th>Friday</th>\n",
       "      <th>Saturday</th>\n",
       "      <th>Sunday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 5430 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   1-HR PHOTO  ACCESSORIES  AUTOMOTIVE  BAKERY  BATH AND SHOWER  BEAUTY  \\\n",
       "0           0            0           0       0                0       0   \n",
       "1           0            0           0       0                0       0   \n",
       "2           0            0           0       0                0       0   \n",
       "3           0            0           0       0                0       0   \n",
       "4           0            0           0       0                0       0   \n",
       "\n",
       "   BEDDING  BOOKS AND MAGAZINES  BOYS WEAR  BRAS & SHAPEWEAR   ...    1627.0  \\\n",
       "0        0                    0          0                 0   ...         0   \n",
       "1        0                    0          0                 0   ...         0   \n",
       "2        0                    0          0                 0   ...         0   \n",
       "3        0                    0          0                 0   ...         0   \n",
       "4        0                    0          0                 0   ...         0   \n",
       "\n",
       "   -1  8191.0  Monday  Tuesday  Wednesday  Thursday  Friday  Saturday  Sunday  \n",
       "0   0       0       0        0          0         0       1         0       0  \n",
       "1   0       0       0        0          0         0       1         0       0  \n",
       "2   1       0       0        0          0         0       1         0       0  \n",
       "3   0       0       0        0          0         0       1         0       0  \n",
       "4   0       0       0        0          0         0       1         0       0  \n",
       "\n",
       "[5 rows x 5430 columns]"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_feature_1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "##### Accuracy : 0.4634"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "af.getAccuracy(y_test, y_pred, len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_2_test = pd.DataFrame(y_pred_test_proba_2, columns = tt_li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_2_test[\"VisitNumber\"] = vn_test_fl_more_than_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_2_test[\"TripType_14\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_2_test = submit_2_test[submit.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vn_test_fl_dice = list(df_to_test.VisitNumber.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45145"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vn_test_fl_dice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_3_test = pd.DataFrame(y_pred_test_proba_3, columns = tt_li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_3_test[\"VisitNumber\"] = vn_test_fl_dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_3_test = submit_3_test[submit.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_test_all = pd.concat([submit_1_test, submit_2_test, submit_3_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_test_all = submit_test_all.sort_values(\"VisitNumber\")\n",
    "submit_test_all.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VisitNumber</th>\n",
       "      <th>TripType_3</th>\n",
       "      <th>TripType_4</th>\n",
       "      <th>TripType_5</th>\n",
       "      <th>TripType_6</th>\n",
       "      <th>TripType_7</th>\n",
       "      <th>TripType_8</th>\n",
       "      <th>TripType_9</th>\n",
       "      <th>TripType_12</th>\n",
       "      <th>TripType_14</th>\n",
       "      <th>...</th>\n",
       "      <th>TripType_36</th>\n",
       "      <th>TripType_37</th>\n",
       "      <th>TripType_38</th>\n",
       "      <th>TripType_39</th>\n",
       "      <th>TripType_40</th>\n",
       "      <th>TripType_41</th>\n",
       "      <th>TripType_42</th>\n",
       "      <th>TripType_43</th>\n",
       "      <th>TripType_44</th>\n",
       "      <th>TripType_999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.106492e-50</td>\n",
       "      <td>9.653557e-54</td>\n",
       "      <td>5.636323e-16</td>\n",
       "      <td>9.078964e-24</td>\n",
       "      <td>2.812958e-04</td>\n",
       "      <td>1.979547e-02</td>\n",
       "      <td>1.340561e-15</td>\n",
       "      <td>6.397182e-43</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.127518e-16</td>\n",
       "      <td>2.911286e-13</td>\n",
       "      <td>0.968618</td>\n",
       "      <td>0.011305</td>\n",
       "      <td>4.639459e-13</td>\n",
       "      <td>7.853481e-35</td>\n",
       "      <td>2.124187e-25</td>\n",
       "      <td>6.522341e-25</td>\n",
       "      <td>2.901157e-23</td>\n",
       "      <td>2.432760e-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3.650732e-48</td>\n",
       "      <td>9.982242e-07</td>\n",
       "      <td>1.871108e-11</td>\n",
       "      <td>2.094947e-29</td>\n",
       "      <td>1.702872e-31</td>\n",
       "      <td>3.806059e-28</td>\n",
       "      <td>2.689917e-18</td>\n",
       "      <td>4.188307e-30</td>\n",
       "      <td>8.873491e-57</td>\n",
       "      <td>...</td>\n",
       "      <td>2.052912e-22</td>\n",
       "      <td>2.514577e-03</td>\n",
       "      <td>0.473402</td>\n",
       "      <td>0.143742</td>\n",
       "      <td>8.879635e-03</td>\n",
       "      <td>1.624739e-19</td>\n",
       "      <td>2.273621e-11</td>\n",
       "      <td>3.045582e-08</td>\n",
       "      <td>3.913261e-13</td>\n",
       "      <td>1.550635e-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.210754e-03</td>\n",
       "      <td>1.512679e-03</td>\n",
       "      <td>1.532167e-02</td>\n",
       "      <td>5.597487e-03</td>\n",
       "      <td>2.832801e-02</td>\n",
       "      <td>3.347708e-02</td>\n",
       "      <td>2.256775e-02</td>\n",
       "      <td>1.899446e-03</td>\n",
       "      <td>3.817823e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.203266e-02</td>\n",
       "      <td>1.146737e-02</td>\n",
       "      <td>0.018215</td>\n",
       "      <td>0.070369</td>\n",
       "      <td>1.989943e-02</td>\n",
       "      <td>3.978709e-03</td>\n",
       "      <td>1.161236e-02</td>\n",
       "      <td>7.972996e-03</td>\n",
       "      <td>6.121550e-03</td>\n",
       "      <td>5.751394e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1.785875e-04</td>\n",
       "      <td>7.326824e-05</td>\n",
       "      <td>3.609887e-05</td>\n",
       "      <td>1.085832e-04</td>\n",
       "      <td>6.762326e-05</td>\n",
       "      <td>2.699233e-05</td>\n",
       "      <td>7.892577e-01</td>\n",
       "      <td>7.691106e-08</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.774390e-05</td>\n",
       "      <td>6.892610e-06</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>2.456320e-07</td>\n",
       "      <td>9.968076e-08</td>\n",
       "      <td>4.435841e-06</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.955480e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>1.210754e-03</td>\n",
       "      <td>1.512679e-03</td>\n",
       "      <td>1.532167e-02</td>\n",
       "      <td>5.597487e-03</td>\n",
       "      <td>2.832801e-02</td>\n",
       "      <td>3.347708e-02</td>\n",
       "      <td>2.256775e-02</td>\n",
       "      <td>1.899446e-03</td>\n",
       "      <td>3.817823e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.203266e-02</td>\n",
       "      <td>1.146737e-02</td>\n",
       "      <td>0.018215</td>\n",
       "      <td>0.070369</td>\n",
       "      <td>1.989943e-02</td>\n",
       "      <td>3.978709e-03</td>\n",
       "      <td>1.161236e-02</td>\n",
       "      <td>7.972996e-03</td>\n",
       "      <td>6.121550e-03</td>\n",
       "      <td>5.751394e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   VisitNumber    TripType_3    TripType_4    TripType_5    TripType_6  \\\n",
       "0            1  1.106492e-50  9.653557e-54  5.636323e-16  9.078964e-24   \n",
       "1            2  3.650732e-48  9.982242e-07  1.871108e-11  2.094947e-29   \n",
       "2            3  1.210754e-03  1.512679e-03  1.532167e-02  5.597487e-03   \n",
       "3            4  1.785875e-04  7.326824e-05  3.609887e-05  1.085832e-04   \n",
       "4            6  1.210754e-03  1.512679e-03  1.532167e-02  5.597487e-03   \n",
       "\n",
       "     TripType_7    TripType_8    TripType_9   TripType_12   TripType_14  \\\n",
       "0  2.812958e-04  1.979547e-02  1.340561e-15  6.397182e-43  0.000000e+00   \n",
       "1  1.702872e-31  3.806059e-28  2.689917e-18  4.188307e-30  8.873491e-57   \n",
       "2  2.832801e-02  3.347708e-02  2.256775e-02  1.899446e-03  3.817823e-05   \n",
       "3  6.762326e-05  2.699233e-05  7.892577e-01  7.691106e-08  0.000000e+00   \n",
       "4  2.832801e-02  3.347708e-02  2.256775e-02  1.899446e-03  3.817823e-05   \n",
       "\n",
       "       ...        TripType_36   TripType_37  TripType_38  TripType_39  \\\n",
       "0      ...       1.127518e-16  2.911286e-13     0.968618     0.011305   \n",
       "1      ...       2.052912e-22  2.514577e-03     0.473402     0.143742   \n",
       "2      ...       2.203266e-02  1.146737e-02     0.018215     0.070369   \n",
       "3      ...       1.774390e-05  6.892610e-06     0.000006     0.000012   \n",
       "4      ...       2.203266e-02  1.146737e-02     0.018215     0.070369   \n",
       "\n",
       "    TripType_40   TripType_41   TripType_42   TripType_43   TripType_44  \\\n",
       "0  4.639459e-13  7.853481e-35  2.124187e-25  6.522341e-25  2.901157e-23   \n",
       "1  8.879635e-03  1.624739e-19  2.273621e-11  3.045582e-08  3.913261e-13   \n",
       "2  1.989943e-02  3.978709e-03  1.161236e-02  7.972996e-03  6.121550e-03   \n",
       "3  2.456320e-07  9.968076e-08  4.435841e-06  0.000000e+00  0.000000e+00   \n",
       "4  1.989943e-02  3.978709e-03  1.161236e-02  7.972996e-03  6.121550e-03   \n",
       "\n",
       "   TripType_999  \n",
       "0  2.432760e-23  \n",
       "1  1.550635e-31  \n",
       "2  5.751394e-01  \n",
       "3  1.955480e-03  \n",
       "4  5.751394e-01  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit_test_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VisitNumber</th>\n",
       "      <th>TripType_3</th>\n",
       "      <th>TripType_4</th>\n",
       "      <th>TripType_5</th>\n",
       "      <th>TripType_6</th>\n",
       "      <th>TripType_7</th>\n",
       "      <th>TripType_8</th>\n",
       "      <th>TripType_9</th>\n",
       "      <th>TripType_12</th>\n",
       "      <th>TripType_14</th>\n",
       "      <th>...</th>\n",
       "      <th>TripType_36</th>\n",
       "      <th>TripType_37</th>\n",
       "      <th>TripType_38</th>\n",
       "      <th>TripType_39</th>\n",
       "      <th>TripType_40</th>\n",
       "      <th>TripType_41</th>\n",
       "      <th>TripType_42</th>\n",
       "      <th>TripType_43</th>\n",
       "      <th>TripType_44</th>\n",
       "      <th>TripType_999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3.175828e-44</td>\n",
       "      <td>1.002715e-40</td>\n",
       "      <td>2.166095e-13</td>\n",
       "      <td>4.179372e-22</td>\n",
       "      <td>6.724353e-03</td>\n",
       "      <td>1.363274e-01</td>\n",
       "      <td>2.948011e-13</td>\n",
       "      <td>1.035182e-41</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.666031e-13</td>\n",
       "      <td>2.328031e-12</td>\n",
       "      <td>0.826118</td>\n",
       "      <td>0.030830</td>\n",
       "      <td>1.237613e-12</td>\n",
       "      <td>7.923613e-33</td>\n",
       "      <td>1.815581e-23</td>\n",
       "      <td>3.778327e-23</td>\n",
       "      <td>2.590057e-22</td>\n",
       "      <td>5.927163e-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>9.340914e-37</td>\n",
       "      <td>6.497091e-08</td>\n",
       "      <td>1.836845e-11</td>\n",
       "      <td>4.432472e-30</td>\n",
       "      <td>5.931267e-32</td>\n",
       "      <td>8.130657e-30</td>\n",
       "      <td>1.061700e-18</td>\n",
       "      <td>1.666864e-30</td>\n",
       "      <td>1.255418e-36</td>\n",
       "      <td>...</td>\n",
       "      <td>2.480656e-22</td>\n",
       "      <td>3.706382e-03</td>\n",
       "      <td>0.202063</td>\n",
       "      <td>0.026589</td>\n",
       "      <td>9.295111e-03</td>\n",
       "      <td>6.476055e-20</td>\n",
       "      <td>2.154178e-11</td>\n",
       "      <td>5.776768e-09</td>\n",
       "      <td>3.698196e-13</td>\n",
       "      <td>2.854383e-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.477099e-03</td>\n",
       "      <td>1.905515e-03</td>\n",
       "      <td>1.947489e-02</td>\n",
       "      <td>7.086649e-03</td>\n",
       "      <td>3.607914e-02</td>\n",
       "      <td>3.982477e-02</td>\n",
       "      <td>2.684251e-02</td>\n",
       "      <td>2.461405e-03</td>\n",
       "      <td>5.035697e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.841871e-02</td>\n",
       "      <td>1.510282e-02</td>\n",
       "      <td>0.023757</td>\n",
       "      <td>0.091342</td>\n",
       "      <td>2.647738e-02</td>\n",
       "      <td>5.176118e-03</td>\n",
       "      <td>1.514823e-02</td>\n",
       "      <td>1.023443e-02</td>\n",
       "      <td>8.074890e-03</td>\n",
       "      <td>4.568377e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1.785875e-04</td>\n",
       "      <td>7.326824e-05</td>\n",
       "      <td>3.609887e-05</td>\n",
       "      <td>1.085832e-04</td>\n",
       "      <td>6.762326e-05</td>\n",
       "      <td>2.699233e-05</td>\n",
       "      <td>7.892577e-01</td>\n",
       "      <td>7.691106e-08</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.774390e-05</td>\n",
       "      <td>6.892610e-06</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>2.456320e-07</td>\n",
       "      <td>9.968076e-08</td>\n",
       "      <td>4.435841e-06</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.955480e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>1.477099e-03</td>\n",
       "      <td>1.905515e-03</td>\n",
       "      <td>1.947489e-02</td>\n",
       "      <td>7.086649e-03</td>\n",
       "      <td>3.607914e-02</td>\n",
       "      <td>3.982477e-02</td>\n",
       "      <td>2.684251e-02</td>\n",
       "      <td>2.461405e-03</td>\n",
       "      <td>5.035697e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.841871e-02</td>\n",
       "      <td>1.510282e-02</td>\n",
       "      <td>0.023757</td>\n",
       "      <td>0.091342</td>\n",
       "      <td>2.647738e-02</td>\n",
       "      <td>5.176118e-03</td>\n",
       "      <td>1.514823e-02</td>\n",
       "      <td>1.023443e-02</td>\n",
       "      <td>8.074890e-03</td>\n",
       "      <td>4.568377e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   VisitNumber    TripType_3    TripType_4    TripType_5    TripType_6  \\\n",
       "0            1  3.175828e-44  1.002715e-40  2.166095e-13  4.179372e-22   \n",
       "1            2  9.340914e-37  6.497091e-08  1.836845e-11  4.432472e-30   \n",
       "2            3  1.477099e-03  1.905515e-03  1.947489e-02  7.086649e-03   \n",
       "3            4  1.785875e-04  7.326824e-05  3.609887e-05  1.085832e-04   \n",
       "4            6  1.477099e-03  1.905515e-03  1.947489e-02  7.086649e-03   \n",
       "\n",
       "     TripType_7    TripType_8    TripType_9   TripType_12   TripType_14  \\\n",
       "0  6.724353e-03  1.363274e-01  2.948011e-13  1.035182e-41  0.000000e+00   \n",
       "1  5.931267e-32  8.130657e-30  1.061700e-18  1.666864e-30  1.255418e-36   \n",
       "2  3.607914e-02  3.982477e-02  2.684251e-02  2.461405e-03  5.035697e-05   \n",
       "3  6.762326e-05  2.699233e-05  7.892577e-01  7.691106e-08  0.000000e+00   \n",
       "4  3.607914e-02  3.982477e-02  2.684251e-02  2.461405e-03  5.035697e-05   \n",
       "\n",
       "       ...        TripType_36   TripType_37  TripType_38  TripType_39  \\\n",
       "0      ...       1.666031e-13  2.328031e-12     0.826118     0.030830   \n",
       "1      ...       2.480656e-22  3.706382e-03     0.202063     0.026589   \n",
       "2      ...       2.841871e-02  1.510282e-02     0.023757     0.091342   \n",
       "3      ...       1.774390e-05  6.892610e-06     0.000006     0.000012   \n",
       "4      ...       2.841871e-02  1.510282e-02     0.023757     0.091342   \n",
       "\n",
       "    TripType_40   TripType_41   TripType_42   TripType_43   TripType_44  \\\n",
       "0  1.237613e-12  7.923613e-33  1.815581e-23  3.778327e-23  2.590057e-22   \n",
       "1  9.295111e-03  6.476055e-20  2.154178e-11  5.776768e-09  3.698196e-13   \n",
       "2  2.647738e-02  5.176118e-03  1.514823e-02  1.023443e-02  8.074890e-03   \n",
       "3  2.456320e-07  9.968076e-08  4.435841e-06  0.000000e+00  0.000000e+00   \n",
       "4  2.647738e-02  5.176118e-03  1.514823e-02  1.023443e-02  8.074890e-03   \n",
       "\n",
       "   TripType_999  \n",
       "0  5.927163e-22  \n",
       "1  2.854383e-31  \n",
       "2  4.568377e-01  \n",
       "3  1.955480e-03  \n",
       "4  4.568377e-01  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit_to_check.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "af.saveDataFrameToCsv(submit_test_all, \"submit_test_all_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_to_check = pd.read_csv(\"Feature_matrix/submit_please_get_great_score_201808080131.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = af.get_df_to_fit(df_train_fl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_test = fitNaiveBayesModel_smoothing(X, y, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_test.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "##### Accuracy : 0.6993"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "af.getAccuracy(y, y_pred, len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0689111273514562"
      ]
     },
     "execution_count": 439,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(y, model_test.predict_proba(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "af.saveDataFrameToCsv(submit_test_all, \"submit_please_get_great_score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_1 = pd.DataFrame(y_pred_proba_1, columns = tt_li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_1[\"VisitNumber\"] = vn_fl_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_1[\"TripType_14\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_1[\"TripType_43\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_1[\"TripType_44\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_test.drop(\"TripType\", axis =1 , inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_test=sub_test.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_1 = submit_1[sub_test.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_2 = pd.DataFrame(y_pred_proba_2, columns = tt_li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_2[\"TripType_14\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_2[\"VisitNumber\"] = vn_fl_more_than_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_2 = submit_2[sub_test.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_3 = pd.DataFrame(y_pred_proba_3, columns = tt_li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "vn_fl_dice = list(df_to_test.VisitNumber.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_3[\"VisitNumber\"] = vn_fl_dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_3 = submit_3[sub_test.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_all = pd.concat([submit_1, submit_2, submit_3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_all = submit_all.sort_values(\"VisitNumber\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_all.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_all.set_index(\"VisitNumber\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.41254359e-06, 5.79517666e-07, 2.85525253e-07, 6.99342921e-06,\n",
       "       5.34868521e-07, 9.51288050e-01, 2.52301732e-07, 6.08330653e-10,\n",
       "       7.52377882e-10, 9.56470393e-08, 1.09051498e-07, 5.89798632e-07,\n",
       "       1.14668745e-07, 9.76530584e-08, 6.54228115e-07, 3.42084355e-07,\n",
       "       3.67567079e-07, 1.02254938e-07, 1.43131129e-07, 1.08304044e-07,\n",
       "       1.80553735e-07, 6.11786011e-08, 5.39045447e-07, 5.89872472e-07,\n",
       "       7.51374501e-08, 5.87045639e-08, 6.14542455e-08, 4.84732605e-02,\n",
       "       1.40345978e-07, 5.45173372e-08, 5.03687637e-08, 9.36357698e-08,\n",
       "       1.94283506e-09, 7.88428341e-10, 3.50854360e-08, 5.71881452e-09,\n",
       "       7.52377882e-10, 2.23956759e-04])"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_test[sub_test.index.isin(vn_fl_one)].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_test_all.set_index(\"VisitNumber\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 feature 완료.\n",
      "2 feature 완료.\n",
      "3 feature 완료.\n"
     ]
    }
   ],
   "source": [
    "submit_fl = get_proba_and_set_submission(models, features_test, targets, vns_test, submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_fl = submit_fl.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "af.saveDataFrameToCsv(submit_fl, \"submit_nb_tried_three_features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_enc = LabelEncoder().fit(y_1)\n",
    "y_labeled = label_enc.transform(y_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_1, y_labeled, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(X_train.values, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test.values, label=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mlogloss:2.9518\teval-mlogloss:2.95404\n",
      "Multiple eval metrics have been passed: 'eval-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until eval-mlogloss hasn't improved in 10 rounds.\n",
      "[1]\ttrain-mlogloss:2.41875\teval-mlogloss:2.4239\n",
      "[2]\ttrain-mlogloss:1.98923\teval-mlogloss:1.99831\n",
      "[3]\ttrain-mlogloss:1.66572\teval-mlogloss:1.67476\n",
      "[4]\ttrain-mlogloss:1.44663\teval-mlogloss:1.45736\n",
      "[5]\ttrain-mlogloss:1.28503\teval-mlogloss:1.30006\n",
      "[6]\ttrain-mlogloss:1.15639\teval-mlogloss:1.1728\n",
      "[7]\ttrain-mlogloss:1.05341\teval-mlogloss:1.07154\n",
      "[8]\ttrain-mlogloss:0.969075\teval-mlogloss:0.989787\n",
      "[9]\ttrain-mlogloss:0.898572\teval-mlogloss:0.921121\n",
      "[10]\ttrain-mlogloss:0.837392\teval-mlogloss:0.860966\n",
      "[11]\ttrain-mlogloss:0.786237\teval-mlogloss:0.811636\n",
      "[12]\ttrain-mlogloss:0.742256\teval-mlogloss:0.770075\n",
      "[13]\ttrain-mlogloss:0.70336\teval-mlogloss:0.731789\n",
      "[14]\ttrain-mlogloss:0.669246\teval-mlogloss:0.698751\n",
      "[15]\ttrain-mlogloss:0.640082\teval-mlogloss:0.670561\n",
      "[16]\ttrain-mlogloss:0.614212\teval-mlogloss:0.646146\n",
      "[17]\ttrain-mlogloss:0.591239\teval-mlogloss:0.624041\n",
      "[18]\ttrain-mlogloss:0.571267\teval-mlogloss:0.604923\n",
      "[19]\ttrain-mlogloss:0.553593\teval-mlogloss:0.588434\n",
      "[20]\ttrain-mlogloss:0.537525\teval-mlogloss:0.573655\n",
      "[21]\ttrain-mlogloss:0.522723\teval-mlogloss:0.560025\n",
      "[22]\ttrain-mlogloss:0.509676\teval-mlogloss:0.547874\n",
      "[23]\ttrain-mlogloss:0.497836\teval-mlogloss:0.536884\n",
      "[24]\ttrain-mlogloss:0.487092\teval-mlogloss:0.527361\n",
      "[25]\ttrain-mlogloss:0.477106\teval-mlogloss:0.518575\n",
      "[26]\ttrain-mlogloss:0.468192\teval-mlogloss:0.510365\n",
      "[27]\ttrain-mlogloss:0.459905\teval-mlogloss:0.502864\n",
      "[28]\ttrain-mlogloss:0.452138\teval-mlogloss:0.496172\n",
      "[29]\ttrain-mlogloss:0.445165\teval-mlogloss:0.490249\n",
      "[30]\ttrain-mlogloss:0.43885\teval-mlogloss:0.485009\n",
      "[31]\ttrain-mlogloss:0.43296\teval-mlogloss:0.480141\n",
      "[32]\ttrain-mlogloss:0.427477\teval-mlogloss:0.475475\n",
      "[33]\ttrain-mlogloss:0.422408\teval-mlogloss:0.471349\n",
      "[34]\ttrain-mlogloss:0.417722\teval-mlogloss:0.467508\n",
      "[35]\ttrain-mlogloss:0.413166\teval-mlogloss:0.463317\n",
      "[36]\ttrain-mlogloss:0.408886\teval-mlogloss:0.460035\n",
      "[37]\ttrain-mlogloss:0.404968\teval-mlogloss:0.456722\n",
      "[38]\ttrain-mlogloss:0.401069\teval-mlogloss:0.454106\n",
      "[39]\ttrain-mlogloss:0.397364\teval-mlogloss:0.451267\n",
      "[40]\ttrain-mlogloss:0.393921\teval-mlogloss:0.448418\n",
      "[41]\ttrain-mlogloss:0.390645\teval-mlogloss:0.446121\n",
      "[42]\ttrain-mlogloss:0.387473\teval-mlogloss:0.443759\n",
      "[43]\ttrain-mlogloss:0.384214\teval-mlogloss:0.440418\n",
      "[44]\ttrain-mlogloss:0.381328\teval-mlogloss:0.438124\n",
      "[45]\ttrain-mlogloss:0.378519\teval-mlogloss:0.435716\n",
      "[46]\ttrain-mlogloss:0.375979\teval-mlogloss:0.433862\n",
      "[47]\ttrain-mlogloss:0.373578\teval-mlogloss:0.431963\n",
      "[48]\ttrain-mlogloss:0.371227\teval-mlogloss:0.430208\n",
      "[49]\ttrain-mlogloss:0.368903\teval-mlogloss:0.428424\n",
      "[50]\ttrain-mlogloss:0.366637\teval-mlogloss:0.42671\n",
      "[51]\ttrain-mlogloss:0.364595\teval-mlogloss:0.425121\n",
      "[52]\ttrain-mlogloss:0.362595\teval-mlogloss:0.423767\n",
      "[53]\ttrain-mlogloss:0.36071\teval-mlogloss:0.422354\n",
      "[54]\ttrain-mlogloss:0.358817\teval-mlogloss:0.421068\n",
      "[55]\ttrain-mlogloss:0.357065\teval-mlogloss:0.419834\n",
      "[56]\ttrain-mlogloss:0.355237\teval-mlogloss:0.418738\n",
      "[57]\ttrain-mlogloss:0.353634\teval-mlogloss:0.417531\n",
      "[58]\ttrain-mlogloss:0.351811\teval-mlogloss:0.416228\n",
      "[59]\ttrain-mlogloss:0.350239\teval-mlogloss:0.41504\n",
      "[60]\ttrain-mlogloss:0.348601\teval-mlogloss:0.414132\n",
      "[61]\ttrain-mlogloss:0.347105\teval-mlogloss:0.413017\n",
      "[62]\ttrain-mlogloss:0.345609\teval-mlogloss:0.412125\n",
      "[63]\ttrain-mlogloss:0.344173\teval-mlogloss:0.411\n",
      "[64]\ttrain-mlogloss:0.342518\teval-mlogloss:0.410015\n",
      "[65]\ttrain-mlogloss:0.341086\teval-mlogloss:0.409069\n",
      "[66]\ttrain-mlogloss:0.339677\teval-mlogloss:0.408147\n",
      "[67]\ttrain-mlogloss:0.338404\teval-mlogloss:0.407432\n",
      "[68]\ttrain-mlogloss:0.337048\teval-mlogloss:0.406713\n",
      "[69]\ttrain-mlogloss:0.335807\teval-mlogloss:0.405951\n",
      "[70]\ttrain-mlogloss:0.334605\teval-mlogloss:0.405287\n",
      "[71]\ttrain-mlogloss:0.333465\teval-mlogloss:0.404355\n",
      "[72]\ttrain-mlogloss:0.332039\teval-mlogloss:0.403581\n",
      "[73]\ttrain-mlogloss:0.330736\teval-mlogloss:0.402824\n",
      "[74]\ttrain-mlogloss:0.329501\teval-mlogloss:0.401963\n",
      "[75]\ttrain-mlogloss:0.328284\teval-mlogloss:0.40128\n",
      "[76]\ttrain-mlogloss:0.327151\teval-mlogloss:0.400454\n",
      "[77]\ttrain-mlogloss:0.326009\teval-mlogloss:0.399615\n",
      "[78]\ttrain-mlogloss:0.324936\teval-mlogloss:0.398726\n",
      "[79]\ttrain-mlogloss:0.323835\teval-mlogloss:0.39803\n",
      "[80]\ttrain-mlogloss:0.322834\teval-mlogloss:0.397319\n",
      "[81]\ttrain-mlogloss:0.321818\teval-mlogloss:0.396605\n",
      "[82]\ttrain-mlogloss:0.320721\teval-mlogloss:0.395931\n",
      "[83]\ttrain-mlogloss:0.319541\teval-mlogloss:0.39508\n",
      "[84]\ttrain-mlogloss:0.318439\teval-mlogloss:0.394359\n",
      "[85]\ttrain-mlogloss:0.316706\teval-mlogloss:0.393017\n",
      "[86]\ttrain-mlogloss:0.315118\teval-mlogloss:0.391633\n",
      "[87]\ttrain-mlogloss:0.313571\teval-mlogloss:0.390411\n",
      "[88]\ttrain-mlogloss:0.312222\teval-mlogloss:0.389477\n",
      "[89]\ttrain-mlogloss:0.310967\teval-mlogloss:0.388608\n",
      "[90]\ttrain-mlogloss:0.309797\teval-mlogloss:0.387913\n",
      "[91]\ttrain-mlogloss:0.308607\teval-mlogloss:0.387201\n",
      "[92]\ttrain-mlogloss:0.307577\teval-mlogloss:0.386603\n",
      "[93]\ttrain-mlogloss:0.306604\teval-mlogloss:0.386157\n",
      "[94]\ttrain-mlogloss:0.30511\teval-mlogloss:0.385107\n",
      "[95]\ttrain-mlogloss:0.303768\teval-mlogloss:0.3842\n",
      "[96]\ttrain-mlogloss:0.30261\teval-mlogloss:0.383415\n",
      "[97]\ttrain-mlogloss:0.301513\teval-mlogloss:0.382769\n",
      "[98]\ttrain-mlogloss:0.300459\teval-mlogloss:0.382204\n",
      "[99]\ttrain-mlogloss:0.299505\teval-mlogloss:0.381491\n",
      "[100]\ttrain-mlogloss:0.29866\teval-mlogloss:0.380976\n",
      "[101]\ttrain-mlogloss:0.297757\teval-mlogloss:0.380484\n",
      "[102]\ttrain-mlogloss:0.296911\teval-mlogloss:0.379996\n",
      "[103]\ttrain-mlogloss:0.296034\teval-mlogloss:0.379577\n",
      "[104]\ttrain-mlogloss:0.295113\teval-mlogloss:0.378988\n",
      "[105]\ttrain-mlogloss:0.294058\teval-mlogloss:0.378465\n",
      "[106]\ttrain-mlogloss:0.29312\teval-mlogloss:0.377926\n",
      "[107]\ttrain-mlogloss:0.292299\teval-mlogloss:0.377707\n",
      "[108]\ttrain-mlogloss:0.29151\teval-mlogloss:0.377448\n",
      "[109]\ttrain-mlogloss:0.290732\teval-mlogloss:0.377048\n",
      "[110]\ttrain-mlogloss:0.289996\teval-mlogloss:0.376714\n",
      "[111]\ttrain-mlogloss:0.289276\teval-mlogloss:0.376321\n",
      "[112]\ttrain-mlogloss:0.28856\teval-mlogloss:0.375897\n",
      "[113]\ttrain-mlogloss:0.287838\teval-mlogloss:0.3756\n",
      "[114]\ttrain-mlogloss:0.287228\teval-mlogloss:0.375383\n",
      "[115]\ttrain-mlogloss:0.286578\teval-mlogloss:0.374901\n",
      "[116]\ttrain-mlogloss:0.285906\teval-mlogloss:0.37458\n",
      "[117]\ttrain-mlogloss:0.285195\teval-mlogloss:0.374192\n",
      "[118]\ttrain-mlogloss:0.284515\teval-mlogloss:0.373852\n",
      "[119]\ttrain-mlogloss:0.283919\teval-mlogloss:0.373474\n",
      "[120]\ttrain-mlogloss:0.283326\teval-mlogloss:0.373243\n",
      "[121]\ttrain-mlogloss:0.282755\teval-mlogloss:0.373032\n",
      "[122]\ttrain-mlogloss:0.282222\teval-mlogloss:0.372754\n",
      "[123]\ttrain-mlogloss:0.281594\teval-mlogloss:0.372436\n",
      "[124]\ttrain-mlogloss:0.281025\teval-mlogloss:0.372262\n",
      "[125]\ttrain-mlogloss:0.280471\teval-mlogloss:0.371993\n",
      "[126]\ttrain-mlogloss:0.279918\teval-mlogloss:0.371905\n",
      "[127]\ttrain-mlogloss:0.279389\teval-mlogloss:0.371608\n",
      "[128]\ttrain-mlogloss:0.278834\teval-mlogloss:0.371415\n",
      "[129]\ttrain-mlogloss:0.278348\teval-mlogloss:0.371227\n",
      "[130]\ttrain-mlogloss:0.27787\teval-mlogloss:0.370955\n",
      "[131]\ttrain-mlogloss:0.277418\teval-mlogloss:0.370713\n",
      "[132]\ttrain-mlogloss:0.276979\teval-mlogloss:0.370511\n",
      "[133]\ttrain-mlogloss:0.276488\teval-mlogloss:0.370223\n",
      "[134]\ttrain-mlogloss:0.275962\teval-mlogloss:0.369915\n",
      "[135]\ttrain-mlogloss:0.27541\teval-mlogloss:0.369598\n",
      "[136]\ttrain-mlogloss:0.2749\teval-mlogloss:0.369528\n",
      "[137]\ttrain-mlogloss:0.274416\teval-mlogloss:0.369396\n",
      "[138]\ttrain-mlogloss:0.27394\teval-mlogloss:0.369268\n",
      "[139]\ttrain-mlogloss:0.273488\teval-mlogloss:0.369155\n",
      "[140]\ttrain-mlogloss:0.27306\teval-mlogloss:0.368921\n",
      "[141]\ttrain-mlogloss:0.272557\teval-mlogloss:0.368804\n",
      "[142]\ttrain-mlogloss:0.272145\teval-mlogloss:0.368613\n",
      "[143]\ttrain-mlogloss:0.271663\teval-mlogloss:0.368547\n",
      "[144]\ttrain-mlogloss:0.271249\teval-mlogloss:0.368378\n",
      "[145]\ttrain-mlogloss:0.270822\teval-mlogloss:0.368227\n",
      "[146]\ttrain-mlogloss:0.270455\teval-mlogloss:0.368186\n",
      "[147]\ttrain-mlogloss:0.270064\teval-mlogloss:0.368016\n",
      "[148]\ttrain-mlogloss:0.269672\teval-mlogloss:0.368015\n",
      "[149]\ttrain-mlogloss:0.269303\teval-mlogloss:0.367968\n",
      "[150]\ttrain-mlogloss:0.268938\teval-mlogloss:0.367803\n",
      "[151]\ttrain-mlogloss:0.268539\teval-mlogloss:0.367698\n",
      "[152]\ttrain-mlogloss:0.268104\teval-mlogloss:0.367756\n",
      "[153]\ttrain-mlogloss:0.267776\teval-mlogloss:0.367582\n",
      "[154]\ttrain-mlogloss:0.267301\teval-mlogloss:0.367535\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[155]\ttrain-mlogloss:0.266862\teval-mlogloss:0.367576\n",
      "[156]\ttrain-mlogloss:0.266475\teval-mlogloss:0.367413\n",
      "[157]\ttrain-mlogloss:0.266077\teval-mlogloss:0.367257\n",
      "[158]\ttrain-mlogloss:0.265656\teval-mlogloss:0.367059\n",
      "[159]\ttrain-mlogloss:0.265275\teval-mlogloss:0.366842\n",
      "[160]\ttrain-mlogloss:0.26489\teval-mlogloss:0.366648\n",
      "[161]\ttrain-mlogloss:0.26444\teval-mlogloss:0.366539\n",
      "[162]\ttrain-mlogloss:0.264052\teval-mlogloss:0.366425\n",
      "[163]\ttrain-mlogloss:0.263638\teval-mlogloss:0.366241\n",
      "[164]\ttrain-mlogloss:0.263185\teval-mlogloss:0.366225\n",
      "[165]\ttrain-mlogloss:0.262759\teval-mlogloss:0.366192\n",
      "[166]\ttrain-mlogloss:0.262383\teval-mlogloss:0.366134\n",
      "[167]\ttrain-mlogloss:0.262007\teval-mlogloss:0.365964\n",
      "[168]\ttrain-mlogloss:0.261601\teval-mlogloss:0.365746\n",
      "[169]\ttrain-mlogloss:0.26112\teval-mlogloss:0.365508\n",
      "[170]\ttrain-mlogloss:0.260762\teval-mlogloss:0.365492\n",
      "[171]\ttrain-mlogloss:0.260425\teval-mlogloss:0.365353\n",
      "[172]\ttrain-mlogloss:0.260108\teval-mlogloss:0.365299\n",
      "[173]\ttrain-mlogloss:0.259741\teval-mlogloss:0.365246\n",
      "[174]\ttrain-mlogloss:0.25942\teval-mlogloss:0.365106\n",
      "[175]\ttrain-mlogloss:0.259037\teval-mlogloss:0.364864\n",
      "[176]\ttrain-mlogloss:0.258655\teval-mlogloss:0.364636\n",
      "[177]\ttrain-mlogloss:0.258271\teval-mlogloss:0.364443\n",
      "[178]\ttrain-mlogloss:0.257832\teval-mlogloss:0.364361\n",
      "[179]\ttrain-mlogloss:0.257508\teval-mlogloss:0.364153\n",
      "[180]\ttrain-mlogloss:0.257197\teval-mlogloss:0.364116\n",
      "[181]\ttrain-mlogloss:0.256887\teval-mlogloss:0.364016\n",
      "[182]\ttrain-mlogloss:0.256517\teval-mlogloss:0.363909\n",
      "[183]\ttrain-mlogloss:0.25619\teval-mlogloss:0.36388\n",
      "[184]\ttrain-mlogloss:0.255847\teval-mlogloss:0.363804\n",
      "[185]\ttrain-mlogloss:0.25549\teval-mlogloss:0.363683\n",
      "[186]\ttrain-mlogloss:0.255178\teval-mlogloss:0.363535\n",
      "[187]\ttrain-mlogloss:0.254881\teval-mlogloss:0.363467\n",
      "[188]\ttrain-mlogloss:0.254563\teval-mlogloss:0.363378\n",
      "[189]\ttrain-mlogloss:0.254212\teval-mlogloss:0.363294\n",
      "[190]\ttrain-mlogloss:0.253769\teval-mlogloss:0.363293\n",
      "[191]\ttrain-mlogloss:0.253465\teval-mlogloss:0.363242\n",
      "[192]\ttrain-mlogloss:0.253041\teval-mlogloss:0.363256\n",
      "[193]\ttrain-mlogloss:0.252773\teval-mlogloss:0.363187\n",
      "[194]\ttrain-mlogloss:0.252502\teval-mlogloss:0.363159\n",
      "[195]\ttrain-mlogloss:0.252205\teval-mlogloss:0.363104\n",
      "[196]\ttrain-mlogloss:0.25196\teval-mlogloss:0.363142\n",
      "[197]\ttrain-mlogloss:0.251695\teval-mlogloss:0.363031\n",
      "[198]\ttrain-mlogloss:0.251445\teval-mlogloss:0.362935\n",
      "[199]\ttrain-mlogloss:0.251207\teval-mlogloss:0.362942\n",
      "[200]\ttrain-mlogloss:0.250965\teval-mlogloss:0.362915\n",
      "[201]\ttrain-mlogloss:0.250701\teval-mlogloss:0.362886\n",
      "[202]\ttrain-mlogloss:0.250422\teval-mlogloss:0.362853\n",
      "[203]\ttrain-mlogloss:0.250187\teval-mlogloss:0.362707\n",
      "[204]\ttrain-mlogloss:0.249956\teval-mlogloss:0.362681\n",
      "[205]\ttrain-mlogloss:0.249693\teval-mlogloss:0.362702\n",
      "[206]\ttrain-mlogloss:0.249412\teval-mlogloss:0.362562\n",
      "[207]\ttrain-mlogloss:0.24914\teval-mlogloss:0.362541\n",
      "[208]\ttrain-mlogloss:0.248886\teval-mlogloss:0.362477\n",
      "[209]\ttrain-mlogloss:0.248634\teval-mlogloss:0.362379\n",
      "[210]\ttrain-mlogloss:0.248401\teval-mlogloss:0.362265\n",
      "[211]\ttrain-mlogloss:0.24814\teval-mlogloss:0.362239\n",
      "[212]\ttrain-mlogloss:0.247864\teval-mlogloss:0.362133\n",
      "[213]\ttrain-mlogloss:0.247582\teval-mlogloss:0.362003\n",
      "[214]\ttrain-mlogloss:0.247297\teval-mlogloss:0.36201\n",
      "[215]\ttrain-mlogloss:0.247056\teval-mlogloss:0.362005\n",
      "[216]\ttrain-mlogloss:0.246834\teval-mlogloss:0.361919\n",
      "[217]\ttrain-mlogloss:0.246603\teval-mlogloss:0.361834\n",
      "[218]\ttrain-mlogloss:0.246371\teval-mlogloss:0.361864\n",
      "[219]\ttrain-mlogloss:0.246165\teval-mlogloss:0.361893\n",
      "[220]\ttrain-mlogloss:0.245847\teval-mlogloss:0.361785\n",
      "[221]\ttrain-mlogloss:0.245544\teval-mlogloss:0.361767\n",
      "[222]\ttrain-mlogloss:0.245299\teval-mlogloss:0.36176\n",
      "[223]\ttrain-mlogloss:0.245075\teval-mlogloss:0.361637\n",
      "[224]\ttrain-mlogloss:0.244833\teval-mlogloss:0.361617\n",
      "[225]\ttrain-mlogloss:0.244595\teval-mlogloss:0.361589\n",
      "[226]\ttrain-mlogloss:0.244389\teval-mlogloss:0.361564\n",
      "[227]\ttrain-mlogloss:0.244115\teval-mlogloss:0.361311\n",
      "[228]\ttrain-mlogloss:0.24387\teval-mlogloss:0.361159\n",
      "[229]\ttrain-mlogloss:0.243628\teval-mlogloss:0.361066\n",
      "[230]\ttrain-mlogloss:0.243393\teval-mlogloss:0.36092\n",
      "[231]\ttrain-mlogloss:0.243133\teval-mlogloss:0.360791\n",
      "[232]\ttrain-mlogloss:0.242928\teval-mlogloss:0.360734\n",
      "[233]\ttrain-mlogloss:0.242722\teval-mlogloss:0.360723\n",
      "[234]\ttrain-mlogloss:0.242479\teval-mlogloss:0.360736\n",
      "[235]\ttrain-mlogloss:0.242225\teval-mlogloss:0.360759\n",
      "[236]\ttrain-mlogloss:0.242\teval-mlogloss:0.360778\n",
      "[237]\ttrain-mlogloss:0.241806\teval-mlogloss:0.360769\n",
      "[238]\ttrain-mlogloss:0.241624\teval-mlogloss:0.360724\n",
      "[239]\ttrain-mlogloss:0.24144\teval-mlogloss:0.360665\n",
      "[240]\ttrain-mlogloss:0.241235\teval-mlogloss:0.360671\n",
      "[241]\ttrain-mlogloss:0.241027\teval-mlogloss:0.360587\n",
      "[242]\ttrain-mlogloss:0.240812\teval-mlogloss:0.360539\n",
      "[243]\ttrain-mlogloss:0.240633\teval-mlogloss:0.360574\n",
      "[244]\ttrain-mlogloss:0.240453\teval-mlogloss:0.360497\n",
      "[245]\ttrain-mlogloss:0.240259\teval-mlogloss:0.360505\n",
      "[246]\ttrain-mlogloss:0.240029\teval-mlogloss:0.360537\n",
      "[247]\ttrain-mlogloss:0.239789\teval-mlogloss:0.360579\n",
      "[248]\ttrain-mlogloss:0.239615\teval-mlogloss:0.360632\n",
      "[249]\ttrain-mlogloss:0.239443\teval-mlogloss:0.360596\n",
      "[250]\ttrain-mlogloss:0.239294\teval-mlogloss:0.360536\n",
      "[251]\ttrain-mlogloss:0.239125\teval-mlogloss:0.36054\n",
      "[252]\ttrain-mlogloss:0.238939\teval-mlogloss:0.360611\n",
      "[253]\ttrain-mlogloss:0.238769\teval-mlogloss:0.360516\n",
      "[254]\ttrain-mlogloss:0.238621\teval-mlogloss:0.360552\n",
      "Stopping. Best iteration:\n",
      "[244]\ttrain-mlogloss:0.240453\teval-mlogloss:0.360497\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_boost_round = 300\n",
    "params = {'objective': 'multi:softprob', \n",
    "          'eval_metric': 'mlogloss',\n",
    "          'num_class': 35, \n",
    "          'max_delta_step': 3, \n",
    "          'eta': 0.2}\n",
    "\n",
    "evals = [(dtrain, 'train'), (dtest, 'eval')]\n",
    "\n",
    "bst = xgb.train(params=params,  \n",
    "                dtrain=dtrain, \n",
    "                num_boost_round=num_boost_round, \n",
    "                evals=evals,\n",
    "                early_stopping_rounds=10,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "metadata": {},
   "outputs": [],
   "source": [
    "af.saveDataFrameToCsv(X_1, \"X_1\")\n",
    "af.saveDataFrameToCsv(y_1, \"y_1\")\n",
    "af.saveDataFrameToCsv(X_2, \"X_2\")\n",
    "af.saveDataFrameToCsv(y_2, \"y_2\")\n",
    "af.saveDataFrameToCsv(X_3, \"X_3\")\n",
    "af.saveDataFrameToCsv(y_3, \"y_3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_enc_2 = LabelEncoder().fit(y_2)\n",
    "y_labeled = label_enc_2.transform(y_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_2, y_labeled, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(X_train.values, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test.values, label=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_boost_round = 50\n",
    "params = {'objective': 'multi:softprob', \n",
    "          'eval_metric': 'mlogloss',\n",
    "          'num_class': 37, \n",
    "          'max_delta_step': 3, \n",
    "          'eta': 0.2}\n",
    "\n",
    "evals = [(dtrain, 'train'), (dtest, 'eval')]\n",
    "\n",
    "bst_2 = xgb.train(params=params,  \n",
    "                dtrain=dtrain, \n",
    "                num_boost_round=num_boost_round, \n",
    "                evals=evals,\n",
    "                early_stopping_rounds=10,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_enc_3 = LabelEncoder().fit(y_3)\n",
    "y_labeled = label_enc_3.transform(y_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_3, y_labeled, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(X_train.values, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test.values, label=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_boost_round = 50\n",
    "params = {'objective': 'multi:softprob', \n",
    "          'eval_metric': 'mlogloss',\n",
    "          'num_class': 38, \n",
    "          'max_delta_step': 3, \n",
    "          'eta': 0.2}\n",
    "\n",
    "evals = [(dtrain, 'train'), (dtest, 'eval')]\n",
    "\n",
    "bst_3 = xgb.train(params=params,  \n",
    "                dtrain=dtrain, \n",
    "                num_boost_round=num_boost_round, \n",
    "                evals=evals,\n",
    "                early_stopping_rounds=10,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
